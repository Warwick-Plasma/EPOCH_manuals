\documentclass[12pt]{article}
\usepackage{url,graphicx,tabularx,array}
\usepackage[margin=.5in,nohead,nofoot]{geometry}
\usepackage{color}
\usepackage{moreverb}
\usepackage{fancyvrb}
\definecolor{warwickdark}{cmyk}{1.0,0.6,0.0,0.06}
\definecolor{warwickmid}{cmyk}{0.69,0.34,0.0,0.0}
\definecolor{warwicklight}{cmyk}{1.0,0.0,0.0,0.0}
\definecolor{warwickred}{cmyk}{0.0,1.0,0.65,0.15}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\emphtext}{\color{warwickdark} \fontfamily{phv}\selectfont\Large\bf}
\newcommand{\inlineemph}{\color{warwicklight} \bf}
\newcommand{\simpleboxverbatim}{\begin{Verbatim}[obeytabs=true,frame=single,
  framerule=0.5mm,rulecolor=\color{warwickmid}]}
\newcommand{\boxverbatim}[1]{\begin{Verbatim}[obeytabs=true,frame=single,
  framerule=0.5mm,rulecolor=\color{warwickmid},label=#1]}
\newcommand{\inlinecode}[1]{{\color{warwickred} \bf\texttt{#1}}}
\newcommand{\EPOCH}{{\color{warwickdark}\fontfamily{phv}\selectfont EPOCH} }
\newcommand{\image}[1]
  {{\begin{figure} \centering \includegraphics{#1} \end{figure}}}
\newcommand{\taggedimage}[2]
  {{\begin{figure}\centering\includegraphics{#1}\label{#2}\end{figure}}}
% Caption before Label to fix strange problem with not putting in subsection
% numbers. DO NOT CHANGE.
\newcommand{\captionedimage}[3]
  {{\begin{figure}\centering \includegraphics{#1} \caption{#3} \label{#2}
    \end{figure}}}
\newcommand{\scaledcapimage}[4]
  {{\begin{figure}\centering \includegraphics[scale=#4]{#1} \caption{#3}
    \label{#2} \end{figure}}}

\begin{document}
{
  \fontfamily{phv}\selectfont
  \input{./title.tex}
}
\fontfamily{garamond}\selectfont
\tableofcontents
\newpage

\section{FAQs}

\subsection{What is \EPOCH?}
\EPOCH is a plasma physics simulation code which uses the Particle in Cell(PIC)
method. In this method, collections of physical particles are represented using
a smaller number of pseudoparticles, and the fields generated by the motion of
these pseudoparticles are calculated using a finite difference time domain
technique on an underlying grid of fixed spatial resolution. The forces on the
pseduoparticles due to the calculated fields are then used to update the
pseudoparticle velocities, and these velocities are then used to update the
pseudoparticle positions. This leads to a scheme which can reproduce the full
range of classical microscale behaviour of a collection of charged particles,
but shows statistical noise if one pseudoparticle represents many real
particles (which is common in real problems), and also shows artificial
smoothing of currents and fields due to the finite spatial resolution of the
underlying grid.\\

This approach can alternatively be considered as using the pseduoparticles as
Monte Carlo sampling points of the full (2N)D phase space of an (N)D
problem. This has siginifcant memory advantages over (2N)D direct Vlasov
solvers at the expense of lower accuracy and higher noise.

\subsubsection{Features of \EPOCH}
\begin{itemize}
  \item MPI parallelised explicit 2nd order relativistic PIC code
  \item Dynamic MPI load balancing option
  \item MPIIO based output, allowing restart on arbitrary number of processors
  \item Data analysis and visualisation options include ITT IDL, LLNL VisIT
    and Mathworks MatLab
\end{itemize}

\subsection{The origins of the code}
The \EPOCH family of PIC codes is based on the older code PSC by Hartmut Ruhl,
and retains almost the same core algorithm for the field updates and particle
advance routines. \EPOCH was written to add more modern features, and to
structure the code in such a way that future expansion of the code is made as
easy as possible.

\subsection{What normalisations are used in \EPOCH?}
Since the idea from the start was that \EPOCH would be used by a large number
of different users, and that it should be as easy as possible to ``plug in''
different modules from different people into a given copy of the code, it was
decided to write \EPOCH in SI units. There are a few places in the code where
some quantities are given in other units for convenience(for example charges
are specified in multiples of the electron charge), but the entire of the core
code is written in SI units.

\subsection{What are those \_num things doing everywhere}
Historically using the compiler autopromotion of REAL to DOUBLE PRECISION was
unreliable, so \EPOCH uses kind tags to specifiy the precision of the code. The
\_num suffixes and the associated definition of REALs as REAL(num) are these
kind tags in operation. The \_num tags force numerical constants to match the
precision of the code preventing errors due to precision conversion. The
important thing is that all numerical constants should be tagged with an \_num
tag, and all REALs should be defined as REAL(num).

\subsection{I just want to use the code as a black box, or I'm just
  starting. How do I do that?}
See the section titled {\bf Getting started guides}

\subsection{I've been through the getting started guides but want more detail
  on using the code. How do I do that?}
See the section titled {\bf \EPOCH for end users}

\subsection{I can set up the code using the autoloaders, but I want more
  control. How do I do that?}
See the section titled {\bf \EPOCH for advanced end users}

\subsection{I am an advanced user, but I want to set up the code so that less
  experienced users can use it. How do I do that?}
See the section titled {\bf Customising \EPOCH}

\subsection{I want to develop an addition to \EPOCH. How do I do that?}
Basically read the entire of this manual. The second part of the manual details
the internals of the code but it expects you to already be familiar with all
the material in the first part of the manual.

\subsection{I want to have a full understanding of how \EPOCH works. How do I
  do that?}
You're insane. Seek professional help. If you really want to understand \EPOCH
in full, the only thing that I can recommend is that you should read all of
this manual and then read through the code, most of it is commented.
\pagebreak

\section{Getting Started Guides}

\subsection{History of these guides}
These guides are based on material which was used as handouts at an \EPOCH
introductory workshop held in February 2010 at the University of Warwick. The
purpose of these guides is to quickly get a new user to the point of being able
to use \EPOCH without getting bogged down in the details of how the code
works. Some of the material covered in these getting started guides will also
appear in the body of the manual.
\pagebreak

\subsection{Running \EPOCH and basic control of EPOCH1D}
When the code is run, the output is\\
\\
\\
\\
\boxverbatim{Command line output}
@@@@@@@@  @@@@@@      @@@@    @@@@@@@@  @@    @@    @@@@@@    @@@@@@
@@@@@@@@  @@@@@@      @@@@    @@@@@@@@  @@    @@    @@@@@@    @@@@@@
@@        @@    @@  @@    @@  @@        @@    @@       @@@    @@  @@
@@        @@    @@  @@    @@  @@        @@    @@       @@@    @@  @@
@@        @@    @@  @@    @@  @@        @@    @@       @@@    @@    @@
@@        @@    @@  @@    @@  @@        @@    @@       @@@    @@    @@
@@@@@@@@  @@@@@@    @@    @@  @@        @@@@@@@@       @@@    @@    @@
@@@@@@@@  @@@@@@    @@    @@  @@        @@@@@@@@       @@@    @@    @@
@@        @@        @@    @@  @@        @@    @@       @@@    @@    @@
@@        @@        @@    @@  @@        @@    @@       @@@    @@    @@
@@        @@        @@    @@  @@        @@    @@       @@@    @@  @@
@@        @@        @@    @@  @@        @@    @@       @@@    @@  @@
@@@@@@@@  @@          @@@@    @@@@@@@@  @@    @@    @@@@@@@@  @@@@@@
@@@@@@@@  @@          @@@@    @@@@@@@@  @@    @@    @@@@@@@@  @@@@@@

Welcome to EPOCH1D Version 1.3

 The code was compiled with the following compile time options
 *************************************************************
 Per particle weighting -DPER_PARTICLE_WEIGHT
 Tracer particle support -DTRACER_PARTICLES
 Particle probe support -DPARTICLE_PROBES
 Particle ionisation model -DPARTICLE_IONISE
 *************************************************************

 Specify output directory
\end{Verbatim}

At which point the end user should simply type in the name of the directory
where the code ouput should be placed. This directory must also include the
file �input.deck� which controls the code setup, specifies how to set the
initial conditions and controls the IO. Writing an input deck for \EPOCH is
fairly time consuming and so the code is supplied with an example input deck
which includes all the necessary sections for the code to run. This section of
the manual describes how to set up the basic code and a few simple problems in
EPOCH1D.
\pagebreak

\subsection{input.deck}
The input deck file resides in the output directory and contains all the basic
information which is needed to set up the code, including the size and
subdivision of the domain, the boundary conditions, the species of particles to
simulate and the output settings for the code.

\subsubsection{{\inlineemph control} block}
The {\inlineemph control} block sets up the basic code properties for the
domain, the end time of the code, the load balancer and the types of initial
conditions to use.

\boxverbatim{control block}
begin:control
   nx=2000 #in x
   npart=200*200*40

   nsteps=-1

   t_end=0.3e-12

   x_start=-5e-6
   x_end=5e-6

   dt_multiplier=0.8

   dlb=F
   dlb_threshold=1.0

   initial_conditions=external
   icfile=ic.deck
   restart_snapshot=98
   neutral_background=T
end:control
\end{Verbatim}


{\emphtext nx} - Number of grid points in the x direction. There must be
sufficient gridpoints so that (x\_end-x\_start)/nx $< \lambda_d$\\

{\emphtext npart} - The global number of pseudoparticles in the
simulation. This parameter does not need to be specified if a specific number
of particles is specified for each particle species. Specifying both will just
use the number of particles specified for each species\\

{\emphtext nsteps} - The number of iterations of the core solver before the
code terminates. Negative numbers instructs the code to only terminate at
{\inlineemph t\_end}.\\

{\emphtext t\_end} - The final simulation time in simulation seconds before the
code terminates.\\

{\emphtext NOTE: The code will terminate if EITHER of the above conditions on
nsteps or t\_end is satisfied}\\

{\emphtext x\_start} - The position of the left hand edge of the domain in
metres. Can be negative.\\

{\emphtext x\_end} - The position of the right hand edge of the domain in
metres. Must be greater than {\inlineemph x\_start}.\\

{\emphtext dt\_multiplier} - Factor by which the timestep is multiplied before
it is applied in the code. Must be less than one.\\

{\emphtext dlb} - Logical flag to activate/deactive the dynamic load
balancing. Even with dlb=F the code will be statically balanced when first
run.\\

{\emphtext dlb\_threshold} - Number indicating the minimum ratio between the
load on the least loaded processor to the most loaded processor. Set to 1 means
always balance, set to 0 means never balance.\\

{\emphtext initial\_conditions} - Sets the type of initial conditions used in
this run of the code. The types of available initial conditions is descibed
later in this document.\\

{\emphtext icfile} - The filename for external (input deck driven) initial
conditions.\\

{\emphtext restart\_snapshot} - The number of the previously written restart
dump to restart the code from.\\

{\emphtext neutral\_background} - Logical flag indicating whether or not to
solve Poisson�s equation at t=0 or assume that there is a neutralising
background field. If T then Poisson�s equation is solved.\\

\pagebreak

\subsubsection{{\inlineemph boundaries} block}
The {\emphtext boundaries} block sets the boundary conditions of each boundary
of the domain. Some types of boundaries allow EM wave sources (lasers) to be
attached to a boundary. The lasers are attached at the initial conditions
stage.

\boxverbatim{boundaries block}
begin:boundaries
   xbc_left=simple_laser
   xbc_right=simple_outflow
end:boundaries
\end{Verbatim}

{\emphtext xbc\_left} - The boundary condition for the left boundary.\\

{\emphtext xbc\_right} - The boundary condition for the right boundary.\\

There are four boundaries types in \EPOCH and each boundary of the domain can
have one and only one of these boundaries attached to it. These boundary types
are\\\\

{\emphtext periodic} - A simple periodic boundary condition. Fields and
particles reaching one edge of the domain are wrapped round to the opposite
boundary.\\\\

{\emphtext other} - A generic boundary condition which in the default \EPOCH
version is perfectly reflecting for both particles and EM waves.\\\\

{\emphtext simple\_laser} - A characteristic based boundary condition to which
one or more EM wave sources can be attached. Since the wave sources require the
domain to be completely set up before they can be calculated the wave sources
are attached when the initial conditions are set.  EM waves impinging on a
{\inlineemph simple\_laser} boundary are transmitted with as little reflection
as possible. Particles are fully transmitted. The field boundary condition
works by allowing outflowing characteristics to propagate through the boundary
while using the attached lasers to specify the inflowing characteristics. The
particles are simply removed from the simulation when they reach the
boundary.\\\\

{\emphtext simple\_outflow} - A simplified version of {\inlineemph
simple\_laser} which has the same properties of transmitting incident waves and
particles, but which cannot have EM wave sources attached to it. These
boundaries are about 5\% more computationally efficient than {\inlineemph
simple\_laser boundaries} with no attached sources. This boundary condition
again allows outflowing characteristics to flow unchanged, but this time the
inflowing characteristics are set to zero. The particles are again simply
removed from the simulation when they reach the boundary.\\\\

{\emphtext NOTE: If either simple\_laser or simple\_outflow are specified on
one or more boundaries then the code will no longer necessarily conserve mass.}

\pagebreak

\subsubsection{{\inlineemph species} block}

\boxverbatim{species block}
begin:species
   n_species=2

   #electrons
   charge1=-1.0
   mass1=1.0
   npart1=2000*100
   frac1=0.5
   name1=Electron
   dump1=T

   #carbon4+
   charge2=4.0
   mass2=1836.0*12
   npart2=2000*100
   frac2=0.5
   name2=Carbon
   dump2=T
end:species
\end{Verbatim}

{\emphtext n\_species} - This MUST be the first entry in this block and
specifies the number of species in the simulation. After this line, the
properties of any numbered species may be set in any order. The species are
numbered from 1 to {\inlineemph n\_species}.\\

{\emphtext charge\inlinecode{n}} - This sets the charge of species n in
multiples of the electron charge. Negative numbers are used for negatively
charged particles.\\

{\emphtext mass\inlinecode{n}} - This sets the mass of species n in multiples
of the electron mass. Negative numbers are not trapped and effectively swap the
charge of the species. This is not recommended since it breaks the
mass\_density diagnostic.\\

{\emphtext npart\inlinecode{n}} - This specifies the number of pseudo-particles
which should be loaded into the simulation domain for species n. This is the
most convenient way of loading particles for simulations containing multiple
species with different number densities. If these are specified then
{\inlineemph npart} (the global number of particles specified in the control
block) is ignored for this species. It should not be specified at the same time
as fracn for a given species.\\

{\emphtext frac\inlinecode{n}} - This specifies what fraction of npart (the
global number of particles specified in the control block) should be assigned
to species n. \\

{\emphtext NOTE: fracn should not be specified at the same time as npartn for a
given species.}\\

{\emphtext name\inlinecode{n}} - This specifies the name of particle species
n. This name can include any alphanumeric characters in the basic ASCII
set. The name is used to indentify the species in any species specific output
information. \\

{\emphtext NOTE: DO NOT SET TWO SPECIES WITH THE SAME NAME!}\\

{\emphtext dump\inlinecode{n}} - Logical flag detailing whether or not to dump
the information about species n. If set to F, then the species information is
not dumped when writing ANY species specific diagnostics, although it is
included in global diagnostics (i.e in the example if dump2=F were specified
then there would be no �mass\_density\_carbon�, but the mass of the carbon
would be considered when calculating �mass\_density�) and restart dumps.\\

{\emphtext tracer\inlinecode{n}} - Logical flag switching particle species n
into tracer particles. Tracer particles are enabled with the correct
precompiler option, and when set for a given species make that species move
correctly for it�s charge and mass, but contribute no current. This means that
these particles as passive tracers in the plasma.\\

\pagebreak

\subsubsection{{\inlineemph output} block}
Output in \EPOCH is handled using the custom designed CFD ({\inlineemph Compact
Flexible Datatype}) self defining file format which will be covered in more
detail in a later set of notes and comes with readers for ITT IDL and LLNL
VisIT, with additional readers for Mathworks Matlab and Yorick under
development. What the code should output and when it should output it is
specified in the �output� block of the input deck which will be covered over
the next few pages, but a quick note should be made on the types of output and
on how to specify when a given variable should be dumped.\\

There are three types of output dump in \EPOCH which are used for different
purposes. These types are\\

{\emphtext normal} - The most frequent type of output dump in \EPOCH is a
normal dump. Only the variables required for science output should be written
at a normal dump.\\

{\emphtext full} - A full dump is usually written every 10 or so normal
dumps. A full dump contains all the data that a normal dump contains and should
also contain any information which is needed only infrequently, whether this is
the full particle information or a large distribution function. It is possible
to turn off full dumps completely.\\

{\emphtext restart} - A restart dump is a dump where the code guarantees to
write enough data to allow the code to restart from the output. Output dumps
are guaranteed to contain all the informtaion in a normal dump and may if they
coincide with the timing for a full dump will also contain the full dump
information.\\

Information will never be written into a file twice, even if two conditions for
it being written are satisfied (i.e even if px should be dumped both because it
is a full dump and a restart dump, px will only be written once).\\

When specifying which type of output dump to write a variable at there are four
options which are specified for each variable and can be combined by
addition. Obviously some combination make no sense but are formally
valid. These are\\

{\emphtext never} - If this variable is not a required restart variable then it
will never be written. If it is a required restart variable then it will be
written only at restart dumps.\\

{\emphtext always} - This variable will be written at full, normal and restart
dumps.\\

{\emphtext full} - This variable will be written at full dumps only.\\

{\emphtext restart} - This variable will be written at restart dumps only.\\

There is also a fifth parameter which can be specified for some variables.\\

{\emphtext species} - The output for this variable should be broken down on a
species by species basis. This only applies to certain kinds of derived field
variable, such as mass\_density. It is combined with a restart frequency code
by addition as in : \inlinecode{px = always + species}.\\

When applied to a variable, these codes are referred to as a {\inlineemph
dumpmask}.\\

\pagebreak

\boxverbatim{output block}
begin:output
   #If use_offset_grid is true then the code dumps a
   #grid which displays positions relative to the
   #Left hand edge of the window
   use_offset_grid=F
   #number of timesteps between output dumps
   dt_snapshot=1.0e-14
   #Number of dt_snapshot between full dumps
   full_dump_every=10
   restart_dump_every=-1
   force_final_to_be_restartable=T

   use_extended_io=T
   extended_io_file=io.deck

   #Properties at particle positions
   particles=never
   px=never
   py=never
   pz=never
   vx=never
   vy=never
   vz=never
   charge=never
   mass=never
   particle_weight=never
   species_id=never

   #Properties on grid
   grid=always
   ex=always
   ey=always
   ez=always
   bx=always
   by=always
   bz=always
   jx=always
   jy=always
   jz=never
   ekbar=always + species
   mass_density=never + species
   charge_density=always
   number_density=always + species
   temperature=always+species

   #extended io
   distribution_functions=always
   particle_probes=never
end:output
\end{Verbatim}

{\emphtext use\_offset\_grid} - When using moving windows some visualisation
programs (notable VisIT) show the motion of the window by moving the
visualisation window rather than by changing the x-axis. Setting this option to
T causes the code to write another grid which always gives the offset relative
to the left hand edge of the window rather than the true origin. Performs no
function when not using the moving window.\\

{\emphtext dt\_snapshot} - Sets the interval between normal output dumps in
simulation seconds. Setting zero or negative means that the code will output
every step of the core solver. The code does NOT guarantee that outputs will be
exactly {\inlineemph dt\_snapshot} apart, what is guaranteed is that the next
output will be after the first iteration which takes the simulation to a time
$/ge$ {\inlineemph dt\_snapshot} from the last output.\\

{\emphtext full\_dump\_every} - The number of normal output dumps between full
output dumps.\\

{\emphtext restart\_dump\_every} - The number of normal output dumps between
restart dumps. Setting to zero makes every dump a restart dump, setting
negative sets the code to not produce restart dumps.\\

{\emphtext force\_final\_to\_be\_restartable} - Force the code to override
other output settings and make the last output dump it writes be a restart
dump. Any internal condition which causes the code to terminate will make the
code write a restart dump, but code crashes or scheduler terminations will not
cause the code to write a restart dump.\\

{\emphtext use\_extended\_io} - Some types of output can only be specified once
the code has been completely set up and all the MPI initialization routines
have been completed. Those routines are classed as extended IO routines and
need their input files to be in a separate input deck. If this option is set to
T then these routines are available for use and the file containing their input
decks must be specified in {\inlineemph extended\_io\_file}.\\

{\emphtext extended\_io\_file} - Input deck file setting up extended diagnostic
options.\\

{\emphtext particles} - The dumpmask for the particle positions. Restart
variable. No particle variables can be plotted in VisIt unless this is
dumped.\\

{\emphtext p\{x,y,z\}} - The dumpmasks for the particle momenta. Restart
variable.\\

{\emphtext v\{x,y,z\}} - The dumpmasks for the particle velocities.\\

{\emphtext charge} - The dumpmask for the charge of a given particle. Trivial
without compiling the code with the option for per particle charge.\\

{\emphtext mass} - The dumpmask for the mass of a given particles. Trivial
without compiling the code with the option for per particle mass.\\

{\emphtext particle\_weight} - The dumpmask for the weighting function which
describes how many real particles each pseudoparticle represents. Restart
variable.\\

{\emphtext species\_id} - The dump mask for the number representing which
particle species a given particle is. This is the same as the number assigned
to that particle species in the species block. Restart variable\\

{\emphtext grid} - The dumpmask for the Cartesian grid which defines the
locations of the grid variables. No grid variables can be plotted in VisIT
unless this variable is output.\\

{\emphtext e\{x,y,z\}} - The electric field vectors pointing in all three
directions. Restart variables.\\

{\emphtext b\{x,y,z\}} - The magnetic field vectors pointing in all three
directions. Restart variables. In 1D Bx is a trivial variable because of the
Solenoidal condition. It is included simply for symmetry with higher dimension
codes.\\

{\emphtext j\{x,y,z\}} - The currents pointing in all three directions. Restart
variables.\\

{\emphtext ekbar} - Mean kinetic energy on grid. Can have species dumpmask.\\

{\emphtext mass\_density} - Mass density on grid. Can have species dumpmask.\\

{\emphtext charge\_density} - Charge density on grid. Can have species
dumpmask.\\

{\emphtext number\_density} - Number density on grid. Can have species
dumpmask.\\

{\emphtext temperature} - Temperature on grid. Can have species dumpmask. The
exact way that temperature is calculated in the code is likely to vary in the
near future.\\

{\emphtext distribution\_function} - Dumpmask for outputting distribution
functions specified in the extended io deck. Each individual distribution
function can have it�s own dumpmask, but this one is more restrictive.\\

\pagebreak

\subsection{External initial conditions}

The initial conditions in \EPOCH can be specified in various ways, but the
easiest way is to specify the initial conditions in the input deck file. This
allows any initial condition which can be specified everywhere in space by a
number density and a drifting Maxwellian distribution function. This sections
details the blocks that can be set to set up the initial conditions.

\subsubsection{{\inlineemph constants} and {\inlineemph DEO} blocks}

\boxverbatim{constant block}
begin:constant
   lambda=1.0e-6#1 micron wavelength
   omega=2.0*pi*c/lambda
   den_crit=critical(omega)
   scale=3.5e-6 #microns
   den_max=5.0*den_crit
   thick=300e-9
   pplength=6000e-9
   widscale=5.0e-6

   t_wid=(10.0e-6)/c
   amax=1.0
   wy=1e-6
   y=0.0
end:constant
\end{Verbatim}

\boxverbatim{deo block}
begin:deo
   slope=exp(-2.0*(y/wy)^2)
   blob=gauss(sqrt(x^2+y^2),0.0,1.0e-6)
end:deo
\end{Verbatim}

The initial conditions deck in \EPOCH is set up, using the normal maths
expressions, by setting the density and temperature for each species which is
then used by the autoloader to actually position the particles.\\

Before moving on to the blocks which actually set up the initial conditions
there are other helpful blocks which should be explained. These are called
{\inlineemph constants} and {\inlineemph DEO}s which allow you to define
constants and maths parser expressions which can be used by name later in the
deck.\\

Constant and DEO blocks can be used anywhere in the input decks, and the
assigned values and expressions carry over to other deck files, allowing
constants defined in the main input deck to be used in the initial conditions
etc. Constants are simply maths parser expressions which are evaluated when
defined and assigned to a name as shown in the panel to the left. When the name
is used on the right hand side of a deck expression, it is simply replaced with
the numerical value calculated when the constant is created.  If a constant
name is reused in a constant block then the old constant is deleted and
replaced with the new one to conserve memory. This happens without warning.\\

However, since constants are created once and never change, they cannot be used
for spatially varying quantities, and this is where DEOs come in. DEO is short
for deferred execution object and as the name implies, a DEO is a deck
expression that is not evaluated when it is created, but rather when it is used
on the right hand side of a deck expression. This allows DEOs to contain
spatially varying information without having to precalculate them at every
location in the domain. However, DEOs require significantly more memory than
constants and should not be used unless needed. As with constants, when a DEO
name is reused in a DEO block the original DEO is deleted and replaced with the
new DEO. When created, DEOs are given a basic sanity test and should cause the
code to exit if they are invalid, but for sufficiently subtle errors, this is
not guaranteed. Use DEOs with caution and test very carefully if errors
appear.\\

Using constants and DEOs can be very helpful when dealing with long,
complicated expressions since they allow the expression to be broken down into
much simpler parts. They can also be used to get around the Fortran string
length limitation built into many compilers which prevents deck lines being
longer then 512 characters long. As a general rule, it is a good idea to break
down complicated expressions, either using constants and DEOS or by other
means, in order to make the deck look more readable.\\

Both constants and DEOs are persistent for the entire runtime of the code,
allowing them to be used when specifying time profiles for lasers, and also
allowing developers to use maths parser expressions for other internal parts of
the code where needed.
\pagebreak

\subsubsection{{\inlineemph laser} blocks}
Laser blocks attach an EM wave source to a boundary which is set as
{\inlineemph simple\_laser}.

\boxverbatim{laser block}
begin:laser
   direction=left
   amp=3.222499e13
   irradiance=1.0e19
   id=1
   freq=omega
   pol=0.0
   phase=0.0
   t_profile=gauss(time,40.0e-15,40.0e-15)
   t_start=0.0
   t_end=80.0e-15
end:laser
\end{Verbatim}

As already mentioned in the discussion of laser boundaries in the boundaries
block, lasers are attached to compatible boundaries here in the initial
conditions deck. In 1D, laser blocks are slightly simpler than their 2D and 3D
equivalents, but most of the important features will be mentioned here. The
only significant difference is that there is also a spatial profile for
multidimensional lasers. This is covered in detail in the section on
multidimensional \EPOCH\\

{\emphtext direction} - The boundary to which to attach the laser. This is
slightly misnamed, since it is NOT the direction in which the laser will be
propagating, but the side of the box to which to attach the laser. The name may
change in future versions, but �direction� will be kept to maintain
compatibility. In 1D, the directions can be either left or right.\\

{\emphtext amp} - The amplitude of the E field of the laser.\\

{\emphtext irradiance} - The irradiance (intensity) of the laser in $W/m^2$. It
may sometimes be more convenient to use either irradiance or amp but the two
are equivalent in effect.\\

{\emphtext id} - An ID code for the laser. Used if you specify the laser time
profile in the \EPOCH source rather than in the input deck. Does not have to be
unique, but all lasers with the same ID will have the same time profile.\\

{\emphtext freq} - Angular frequency (rad/s not Hz) for the laser.\\

{\emphtext pol} - Polarization angle for the laser in degrees. This may be
changed to radians for consitency in the future. \\

{\emphtext phase} - Phase shift for the laser in radians.\\

{\emphtext t\_profile} - Used to specify the time profile for the laser. Should
use the parser variable time to specify the time profile. Since this is applied
after the laser amplitude, it should run between 0 and 1. Setting values
greater than 1 is possible but will cause the maximum laser intensity to grow
beyond amp.\\

{\emphtext t\_start} - Start time for the laser in seconds, can be set to the
string �start� to start at the beginning of the simulation. When using this
parameter, the laser start is hard, to get a soft start use the {\inlineemph
t\_profile} parameter to ramp the laser up to full strength.\\

{\emphtext t\_end} - End time for the laser in seconds, can be set to the
string �end� to end at the end of the simulation. When using this parameter,
the laser end is clipped straight to zero at t$>${\inlineemph t\_end}. To get a
soft end use the {\inlineemph t\_profile} parameter to ramp the laser down to
zero.\\

{\emphtext NOTE: You should not use amp and irradiance in the same block
(despite the above example). The last set of the two would override the
preceeding element.}\\

The laser time profiles specified in the laser input block represent only the
temporal envelope for the wave. The wave itself is introduced as a sinusoidal
variation using the frequency specified in the laser block.

In theory, any laser time profile required is possible, but the core FDTD
solver for the EM fields in EPOCH produces spurious results if suddent changes
in the field intensity occur. This is shown in the two figures on this
page. The pulse shown in figure \ref{badpulse} used a constant {\inlineemph
t\_profile} and used {\inlineemph t\_end} to stop the laser after 8fs. Since
the stopping time was not an exact multiple of the period, the result was to
introduce spurious oscillations behind the pulse. If the laser had a finite
phase shift so that the amplitude did not start at zero, a similar effect would
be observed on the front of the pulse.

\captionedimage{./images/pulse2.eps}{badpulse}{A laser pulse with a sharp
cutoff shows numerical artifacts behind the pulse.}
\captionedimage{./images/pulse1.eps}{smoothpulse}{A laser pulse with a smooth
temporal profile shows no artifacts.}

Figure /ref{smoothpulse} instead used a Gaussian window function with a
characteristic width of 8fs as well as using {\inlineemph t\_end} to introduce
a hard cutoff. It can clearly be seen that there are no spurious oscillations
and the wave packet propagates correctly, showing only some dispersive
features.

There is no hard and fast rule as to how rapid the rise or fall for a laser can
be, and the best advice is to simply test the problem and see whether any
problems occur. If they do then there are various solutions. Essentially, the
timestep must be reduced to the point where the sharp change in amplitude can
be accomodated. The best solution for this is to increase the spatial
resolution (with a comparable increase in the number of pseudo-particles), thus
causing the timestep to drop via the CFL condition.

This is computationally expensive, and so a cheaper option is simply to
decrease the input.deck option {\inlineemph dt\_multiplier}. This artificially
decreases the timestep below the timestep calculated from the internal
stability criteria and allows the resolution of sharp temporal gradients. This
is an inferior solution since the FDTD scheme has increased error as the
timestep is reduced from that for EM waves. The latest version of EPOCH
includes a high order field solver to attempt to reduce this.
\pagebreak

\subsubsection{{\inlineemph species\inlinecode{n}} block}
\boxverbatim{species{\it n} block}
begin:species2
   rho=if(abs(x) lt thick,den_max,0.0)
   rho=if((x gt -thick) and (abs(y) gt 2e-6),0.0,rho(2))
   temp_x=0.0
   temp_y=temp_x(1)
   minrho=0.1 * den_max
end:species2

begin:species1
   rho=4.0*rho(2)
   temp_x=temp_x(1)
   temp_y=temp_x(1)
   minrho=0.1 * den_max
end:species1
\end{Verbatim}

The actual initial conditions are specified in one or more blocks called
species blocks. There should be one of these blocks for each species which is
to have it�s initial conditions set from the external initial conditions.\\

Each block is started with a\\

{\emphtext begin:species\inlinecode{n}}\\

line, and ends with an associated \\

{\emphtext end:species\inlinecode{n}}\\

line. The species number n is the same species number which is assigned
properties in the species block of input.deck. So if you assigned species 1 the
properties of an electron then the initial conditions given in the block
species1 would be the initial conditions used to set up the electrons. Note
that as in the example above the species do not have to be specified in any
given numerical order. The above example positions carbon 4+ ions (species2)
and then positions four times the number of electrons with the same
profile. The elements of the species block are\\

{\emphtext rho} - Particle number density in $m^{-3}$. Despite the name, this
is NOT the mass density. As soon as a rho= line has been parsed, the values are
calculated for the whole domain and are available for reuse on the right hand
side of an expression. This is seen in the above example in the first two lines
for species2, where the density is first set and then corrected.\\

{\emphtext temp\_\{x,y,z\}} - The temperature in each direction for a thermal
distribution in K. To specify a temperature in ev, simply use the deck
parser. So for example temp\_x=4*kev*kb gives a 4kev temperature.\\

{\emphtext temp} - Sets an isotropic temperature distribution in K. Does not
give thermal distribution in ignorable directions. If both temp and a specific
temp\_x, temp\_y, temp\_z parameter is specified then the last to appear in the
deck has precedence.\\

{\emphtext minrho} - Minimum particle number density in $m^{-3}$. When the
number density in a cell falls below minrho the autoloader does not load any
pseudoparticles into that cell to minimize the number of low weight,
unimportant particles. If set to 0 then all cells are loaded with particles.

{\emphtext maxrho} - Maximum particle number density in $m^{-3}$. When the
number density in a cell rises above maxrho the autoloader clips the density to
maxrho allowing easy implementation of exponential rises to plataeus.

{\emphtext drift\_\{x,y,z\}} - Specifies a momentum space offset in kgms-2 to
the distibution function for this species. At present the drift\_\{x,y,z\}
parameter CANNOT vary in space and is just a single constant.
\pagebreak

\subsubsection{{\inlineemph species\_external\inlinecode{n}} block}
\boxverbatim{species\_external{\it n} block}
begin:species_external2
   rho=Data/ic.dat
   offset=80000
   temp_x=Data/ic.dat
end:species_external2
\end{Verbatim}

The penultimate type of block in the initial conditions deck is the
species\_external\inlinecode{n} block. It is very similar to the ic.deck
{\inlineemph species\inlinecode{n}} block, but instead of specifying the
initial conditions mathematically in the input deck, you specify the filename
of a simple binary file containing the information required. The use of this
block is very simple and is shown in the example above.\\

All the elements which exist in the simple {\inlineemph species\inlinecode{n}}
block also exist in the {\inlineemph species\_external\inlinecode{n}} block,
and the value on the right hand side should be the filename which holds the
data wanted. An additional element is also introduced, the offset element which
is the offset in bytes from which the start of the file where the data should
be read from. As a given line in the block executes, the file is opened, the
file handle is moved to the point specified by the offset parameter, the data
is read and the file is then closed. Therefore, unless the offset value is
changed between data reading lines the same data will be read into all the
variables. The data is read in as soon as a line is executed, and so it is
perfectly possible to load data from a file with the {\inlineemph
species\_external\inlinecode{n}} block and then modify the data with a
{\inlineemph species\inlinecode{n}} block.\\

The file should be a simple binary file consisting of floating point numbers of
the same precision as \inlinecode{\_num} in the core \EPOCH code.\\

{ \emphtext NOTE: The files that are expected by this block are SIMPLE BINARY
files, NOT Fortran unformatted files. It is possible to read Fortran
unformatted files using the offset element, but care must be taken!}\\

\subsubsection{{\inlineemph fields} block}
\boxverbatim{fields block}
begin:fields
   ex=sin(pi*x/lengthx)
   ey=cos(pi*x/lengthx)
   ez=0
   bx=1.0
   by=-1.0
   bz=0
end:fields
\end{Verbatim}

The final type of block in the EPOCH input deck is the fields block. This
allows you to specify the electric and magnetic fields at any point in the
domain. Once again, this is a very simple block needing only limited
explanation. All field variables are accessible by name and can be read back
using the appropriate commands from the maths parser. \\

Any valid maths parser expression can be used to set up the fields, and no
check is made to ensure that the solenoidal condition is satisfied (as can be
seen in the above example)\\

\pagebreak

\subsection{Moving to EPOCH2D and EPOCH3D}
EPOCH1D is the simplest version of \EPOCH and, although feature complete, lacks
many of the elements which are required for multidimensional operation. These
elements are mainly small modifications to the concepts already introduced in
EPOCH1D but are significant enough to need at least some discussion.\\

The higher dimension versions of the code go by the uninspired names of EPOCH2D
and EPOCH3D. Most of the input decks are equivalent to those already covered in
EPOCH1D, with a few added elements for setting the number of grid points in the
additional dimensions, setting the start and end points for the axes in the new
dimensions, and setting boundary conditions on the new boundaries. These will
be covered in more detail over the next few pages.\\

The laser blocks become slight more complicated by the addition of spatial
profiles for the laser front, and the addition of the ability to have spatially
dependent phase profiles across the laser front. This will be covered later in
this document.\\

The data loading routines are identical to those for EPOCH1D, although
obviously new routines are required to actually visualise 2D and 3D data. 2D
and 3D data is much larger than 1D, and a much larger number of particles are
required to adequately resolve the physics in multidimensional simulation so
the data files generated by higher dimensionality versions of EPOCH will be
much larger, which makes the more advanced IO routines available in \EPOCH more
useful. These will the next elements to be covered.\\

\subsubsection{Changes to the {\inlineemph control} block}

\boxverbatim{Changed control block}
begin:control
   .
   .
   ny=200
   nz=200
   .
   y_start=-10e-6
   y_end=10e-6
   z_start=-10e-6
   z_end=10e-6
   .
   .
end:control
\end{Verbatim}

The modified control block in EPOCH2D and 3D is very similar to the control
block already introduced for EPOCH1D. All that is added are new elements
describing the number of gridpoints in y and z ({\inlineemph ny \& nz}), and
new start and end lines for the length of the domain in the new directions
({\inlineemph y\_start -> y\_end} \& {\inlineemph z\_start -> z\_end}). These
operate in exactly the same way as those already introduced with EPOCH1D,
although care must be taken to increase the number of particles to ensure that
the number of particles per cell remains high enough to accuratly resolve the
distribution function.\\

Also note that the amount of memory required for multidimensional simulations
will generally be hundreds of times larger than that required for 1D
simulations.\\

\subsubsection{Changes to the {\inlineemph boundaries} block}

\boxverbatim{Changed boundaries block}
begin:boundaries
   .
   .
   ybc_up=periodic
   ybc_down=periodic
   zbc_front=simple_outflow
   zbc_back=simple_laser
end:boundaries
\end{Verbatim}

The modified boundary block includes new boundary conditions for the additional
boundaries that are introduced in higher dimensions. These available boundaries
are exactly the same as in 1D, with the additional boundaries being:\\

{\inlineemph ybc\_up}    - top of domain\\
{\inlineemph ybc\_down}  - bottom of domain\\
{\inlineemph zbc\_front} - front of domain\\
{\inlineemph zbc\_back}  - back of domain\\

These are equivalent to the existing 1D simulations except that the moving
window always moves parallel to the x-axis when activated.\\ This concludes all
the modifications to input.deck that are required to use \EPOCH in multiple
dimensions. There are some modifications that are required to allow
multidimensional initial conditions, but a surprising number of initial
conditions are in fact 1D even when running in multi-dimensional versions of
\EPOCH. The next few pages cover the modifications to the initial conditions
file which are needed for true multidimensional initial conditions with
examples.

\subsubsection{Multidimensional initial conditions}

The basic modification to the EPOCH initial conditions deck is the addition of
the new variables describing positions and length in the new directions. The
names of these variables are given in the full manual and will be used without
introduction here.

A very simple problem to set up using EPOCH 2D is a Gaussian blob which is
shown in Figure \ref{gaussblob}, in the form both of the ic.deck needed to
create it and the output from VisIT that is produced from running this deck.

In Figure \ref{gaussblobinverse}, a very small modification to this initial
conditions deck is shown which creates the a case with a Gaussian density
minimum at the centre. This makes it clear that multidimensional initial
conditions are only a little more complex than 1D initial conditions, but at
present these are not very interesting initial conditions.

The next page extends this example to a more useful initial condition.

\scaledcapimage{./images/gaussic.eps}{gaussblob}{A Gaussian density blob at the
centre of the domain.}{0.4}

\begin{minipage}{\textwidth}
\boxverbatim{species block to set up Gaussian density blob}
begin:constant
   width=2.5e-6 #2.5 microns
end:constant

begin:deo
   r=sqrt(x^2+y^2)
end:deo

begin:species1
   rho=1.0e19 * gauss(r,0.0,width)
end:species1
\end{Verbatim}
\end{minipage}

\scaledcapimage{./images/invgaussic.eps}{inversegaussblob}{A Gaussian density
defecit at the centre of the domain.}{0.4}

\begin{minipage}{\textwidth}
\boxverbatim{species block to set up Gaussian density blob}
begin:constant
   width=2.5e-6 #2.5 microns
end:constant

begin:deo
   r=sqrt(x^2+y^2)
end:deo

begin:species1
   rho=1.0e19 * (1.0-gauss(r,0.0,width))
end:species1
\end{Verbatim}
\end{minipage}

\pagebreak

\subsubsection{{\inlineemph laser} blocks in multiple dimensions.}

\scaledcapimage{./images/profile_flat.eps}{flatlaser}{Constant laser
profile}{0.4} \scaledcapimage{./images/profile_gauss.eps}{gausslaser}{Gaussian
laser profile}{0.4}
\scaledcapimage{./images/profile_diff_gauss.eps}{diffgausslaser}{Differential
Gaussian laser profile}{0.4}

The laser block already introduced in the EPOCH1D handouts are still present in
2D and 3D, but have one additional feature and a modification to one existing
feature. The new feature is {\inlineemph profile} which is defined
by\\

{\emphtext profile} - The spatial profile for the laser. This is
essentially an array defined along the edge (or surface) that the laser is
attached to. It is clear that the spatial profile is only meaningful
perpendicular to the laser�s direction of travel and so it simply does not
exist in 1D. The laser profile is evaulated while the initial conditions deck
is evaluated and so cannot include any temporal information which must be
encoded in {\inlineemph t\_profile}.  The spatial profile is evaluated at the
boundary where the laser is attached and so only spatial information in the
plane of the boundary is significant. This is most clearly explained through a
few examples. In these examples the spatial profile of the laser is set to vary
between a flat uniform profile ({\inlineemph profile=1}), a Gaussian profile in
y ({\inlineemph profile=gauss(y,0,2.5e-6)}) and a differentiated Gaussian
profile in y ({\inlineemph profile=(y/2.5e-6) * gauss(y,0,2.5e-6)}). The
difference between these profiles is obvious but the important point is that a
laser travelling parallel to the x-direction has a profile in the y
direction. Similarly a laser progagating in the y-direction has a profile in
the x direction. In 3D this is extended so that a laser propagating in a
direction has a profile in both other directions. So a laser travelling
parallel to the x axis in 3D would have a profile in y and z. Since 3D lasers
are very similar to 2D lasers, they will not be considered here in greater
detail, but in 3D, it is possible to freely specify the laser profile across
the entire face where a laser is attached.\\

The modified parameter in
multidimensional lasers is the phase parameter which is also modified to have
be spatially dependent. This allows a user to add a laser travelling at an
angle to a boundary although no examples of this will be given. It is not
currently possible to automatically link lasers on two boundaries to allow a
laser to propagate in from a corner.\\

\pagebreak

\subsubsection{Extended IO}

\boxverbatim{dist\_fn block}
begin:dist_fn
   name=x_px
   ndims=2
   dumpmask=always

   direction1=dir_x
   direction2=dir_px

   #range is ignored for spatial coordinates
   range1=1>1
   range2=-50.0e-20>50.0e-20

   #resolution is ignored for spatial coordinates
   resolution1=1
   resolution2=5000

   include_species_1=F
   include_species_2=T
   include_species_3=T
end:dist_fn
\end{Verbatim}

One way of considering the PIC methodology is based on the idea of using the
simulation pseudo-particles as Monte-Carlo sampling points of the phase space
of Vlasov�s equation. While direct simulation of Vlasov�s equation leads to
much lower noise then using this Monte-Carlo approach it is much more
computationally expensive and is currently only just possible in 2D and
completely impossible in 3D. However, sometimes it is useful to be able to
reconstruct at least some of the phase space for one or more particle species,
and this option is provided through an extended IO option.  The distribution
function is integrated over all dimensions which are not axes of the
distribution function.\\

When extended IO is turned on in the output block of input.deck it allows a
user to specify an additional input deck file which contains information about
setting up additional diagnostics including phase space reconstructions. It is
possible to set up as many 2D and 3D distribution functions as required by
simply specifying multiple {\inlineemph dist\_fn} blocks. The layout of these
blocks is as follows:\\

{\emphtext name} - The name of the distribution function when it is
output. This name is appended with the name of each species for which the data
is output and so in the output this block when applied to a species named
carbon is called for example {\inlineemph x\_px\_carbon}. The Cartesian grid
which describes the axes of the distribution function would then be called
{\inlineemph grid\_x\_px\_carbon}.\\

{\emphtext ndims} - The number of dimensions in this phase space
reconstruction. Due to difficulties in visualising data in more than three
dimensions, this is restricted to being either 2 or 3.\\

{\emphtext dumpmask} - At which type of output should this distribution
function should be dumped. Whether or not the distribution function is actually
dumped is defined by the more restrictive or this parameter and the setting for
distribution functions in the output section of input.deck.\\

{\emphtext direction\inlinecode{n}} - This is a code representing the direction
which is calculated to run along axis \inlinecode{n}. This can be any one of:
dir\_x, dir\_y, dir\_z, dir\_px, dir\_py, dir\_pz, with spatial codes only
being available in dimensionalities of the code which have that
direction. Therefore dir\_z does not exist in EPOCH1D or EPOCH2D.\\

{\emphtext range\inlinecode{n}} - The range between which this axis should
run. This is in the form of minimum$>$maximum at present although this is a
slightly inelegant notation which may change. The rangen parameter is ignored
when a direction is a spatial direction since all spatial directions run over
the whole domain. For momentum directions this parameter is specified in
$kgms^{-2}$. If the range of a momentum direction is set so that the maximum
and the minimum are both zero then the code will automatically set the range to
exactly span the range of particle momenta at the point of writing the dump.\\

{\emphtext NOTE: Currently the range parameters have to be simple floating
point number, NOT maths parser expressions.}

{\emphtext resolution\inlinecode{n}} - The number of gridpoints in a given
direction. Once again this is ignored for spatial dimensions where the
resolution is always the same as the resolution of the underlying simulation.

{\emphtext include\_species\_\inlinecode{n}} - Logical flag indicating whether
the species defined in input.deck as species number n should be included in the
output. This is useful since it is rare that momentum limits are appropriate
for both electrons and ions so usually for a given dist\_fn block only
electrons or ions are considered. It is possible to have two dist\_fn blocks
with the same name but different momentum ranges and different
include\_species\_n settings to produce the effect of a single diagnostic for
all species in the output file.\\

{\emphtext NOTE: If using multiple dist\_fn blocks with the same name MAKE SURE
that the same species is not included in both blocks, since the data for both
would be written but only the first block would be available in the reader
routines.}\\

There are a few additional commands which are less commonly used by can be
useful in some circumstances. These commands allow a user to restrict which
particles should be included in the integration over directions which are not
axes of the distribution function. It allows the user to specify maximum and
minimum values for each spatial and momentum direction and use particles which
fall within this range when calculating the distribution function. The
restrictions are specified in the same minimum$>$maximum form as ranges. These
commands are:\\

{\emphtext restrict\_\{x,y,z\}} - Restricts over spatial dimensions. Only
spatial dimensions which exist in the code being run are available. Therefore,
attempting to set restrict\_z in EPOCH1D will produce a warning.\\

{\emphtext restrict\_p\{x,y,z\}} - Restricts over momentum directions. All
momentum directions exist in all versions of the code, so it is possible to set
restrictions in any momentum dimension in any dimensionality of the code.

{\emphtext NOTE: It is possible to restrict in dimensions which are included in
the distribution function and these restrictions are honoured. This means that
there will be empty sections of the distribution function plot.}


\pagebreak

\subsection{Basic examples of using \EPOCH}

\subsubsection{Electron two stream instability}

An obvious simple test problem to do with \EPOCH is the electron two stream
instability. An example of a nice dramatic two stream instability can be
obtained using EPOCH1D by setting the code with the following input deck
files.\\

\boxverbatim{input.deck}
begin:control
   #global number of gridpoints
   nx=400 #in x
   npart=3200

   #maximum number of iterations
   #set to -1 to run until finished
   nsteps=-1

   #final time of simulation
   t_end=1.5e-1

   #size of domain
   x_start=0
   x_end=5.0e5

   #Don't know if this should be in the deck or not
   dt_multiplier=0.9

   dlb=F
   dlb_threshold=1.0

   initial_conditions=external
   icfile=ic.deck
   restart_snapshot=98

   #Setting neutral_background to F makes the code solve
   #Poisson's equation for the initial electric field
   #Setting it to T makes the initial electric field 0
   neutral_background=T
end:control

begin:boundaries
   xbc_left=periodic
   xbc_right=periodic
end:boundaries

begin:species
   n_species=2

   #Rightwards travelling electrons
   charge1=-1
   mass1=1.0
   frac1=0.5
   name1=Right
   dump1=T

   #Leftwards travelling electrons
   charge2=-1
   mass2=1.0
   frac2=0.5
   name2=Left
   dump2=T
end:species

begin:output
   #If use_offset_grid is true then the code dumps a
   #grid which displays positions relative to the
   #Left hand edge of the window
   use_offset_grid=F
   #number of timesteps between output dumps
   dt_snapshot=1.5e-3
   #Number of dt_snapshot between full dumps
   full_dump_every=1
   restart_dump_every=-1
   force_final_to_be_restartable=T

   use_extended_io=F

   #Properties at particle positions
   particles=always
   px=always
   py=never
   pz=never
   vx=never
   vy=never
   vz=never
   charge=never
   mass=never
   particle_weight=never
   species_id=always

   #Properties on grid
   grid=always
   ex=always
   ey=always
   ez=always
   bx=always
   by=always
   bz=always
   jx=always
   jy=never
   jz=never
   ekbar=always
   mass_density=never + species
   charge_density=never
   number_density=always + species
   temperature=never
end:output
\end{Verbatim}

\boxverbatim{ic.deck}
begin:constant
   drift_p=2.5e-24
   temp=273
   dens=10
end:constant

begin:species1
   temp_x=temp
   drift_x=drift_p
   rho=dens
end:species1

begin:species2
   temp_x=temp
   drift_x=-drift_p
   rho=dens
end:species2
\end{Verbatim}

\captionedimage{./images/late.eps}{tsilate}{The final state of the electron
phase space for the two stream instability example.}

While the {\inlineemph input.deck} file is rather long, most of it is the basic
standard input deck that is supplied with \EPOCH, with only the length of the
domain, the final time and the time between snapshots specific to this
problem. {\inlineemph ic.deck} the initial conditions file is very simple
indeed. The first block sets up constants for the momentum space drift, the
temperature and the electron number density. The second and third blocks set up
the two drifting Maxwellian distributions and the constant density profile. The
output from this example is best visualised in IDL using the command\\
\inlinecode{plot,data.particles.particlepositions,data.px,psym=3}\\ which
should produce a figure that looks like Figure\ref{tsilate}.

\subsubsection{Structured density profile in EPOCH2D}
A simple but useful example for EPOCH2D is to have a highly structured initial
condition to show that this is still easy to implement in EPOCH. A good example
initial condition would be\\

\boxverbatim{ic.deck}
begin:constant
  den_peak=1.0e19
end:constant

begin:species2
  rho=den_peak*(sin(4.0*pi*x/lengthx+pi/4))*(sin(8.0*pi*y/lengthy)+1)
  minrho=0.1*den_peak
end:species2

begin:species1
  rho=rho(2)
  minrho=0.1*den_peak
end:species1
\end{Verbatim}

Although not included here the input deck associated with these initial
conditions sets {\inlineemph species1} to be electrons and {\inlineemph
species2} to be protons. There species block for {\inlineemph species2} is set
first to set up the ion density to be a highly structured 2D sinusoidal
profile. The species block for {\inlineemph species1} is then set up to simply
match the density of {\inlineemph species2} to produce charge neutrality. On
it's own this initial condition does nothing and so only needs to run for 0
timesteps({\inlineemph nsteps=0} in input.deck). The resulting electron number
density should look like Figure \ref{complexdensity}


\scaledcapimage{./images/shapetest.eps}{densitycomplex}{Complex 2D density
structure}{0.4}

\subsubsection{A hollow cone in 3D}
A more useful example of an initial condition is to create a hollow cone. This
is easy to do in both 2D and 3D, but is presented here in 3D form.\\

\boxverbatim{ic.deck}
begin:constants
   den_cone=1.0e22
end:constants

begin:deo
   ri=abs(x-5.0e-6)
   ro=ri+1.0e-6
   r=sqrt(y^2+z^2)
end:deo

begin:species2
   rho=if(r gt ri) and(r lt ro),den_cone,0.0)
   rho=if((x gt 3.0e-6) and (x lt 4.0e-6) and (r lt ri),den_cone,rho(2))
   rho=if(x gt 4e-6,0.0,rho(2))
end:species2

begin:species1
   rho=rho(2) * 22.0
end:species1
\end{Verbatim}

To convert this to 2D, simply replace the line \inlinecode{r=sqrt(y\^2+z\^2)}
with the line \inlinecode{r=abs(y)}. The actual work in these initial
conditions is done by the three lines inside the block for {\inlineemph
species2}. Each of these lines performs a very specific function, with those
functions being

\begin{enumerate}
\item Creates the outer cone. Simply tests whether \inlinecode{r} is within
  the range of radii which corresponds to the thickness of the cone and if so
  fills it with density. Since the inner radius is x dependent this produces a
  cone rather than a cylinder. On it's own, this line produces a pair of cones
  joined at the tip.
\item Creates the solid tip of the cone. This line just tests whether the
  point in space is within the outer radius of the cone and within a given
  range in x, and fills it with density if true.
\item Cuts off all of the cone beyond the solid tip. Simply tests if x is
  greater than the end of the cone tip and sets the density to zero if so.
\end{enumerate}

\scaledcapimage{./images/3dcone.eps}{3dcone}{Cone initial conditions in 3D}{0.4}
\scaledcapimage{./images/2dcone.eps}{2dcone}{Cone initial conditions in 2D}{0.4}

This deck produces and initial condition which looks like Figure \ref{3dcone}
and Figure \ref{2dcone} in 3D and 2D respectively.
\pagebreak

\section{\EPOCH core algorithm}
\scaledcapimage{./images/coreblock.eps}{coreblock}{Block diagram of the core
routines in \EPOCH}{0.5}
EPOCH CORE ALGORITHM GOES HERE.

\pagebreak

\section{\EPOCH for end users}

\subsection{Structure of the \EPOCH codes}
When obtained, the \EPOCH codes all have a similar structure. Inside the
epoch{n}d directory, there are 4 subdirectories

\begin{itemize}
\item src - The \EPOCH source code
\item IDL - The IDL routines needed to open the Compact Flexible Datatype
  (CFD) files which the code outputs
\item VisIT - The files for creating a plugin for the LLNL VisIT parallel
  visualisation tool for reading CFD files
\item Data - A sample data directory containing example input deck files
\end{itemize}
there are also 8 files

\begin{itemize}
\item cleandir - A script which deletes the output files generated by the
  \EPOCH code from an output directory while leaving the input files needed to
  run the code
\item copydir - A script which copies the input files used by \EPOCH from one
  directory to another without copying any of the output files
\item deck.file - An example file showing how to run the code without user
  interaction. It will be explained in more depth later
\item \EPOCH.pbs - An example PBS batch submission script showing how to use
  the code in a parallel environment. In general, it probably will not be
  suitable for your particular machine, please consult the documentation for
  the facility that you are working on.
\item Makefile - A standard makefile
\item pack\_for\_transport - A script which is used in the event of bug
  reporting. pack\_for\_transport packs up all the relevant parts of a
  standard \EPOCH installation into a single tgz file. The file is then sent
  when reporting the bug.
\item Start.pro - An IDL script which starts the IDL visualisation
  routines. Execute it using ``idl Start''
\end{itemize}

\subsection{Libraries and requirements}
The \EPOCH codes are written using MPI for parallelism, but have no other
libraries or dependencies. Currently, the codes are written to only require and
MPI1.2 compatible compiler, although this may change to require full MPI2
compliance in the future. Current versions of both MPICH and OpenMPI are full
MPI2 implementations and are known to work with this code. The SCALI MPI
implementation is only a full MPI1.2 implementation and may loose support
soon.\\

It is not possible to rewrite the code to remove the dependancy on the MPI
libraries without a massive rewrite, which there are no plans to perform.

The code is supplied with a standard GNU make makefile, which is also
compatible with most other forms of the {\bf make} utility. In theory it is
possible to compile the code without a {\bf make} utility, but it is much
easier to compile the code using the supplied makefile.

\subsection{Compiling and running \EPOCH}

To compile \EPOCH in the supplied state, just type\\
\inlinecode{make}\\
and the code will compile. There are certain options within the code which are
controlled by compiler pre-processors which are described in the next
section. When the code is compiled, it creates a new directory called ``bin''
which contains the compiled binary which will be called \inlinecode{epoch1d},
\inlinecode{epoch2d} or \inlinecode{epoch3d}. To run the code, just execute the
binary file by typing\\
\inlinecode{./bin/epoch2d}\\
or whatever the correct binary is for the dimensionality of the code that you
have. You should be given a screen which begins with the \EPOCH logo, and then
reads\\

\simpleboxverbatim

Welcome to EPOCH2D Version 1.3

 The code was compiled with the following compile time options
 *************************************************************
 Per particle weighting -DPER_PARTICLE_WEIGHT
 Tracer particle support -DTRACER_PARTICLES
 Particle probe support -DPARTICLE_PROBES
 Particle ionisation model -DPART_IONISE
 *************************************************************

 Specify output directory

\end{Verbatim}

At this point, the user simply types in the name of the (already existing)
output directory and the code will read the input deck files inside the
specified directory and start running. To run the code in parallel, just use
the normal mpirun or mpiexec scripts supplied by your MPI implementation. If
you want the code to run unattended, then you will need to specify the output
directory by piping the directory name in from a file. An example of such a
file is supplied as ``deck.file'' with the standard distribution of \EPOCH. To
use it, just run the code as\\
\inlinecode{mpirun -np 2 ./bin/epoch2d < deck.file}\\
and the code will run without user input. Some cluster queuing systems do not
allow the use of input pipes to mpirun. In this case, there is usually a
``-stdin'' command line option to specify an input file, see your cluster
documentation for more details.

\subsection{Compiler flags and pre-processor defines}
As already stated, some features of the code are controlled by compiler
pre-processor directives. The flags for these pre-processor directives are
specified in ``Makefile'' and are placed on the line which reads\\
\simpleboxverbatim
DEFINES = -DPER_PARTICLE_WEIGHT
\end{Verbatim}
To turn on the effect given by a given preprocessor directive, just add the
command \inlinecode{-D\{directive\}} to the \inlinecode{DEFINES} line. The
options currently controlled by the preprocessors are\\
\begin{itemize}
\item PER\_PARTICLE\_WEIGHT - Instead of running the code where each
  pseudoparticle represents the same number of real particles, each
  pseudoparticle can represent a different number of real particles. Many of
  the codes more advanced features require this and it is turned on by
  default. It can be turned off to save on memory, but this is recommended
  only for advanced users.
\item PARTICLE\_CELL\_DIVISION - After the code has updated the particle
  positions, it splits the particles into seperate lists for each grid
  cell. Some features of the code (like collision operators) require this
  feature to be on, but it is off by default
\item PARTICLE\_DEBUG - Each particle is additionally tagged with information
  about which processor it is currently on, and which processor it starts
  on. This is a debug mode for code development
\item FIELD\_DEBUG - The code also outputs information about where the
  processor boundaries are in space. This is a debug mode for code development
\item PARTICLE\_IONISE - Activate the particle ionisation code (BETA)
\item PARTICLE\_COUNT\_UPDATE - Makes the code keep global particle counts for
  each species on each processor. This information isn't needed by the core
  algorithm, but can be useful for developing some types of additional physics
  packages. It does require one additional MPI\_ALL\_REDUCE per species per
  timestep, so it is not activated by default.
\item TRACER\_PARTICLES - Gives the option to specify one or more species as
  tracer particles. Tracer particles are specified like normal particles, and
  move about as would a normal particle with the same charge and mass, but
  tracer particles do not generate any current and are therefore passive
  elements in the simulation. Any attempt to add particle collision effects
  should remember that tracer species should not interact through collisions.
\item PARTICLE\_PROBES - For laser plasma interaction studies it can sometimes
  be useful to be able to record information about particles which cross a
  plane in the simulation. Since this requires the code to check whether each
  particles has crossed the plane in the particles pusher and also to store
  copies of particles until the next output dump, it is a heavyweight
  diagnostic. Therefore, this diagnostic is only enabled when the code is
  compiled with this directive.
\item NO\_DECK - When developing the code, it is sometimes more convenient to
  deactivate the input deck support and run the code with all variables
  specified internally to the code. This input deck option turns off the deck
  parser and calls internal routines to set the same variables. NB - It is NOT
  ACCEPTABLE to develop an extension to the code which requires the code to be
  run in this mode. An input deck parser MUST be written for any released
  extension to \EPOCH.
\item SPLINE\_FOUR - Swap the code from a 2nd order cloud in cell PIC code to
  using 4th order spline particle shape functions.
\end{itemize}

So to turn on per particle weighting and particle debugging, the line would
look like\\
\simpleboxverbatim
DEFINES = -DPER_PARTICLE_WEIGHT -DPARTICLE_DEBUG
\end{Verbatim}

If a user requests an option which the code has not been compiled to support
then the code will give an error message as follows
\simpleboxverbatim
 ***ERROR*** The element particle_probes of block output
  cannot be set because the code has not been compiled with the correct preproce
 ssor options.
 Code will continue, but to use selected features, please recompile with
 -DPARTICLE_PROBES option
\end{Verbatim}

It is also possible to pass other flags to the compiler. In "Makefile" there is
a line which reads\\
\inlinecode{FFLAGS = -O3 -fast}\\
the two commands to the right are compiler flags and are passed unaltered to
the fortran compiler. Change this line to add any additional flags required by
your compiler.

\subsection{The \EPOCH input deck}
The input deck files are the files which describe the setup of the code and
include almost all the controlable parameters for the code. The input deck is
contained in a file called ``input.deck'' which must be present in the output
directory that is given to the code at runtime. The input deck is a structured
file which is split into separate blocks, with each block containing several
``parameter''=''value'' pairs. The pairs can be present in any order, and not
all possible pairs must be present in any given input deck. If a required pair
is missing the code will fail. The input deck is case sensitive, so true is
always ``T'', false is always ``F'' and the names of the parameters are always
lower case.\\

There are three {\it input deck directive} commands, which are
\begin{itemize}
\item begin:{\it block} - Begin the block named {\it block}
\item end:{\it block} - Ends the block names {\it block}
\item include:{\it filename} - Includes another file (called {\it filename})
  into the input deck at the point where the directive is encountered. The
  input deck parser reads the included file exactly as if the contents of the
  included file were pasted directly at the position of the include directive.
\end{itemize}
Each block must be surrounded by valid {\it begin:} and {\it end:} directives
or the input deck will fail. There are currently five valid blocks hard coded
into the input deck reader, but it is possible for end users to extend the
input deck. If the input deck has been extended then you must contact the
writer of the extension for assistance. The five built in blocks are
\begin{itemize}
\item control - Contains information about the general code setup
\item boundaries - Contains information about the boundary conditions for this
  run
\item species - Contains information about the species of particles which are
  used in the code
\item output - Contains information about when and how to dump output files
\item window - Contains information about the moving window if the code is
  used in that fashion.
\end{itemize}

\subsubsection{The control block}
The control block of a valid input deck for EPOCH2D reads as follows\\
\simpleboxverbatim
begin:control
   #global number of gridpoints
   nx=512 #in x
   ny=512 #in y
   #global number of particles
   npart=1000000

   #maximum number of iterations
   #set to -1 to run until finished
   nsteps=-1

   #final time of simulation
   t_end=1.0e-12

   #size of domain
   x_start=-0.1e-6
   x_end=400.0e-6
   y_start=-400.0e-6
   y_end=400.0e-6

   #Don't know if this should be in the deck or not
   dt_multiplier=0.8

   #dynamic load balancing
   dlb=F
   dlb_threshold=1.0

   initial_conditions=external
   icfile=ic.deck
   restart_snapshot=76

   #Setting neutral_background to F makes the code solve
   #Poisson's equation for the initial electric field
   #Setting it to T makes the initial electric field 0
   neutral_background=T
end:control
\end{Verbatim}

Most of the control block is self explanatory, but there are three parts which
need further description. \\
``dlb'' stands for Dynamic Load Balancing, and when turned on, it allows the
code to rearrange the internal domain boundaries to try and balance the
workload on each processor. This rearrangement is an expensive operation, so
it only performed when the maximum load imbalance reaches a given critical
point. This critical point is given by the parameter ``dlb\_threshold'' which
is the ratio of the workload on the least loaded processor to the most loaded
processor. When the calculated load imbalance is less than ``dlb\_threshold''
the code performs a rebalancing sweep, so if ``dlb\_threshold=1.0'' is set
then the code will keep trying the rebalance the workload at almost every
timestep. At present the workload on each processor is simply calculated from
the number of particles on each processor, but this will probably change in
future.\\
``initial\_conditions'' is a parameter which tells the code how to set up the
initial conditions for the code. The \EPOCH initial conditions is split up
into five parts. The five parts are
\begin{itemize}
\item manual - The manual load section allows the end user full access to all
  particle properties, allowing the introduction of non-thermal particle
  distributions.
\item restart - Restart from a previous output file. If this is specified then
  the ``restart\_snapshot'' parameter must be set to the output dump number to
  restart from.
\item internal\_early - Internal (in source code) setting of autoloader
  properties before reading of initial conditions deck file
\item external - Setting of autoloader properties from an external initial
  conditions deck file. This allows changing run conditions without having to
  recompile the code. If this is specified then the parameter ``icfile'' must
  be set to the file which contains the inital conditions.
\item internal\_late - Internal (in source code) setting of autoloader
  properties after reading of initial conditions deck file
\end{itemize}
The ``initial\_conditions'' parameter is therefore some combination of these
options (exactly how you use them is specified in the next section). The
options are combined by addition, so if you want to use the internal\_early,
external and manual initial conditions, then set\\
\inlinecode{initial\_conditions = internal\_early + external + manual}\\

Finally, ``neutral\_background'' is a parameter which changes the initial
behaviour of the code. If ``neutral\_background'' is set to T then the code
assumes that there exists sufficient particles to mean the initial condition
has an electric field of exactly zero. This is appropriate when the number of
real particles per pseudoparticle is very large, meaning that the electric
fields due to the pseudoparticles will be artificially large. Setting
``neutral\_background'' to F means that the code will solve Poisson's equation
for the initial conditions, leading to a finite electric field at t=0. This is
appropriate when the number of real particles per pseudoparticle is small, or
when the initial conditions include a region which has a charge excess or
depletion at t=0.\\

\subsubsection{The boundaries block}
The next section of the input deck describes the boundary conditions. The
boundaries block for EPOCH3D is as follows\\
\simpleboxverbatim
begin:boundaries
   xbc_left=other
   xbc_right=other
   ybc_up=periodic
   ybc_down=periodic
   zbc_front=other
   zbc_back=other
end:boundaries
\end{Verbatim}

This block is fairly self explanatory and describes the boundary conditions
applied to each of the 6 faces of the cuboid which represents the extents of
the simulation. In lower dimensions, only xbc\_ or only xbc\_ and ybc\_
appear. The possible boundary conditions are\\
\begin{itemize}
\item periodic - Particles and fields crossing this boundary wrap back round
  to the opposite boundary. If either boundary condition is set to periodic
  then the boundary condition on the matching boundary at the other side of
  the box is also assumed periodic
\item other - Particles are perfectly reflected from this boundary
  type. Electric and magnetic fields are clamped to zero at the boundary
\item simple\_laser - Particles and outwardly propagating EM waves travel
  through the boundary. One or more inwardly propagating EM wave sources may
  be specified either in the input deck or in the inital conditions section.
\item simple\_outflow - Particles and outwardly propagating EM waves travel
  through the boundary. It is not possible to attach a wave source to this
  type of boundary, which makes is simpler and faster than simple\_laser.
\end{itemize}
Other boundary types will appear as the code matures probably including laser
driven boundaries and absorbing boundaries.\\

\subsubsection{The species block}
The next section of the input deck describes the particles species used in the
code. An example species block for any \EPOCH code is given below\\
\simpleboxverbatim
begin:species
   n_species=2

   #H+ ions
   charge1=1.0
   mass1=1800.0
   frac1=0.5
   name1=Proton
   dump1=T

   #electrons
   charge2=-1.0
   mass2=1.0
   frac2=0.5
   name2=Electron
   dump2=T
end:species
\end{Verbatim}

The species block is slight more complex than preceeding blocks in that the
amount of information in a block depends upon information in the block. While
for most input deck blocks the structure is completely freeform, the first
thing specified in the species block must be ``n\_species'' which tells the
code how many species of particle are present in the code. After that, the
block is one again freeform, although it makes sense to keep the information
for each species together. Each species has the following data which must be
specified in the input deck\\
\begin{itemize}
\item charge - The charge on the particle in units of the electron charge
\item mass - The mass of the particle in units of the electron mass
\item frac - The fraction of the total number of particles in the simulation
  which are of this species
\item name - The name of this particle species (this appears in the output
  dumps)
\item dump - Whether or not to dump this particle species in normal outputs
  (this is ignored for restart dumps when enough information is dumped to
  restart the code)
\item npart - This can be used instead of \inlinecode{frac} to explicitly set
  the number of particles for a species. If this element is set then the code
  effectively ignores the values of \inlinecode{npart} set in the control
  block.
\item tracer - If the code is compiled with tracer particle support then
  setting this logical element to "\inlinecode{T}" makes the code treat this
  species as a tracer species. Tracer species have the correct charge and mass
  but do not contribute any current.
\end{itemize}

The particle species which a given property refers to is simply set by a
number after the property name, starting with 1 for the first species and
ending at n\_species for the final species. A final note : if the values of
frac for all species don't add up to one then there will be some particles
requested which are never assigned a species. These particles are destroyed
before the code runs to save memory and compute time, but it means that the
number of particles in the simulation will be lower than expected.\\

\subsubsection{The output block}
The final section of the input deck is the output section. It describes the
data that the user wants dumped from the code and an example block from any
version of \EPOCH is given below\\
\simpleboxverbatim
begin:output
   #If use_offset_grid is true then the code dumps a
   #grid which displays positions relative to the
   #Left hand edge of the window
   use_offset_grid=T

   #number of timesteps between output dumps
   dt_snapshot=1.0e-14
   #Number of dt_snapshot between full dumps
   full_dump_every=1
   restart_dump_every=1
   force_final_to_be_restartable=T

   use_extended_io=T
   extended_io_file=io.deck

   #Properties at particle positions
   particles=full
   px=never
   py=never
   pz=never
   vx=full
   vy=full
   vz=never
   charge=full
   mass=full
   particle_weight=always
   species_id=always

   #Properties on grid
   grid=always
   ex=always
   ey=always
   ez=always
   bx=always
   by=always
   bz=always
   jx=always
   jy=always
   jz=always
   temperatures=always
   mass_density=always
   charge_density=always
end:output
\end{Verbatim}

The first set of options control the type and frequency of output dumps. They
are used as follows\\
\begin{itemize}
\item use\_offset\_grid - Causes the code to output a special grid which moves
  with a moving window if one is specified. This is needed to allow
  visualisation packages like LLNL VisIT which cannot cope with moving axes to
  work properly. If you are not using a moving window then setting this option
  to true merely wastes space as both the normal and the special grid are the
  same.
\item dt\_snapshot - Time (in internal seconds) between performing a basic
  output dump
\item full\_dump\_every - Number of basic output dumps between full output
  dumps
\item restart\_dump\_every - Number of basic output dumps between restart
  output dumps. Set to -1 or lower to not produce restart dumps
\item force\_final\_to\_be\_restartable - Whether or not the code should force
  the last output dump to be a restart dump. This ensures that it is possible
  to restart the code from the last output dump.
\item use\_extended\_io - Some forms of more advanced IO require that the
  entire of the input deck MUST have been parsed before they can be set
  up. These are termed ``extended io features'' and are specified in another
  file
\item extended\_io\_file - The file which contains the information about the
  extended io.
\end{itemize}

The remaining items control what data should be dumped at which type of
output. There are three possible values\\
\begin{itemize}
\item never - This will never be dumped unless it is a required restart
  variable in which case it will be dumped at a restart dump
\item full - Dump only at a full output dump
\item always - Dump at a basic output dump
\item species - When applied to a grid variable which can meaningfully be
  calculated on a per species level, this cause the code to dump per species
  information about that variable. This is simply added to the frequency code,
  i.e. mass\_density=always+species will cause the mass density to be output
  at every dump for each species and also globally.
\end{itemize}

The options are fairly self explanatory, but they are given in more detail
below. The first set are per particle properties which must be plotted at the
individual particle positions to make sense\\
\begin{itemize}
\item particles - Dump particle positions data
\item px, py, pz - Dump particle momentum in x, y ,z direction
\item vx, vy, vz - Dump particle velocity in x, y, z direction
\item charge - Dump particle charge
\item mass - Dump particle mass
\item particle\_weight - Dump the weight value for each particle (The weight
  is the number of real particles represented by a given pseudoparticle)
\item species\_id - Dump the species number for each particle
\end{itemize}

There are then also more variables which are defined on the underlying grid.\\
\begin{itemize}
\item grid - Dump the grid underlying the simulation
\item ex, ey, ez - Dump the electric field in x, y, z
\item bx, by, bz - Dump the magnetic field in x, y, z
\item jx, jy, jz - Dump the current in x, y, z
\item temperature - Dump the mean particle kinetic energy at each gridpoint
  for each species
\item mass\_density - Dump the mass density
\item charge\_density - Dump the charge density
\end{itemize}

\subsection{The window block}
\EPOCH can include an optional block which causes the simulation domain to
operate as a moving window. At present, it is only possible to have the window
moving at a constant speed parallel to the x direction, although the window
does not have to start moving at t=0. When the window moves, the code removes
particles from the left hand edge of the domain and introduces new particles
at the right hand edge. The code does not only reintroduce the same number of
particles at the right hand edge as are removed at the left hand edge, but
introduces new particles so that for each species the new particles have a
given number density, temperature and number of pseudoparticles per cell. It
is not currently possible to turn off the reintroduction of particles to allow
a pulse to travel into a vacuum region, although this is being developed. The
block looks like\\
\simpleboxverbatim
begin:window
   move_window=T
   window_v_x=3.0e8
   window_start_time=7.0e-13
   xbc_left_after_move=simple_outflow
   xbc_right_after_move=simple_outflow
end:window
\end{Verbatim}

\begin{itemize}
\item move\_window - Logical flag determining whether or not to move the
  window. If the window block is absent then this is the same a setting
  move\_window to F
\item window\_v\_x - The speed in m/s of the window
\item window\_start\_time - The time in seconds at which the window should
  start moving.
\item xbc\_left\_after\_move - The boundary condition which should apply to
  the left boundary after the window has started moving. This is to allow the
  swapping of a laser boundary to a simple outflow boundary. Boundary codes
  are the same as when just specifying normal boundaries. If a boundary value
  isn't specified then it is assumed that the boundary isn't changed when the
  window starts moving.
\item xbc\_right\_after\_move - The boundary condition which should apply to
  the right boundary after the window has started moving.
\end{itemize}

The basic input deck has now been considered fully, but it remains to point
out that it is possible for an end user to add new blocks to the input deck,
so a version of the code which you have obtained from a source other than
CCPForge may include other input deck blocks. These should be described in
additional documentation provided with the version of the code that you have.

\subsection{Controlling \EPOCH without using the input deck}
During development, it can sometimes be useful to control \EPOCH with all the
parameters hard coded into the source rather than fed in from an input
deck. If the code is compiled with the {\bf ``-DNO\_DECK''} preprocessor
option then the code changes to a mode where setup constants are specified in
the file {\bf control.F90}. This file has the following structure

\simpleboxverbatim
  !****************************************************
  !Equivalent to "control" block in input deck
  !****************************************************
  SUBROUTINE Setup_Control_Block

    !Number of gridpoints in x direction
    nx_global = 256

    !Number of gridpoints in y direction
    ny_global = 50

    !Number of particles of all species(at t=0)
    npart_global=8e5

    !maximum number of iterations
    !set to -1 to run until finished
    nsteps = -1
    !Final runtime of simulation in seconds (NOT walltime)
    t_end = 3.0e-12

    !size of domain
    x_start=-350.0e-6_num
    x_end=150.0e-6_num
    y_start=-50.0e-6_num
    y_end=50.0e-6_num

    !CFL multiplier
    dt_multiplier=0.8_num

    !Dynamic load balancing
    dlb=.FALSE.
    dlb_threshold=1.0_num

    !Initial conditions
    !Bitmask, combine with IOR (or addition)
    !IC_EARLY_INTERNAL
    !IC_EXTERNAL
    !IC_LATE_INTERNAL
    !IC_MANUAL
    !IC_RESTART
    ictype=IC_EARLY_INTERNAL
!!$    icfile%Value="ic.deck"
    restart_snapshot=0

    !Neutralising background
    Neutral_Background=.TRUE.

    !Setup the moving window
    move_window=.TRUE.
    window_v_x=2.8e8_num
    window_start_time=7.0e-13_num
    xbc_left_after_move=BC_SIMPLE_OUTFLOW
    xbc_right_after_move=BC_SIMPLE_OUTFLOW


  END SUBROUTINE Setup_Control_Block
  !****************************************************
  !Equivalent to "boundaries" block in input deck
  !****************************************************
  SUBROUTINE Setup_Boundaries_Block

    !Boundary values, can be
    !BC_OTHER - Reflecting boundary, easily changed
    !BC_PERIODIC - Periodic boundary
    !BC_SIMPLE_OUTFLOW - Outflow particle and wave boundary
    !BC_SIMPLE_LASER - Outflow particle and wave boundary with superimposed
    ! inward propagating laser
    xbc_left=BC_SIMPLE_LASER
    xbc_right=BC_SIMPLE_OUTFLOW
    ybc_down=BC_SIMPLE_OUTFLOW
    ybc_up=BC_SIMPLE_OUTFLOW

  END SUBROUTINE Setup_Boundaries_Block
  !****************************************************
  !Equivalent to "species" block in input deck
  !****************************************************
  SUBROUTINE Setup_Species_Block
    !Must set nSpecies before the call to Setup_Species
    nSpecies=2
    CALL Setup_Species

    !M0 is the mass of an electron
    !Q0 is the charge of an electron
    ParticleSpecies(1)%Name="Electron"
    ParticleSpecies(1)%Mass=1.0_num*M0
    ParticleSpecies(1)%Charge=-1.0_num*Q0
    ParticleSpecies(1)%Count=0.5_num * npart_global
    ParticleSpecies(1)%dump=.TRUE.

    ParticleSpecies(2)%Name="Ions"
    ParticleSpecies(2)%Mass=1836.0_num*M0
    ParticleSpecies(2)%Charge=1.0_num*Q0
    ParticleSpecies(2)%Count=0.5_num * npart_global
    ParticleSpecies(2)%dump=.TRUE.


  END SUBROUTINE Setup_Species_Block
  !****************************************************
  !Equivalent to "output" block in input deck
  !****************************************************
  SUBROUTINE Setup_Output_Block

    dt_snapshots=3.0e-14_num
    full_dump_every=1
    restart_dump_every=-1
    force_final_to_be_restartable=.TRUE.
    use_offset_grid=.TRUE.
    use_extended_io=.FALSE.

    !Dumpmask is a bitmasked variable which determines whether or not to
    !dump a given variable at a given type of output dump. The possible values are
    !IO_NEVER - Default value, never dump
    !IO_ALWAYS - Dump at every output
    !IO_FULL - Dump at only full outputs
    !IO_SPECIES - When ORed with another value, tells the code to output
    !             some additional per species information

    !The numbers for each variable are
    !1   - The particle positions
    !2   - The cartesian grid
    !3   - Particle px
    !4   - Particle py
    !5   - Particle pz
    !6   - Particle vx
    !7   - Particle vy
    !8   - Particle vz
    !9   - Ex
    !10  - Ey
    !11  - Ez
    !12  - Bx
    !13  - By
    !14  - Bz
    !15  - Jx
    !16  - Jy
    !17  - Jz
    !18  - Particle Charge
    !19  - Particle Mass
    !20  - Kinetic energy (on grid)
    !21  - Mass density (Can have IO_SPECIES)
    !22  - charge density (Can have IO_SPECIES)
    !23  - number density (Can have IO_SPECIES)
    !24  - Particle weighting value
    !25  - Particle species information

    DumpMask(2)=IO_ALWAYS
    DumpMask(9:10)=IO_ALWAYS
    DumpMask(14)=IO_ALWAYS
    DumpMask(15:16)=IO_ALWAYS
    DumpMask(20)=IO_ALWAYS
    DumpMask(21)=IOR(IO_ALWAYS,IO_SPECIES)
    DumpMask(22)=IO_ALWAYS
    DumpMask(23)=IOR(IO_ALWAYS,IO_SPECIES)

  END SUBROUTINE  Setup_Output_Block
\end{Verbatim}

It is generally fairly obvious how to swap from using the input deck to using
the control.F90 file, so no further explanation is given at present, except to
note that when developing a new part of the code, it is considered good design
practice to set it up so that it is possible to control it both from the input
deck and from either control.F90 or the initial conditions areas. See the
programmers guide part of this manual for more details. It is NOT considered
acceptable to force a user to specify any part of the code either in the input
deck or within the code source.

\subsection{The maths parser}
A discussion of the input deck for \EPOCH would not be complete without
consideration of the maths parser. This means that any parameter taking a
numerical value (integer or real) can be input as a mathematical expression
rather than as a numerical constant. The maths parser is fairly extensive and
includes a range of mathematical functions, physical and simulation constants
and appropriately prioritised mathematical operators. Some features of the
deck only make sense in the context of the external inital conditions file,
and will be described in that section.

\subsubsection{Constants}
The maths parser in \EPOCH  has the following constants
\begin{itemize}
\item pi - The ratio of the circumerence of a circle to it's diameter
\item kb - Boltzmann's constant
\item me - Mass of an electron
\item qe - Charge of an electron
\item epsilonnought - Permiability of free space
\item munought - Permittivity of free space
\item lengthx - The length of the simulation box in the x direction
\item lengthy - The length of the simulation box in the y direction (2D and 3D
  only)
\item lengthz - The length of the simulation box in the z direction (3D only)
\end{itemize}

It is also possible for an end user to specify custom constants both within
the code and from the input deck. This is covered later in this subsection. An
example of using a constant would be\\
\inlinecode{length\_x=pi}\\

\subsubsection{Functions}
The maths parser in \EPOCH has the following functions
\begin{itemize}
\item sqrt(a) - Square root
\item sin(a) - Sine
\item cos(a) - Cosine
\item tan(a) - Tangent
\item exp(a) - Exponential
\item asin(a) - Arcsine
\item acos(a) - Arccosine
\item atan(a) - Arctangent
\item if(a,b,c) - Conditional function. If a != 0 then function returns b,
  otherwise function returns c
\item floor(a) - Convert real to integer rounding down
\item ceil(a) - Convert real to integer rounding up
\item nint(a) - Convert real to integer rounding to nearest integer
\item tanh(a) - Hyperbolic tangent
\item sinh(a) - Hyperbolic sine
\item cosh(a) - Hyperbolic cosine
\end{itemize}

It is also possible for an end user to specify custom functions within the
code. An example of using a function would be\\
\inlinecode{length\_x = exp(pi)}\\

\subsubsection{Operators}
The maths parser in \EPOCH allows the following operators
\begin{itemize}
\item a + b - Addition operator
\item a - b - Subtraction operator or unary negation operator (autodetected)
\item a * b - Multiplication operator
\item a / b - Division operator
\item a\^b - Power raise operator
\item a e b - Power of ten operator (1.0e3 = 1000)
\item a lt b - Less than operator. Returns 1 if a < b, otherwise returns
  0. Intended for user with if.
\item a gt b - Greater than operator. Returns 1 if a > b, otherwise returns 0.
\item a eq b - Equality operator. Returns 1 if a==b, otherwise returns 0.
\item a and b - Logical and operator. Returns 1 if a != 0 and b != 0,
  otherwise returns 0
\item a or b - Logical or operator. Returns 1 if a != 0 or b != 0, otherwise
  returns 0
\end{itemize}

It is not possible at this time to specify custom operators without major
changes to the code. An example of using an operator would be\\
\inlinecode{length\_x = 10.0 + 12.0}\\

\subsection{Creating custom constants within the input deck}
Setting up the custom extensions to the input deck are discussed in the
section {\bf Customising \EPOCH} later in the manual, but it is simple to set
up custom constants from within the input deck. There is a special input deck
block called {\it constant} which simply contains the constants which you want
to set up. Suppose for example that you have a problem in 1D where the Debye
length is known and you want the box to be a fixed number of Debye lengths,
and the grid spacing to always be at least 0.5 Debye lengths, you would set
that up as follows\\
\simpleboxverbatim
begin:constant
   l_debye=1.0e-6 # Debye length is 1 micrometer
   n_debye_in_box = 100 # number of debye lengths in simulation
   n_gridpoints=100 # number of grid points requested
   l_metres=l_debye * n_debye_in_box # length of simulation box in metres
   n_gp_per_debye=n_gridpoints/n_debye_in_box # number of gridpoints per debye length
end:constant

begin:control
   #if the number of gridpoints per debye length is greated than 2
   #use the requested number of gridpoints, otherwise use enough
   #that there are two gridpoints per debye length
   nx = if(n_gp_per_debye gt 2, n_gridpoints, n_debye_in_box * 2)
   length_x = l_metres
end:control
\end{Verbatim}

Note that in this case, it is still up to the user to ensure that the Debye
length is actually the value given in \inlinecode{l\_debye} by setting the
initial conditions. The named constants are created the first time they are
specified, and can be reset at will. It is possible to have several instances
of the constant block, either creating new constants or resetting existing
ones. It is possible to break other blocks to define constants and then
restart the block, so this is valid\\
\simpleboxverbatim
begin:control
   #some of control block
end:control

begin:constant
   #set constants
end:constant

begin:control
   #rest of control block
end:control
\end{Verbatim}

\subsection{MPI in \EPOCH}
\EPOCH is a parallel PIC code using the standard MPI 2.0 library. However, the
code has been written in such a way that it is possible to use most of the code
with no knowledge of MPI at all. However, this does mean that there are some
quantities which MUST be read from specific variables in the code rather than
hard coding quantities in. These variables are listed below

\subsubsection{Important values in the \EPOCH code}
When setting up initial conditions within the \EPOCH source (rather than using
the external initial conditions) there are several constants that you need to
know about. These constants are
\begin{itemize}
\item nx - Number of gridpoints on local processor in the x direction
\item ny - Number of gridpoints on local processor in the y direction (2D and
  3D)
\item nz - Number of gridpoints on local processor in the z direction (3D)
\item length\_x - Length of domain in x direction (Note that this is NOT the
  same syntax as in the input deck where the equivalent variables is just
  lengthx)
\item length\_y - Length of domain in y direction (2D and 3D)
\item length\_z - Length of domain in z direction (3D)
\item nSpecies - The number of species in the code
\end{itemize}

There are also up to three arrays which you will have to use
\begin{itemize}
\item x(-1:nx+2) - Position of a given gridpoint in real units in the x
  direction
\item y(-1:ny+2) - Position of a given gridpoint in real units in the y
  direction (2D and 3D)
\item z(-1:nz+2) - Position of a given gridpoint in read units in the z
  direction (3D)
\end{itemize}

When using the autoloader you shouldn't need to read particle properties
directly at all. If you do then please read the next section on using the
manual particle loader.

\subsection{\EPOCH initial conditions using the autoloader}
The \EPOCH autoloader is a feature which means that if your initial condition
can be specified as a number density and temperature profile on the underlying
grid then you don't have to deal with the details of the internal
representation of particles in \EPOCH. There are three phases of the
autoloader in EPOCH

\begin{itemize}
\item internal\_early - Initial conditions which are specified in the \EPOCH
  source and are executed before the external section
\item external - Initial conditions which are specified in an external input
  deck like file. It is not necessary to recompile the code, or even have
  access to the source to change the external initial conditions
\item internal\_late - Initial conditions which are specified in the \EPOCH
  source and are executed after the external section
\end{itemize}

The purpose of this separation into three phases is to allow maximum
flexibility with the minimum need for access to source code. It is therefore
possible to use the code entirely in classic mode where initial conditions are
specified entirely within the \EPOCH source, to use a completly external
method where no initial conditions are specified in the \EPOCH source at all,
or a hybrid approach where a base initial condition is specified internally,
then modified by the external conditions, and then finally modified again
internally.

\subsubsection{Setting autoloader parameters within \EPOCH}
Within EPOCH, there are Fortran90 structures which represent the information
needed by the autoloader for each species. In 2D, the definition of these
structures is

\simpleboxverbatim
  TYPE :: Initial_Condition_Block

     REAL(num),DIMENSION(:,:),ALLOCATABLE :: Rho !Number density
     REAL(num),DIMENSION(:,:,:),ALLOCATABLE :: Temp !Temperature
     REAL(num) :: minrho !Minimum density
     REAL(num) :: maxrho !Maximum density

  END TYPE Initial_Condition_Block
\end{Verbatim}

In 1D, there is one fewer dimension to both arrays, and in 3D there is one
more dimension to both arrays. An instance of the structure is created for
each particle species and is named ``InitialConditions(iSpecies)''. The
elements of this structure have the following definitions (againin 2D)\\
\begin{itemize}
\item Rho(-1:nx+2,-1:ny+2) - Particle {\bf NUMBER} density at all spatial
  positions in the grid. Must be defined fully between -1:nx+2 and -1:ny+2
\item Temp(-1:nx+2,-1:ny+2,1:3) - Temperature of a thermal distribution at all
  spatial positions in the grid, and independantly in each dimension
  (including ignorable directions). The final dimension is the direction in
  which to apply the specified thermal distribution.
\item minrho - The minimum density at which to load particles. If the initial
  particle number density at any point is lower then minrho then particles are
  not loaded there by the autoloader.
\item maxrho - The maximum density. If the initial particle number density
  exceeds maxrho then the density is clipped to maxrho.
\end{itemize}

So an example of setting up a cold plasma block for all species in 2D would
look like
\simpleboxverbatim
  SUBROUTINE IC_Early
     INTEGER :: iSpecies
     REAL(num) :: slab
     DO iSpecies=1,nSpecies
        InitialConditions(iSpecies)%Temp=0.0_num
        InitialConditions(iSpecies)%minrho=1.4_num
        DO iy=-1,ny+2
           DO ix=-1,nx+2
              slab=0.0_num
              IF (x(ix) .LT. 1.0_num .AND. x(ix) .GT. -1.0_num) slab=100.0
              InitialConditions(iSpecies)%Rho(ix,iy)=1.0_num + slab
           ENDDO
        ENDDO
     ENDDO

  END SUBROUTINE IC_Early
\end{Verbatim}

This sets up a plasma slab with a density of 100 particles per square metre
between x=-1 and x=+1 with no restriction on y. Note that density is never set
to zero anywhere, the lowest value of rho is 1.0. However, since the minrho
value is set to 1.4 then particles are only loaded inside the slab where the
density is greater than 1.4. If rho had simply been set to zero (or worse,
some small but non-zero number) the code would have positioned particles in
that cell anyway, but would have assigned the particles very low or zero
weight functions meaning that they would have barely contributed to the
solution while at the same time taking up compute resources. If you have
localised density slabs in a vacuum, you should always use the minrho
parameter to set a cutoff below which particles are not loaded. Running this
example gives the following (This picture was produced using LLNL visit to
plot a subset of the particles. The apparantly ordered layout of particles is
a result of the quiet start algorithm combined with the routine which selects
a subset of the particles)\\
%Example image from visit for these initial conditions
\image{./images/example.eps}
In the given example the code is in the subroutine ``IC\_Early'', but since
the external setup isn't used it could be copied freely into the ``IC\_Late'',
only changing the input deck to tell \EPOCH to use late internal initial
conditions instead of early internal initial conditions. The only difference
between the early and late internal initial conditions is that in
``IC\_Early'' the temperature and number density are guaranteed to be zero,
whereas in ``IC\_Late'' they will contain any changes made in ``IC\_Early''
and in the external initial conditions. So to take a (very silly) example, I
could use the following code to change the slab to have a finite width in y.

\simpleboxverbatim
  SUBROUTINE IC_Late
     INTEGER :: iSpecies
     DO iSpecies=1,nSpecies
        DO iy=-1,ny+2
           DO ix=-1,nx+2
              IF (y(iy) .GT. 1.0_num .OR. y(iy) .LT. -1.0_num)&
                 InitialConditions(iSpecies)%Rho(ix,iy)=1.0_num
           ENDDO
        ENDDO
     ENDDO

  END SUBROUTINE IC_Late
\end{Verbatim}

Once this has been added then changing ``initial\_conditions'' field of the
input deck from ``initial\_conditions = internal\_early'' to
``initial\_conditions = internal\_early + internal\_late'' changes the output
of the code from the previous figure to this one\\
%Example image from visit for the second set of initial conditions
\image{./images/example2.eps}
Both figures are from runs with the same number of particles and the same
fraction of particles displayed in VisIT. This shows why the use of the minrho
field is so useful, because the second figure obviously has a higher particles
density than the first, since the particles are concentrated into a smaller
region.

\subsubsection{Setting autoloader properties from the input deck}
If the external initial conditions are specified then the code reads the input
deck field ``icfile'' which specifies a file which contains the initial
conditions information. This file is read by the input deck parser, and has
the same maths capabilities as the normal input deck, but with some additional
constants and functions which only make sense when specifiying initial
conditions. The layout of an inital conditions file is
\simpleboxverbatim
begin:constant
   partdens=1.0e25
   wpe=sqrt(partdens * qe^2/(me * epsilonnought))
end:constant

begin:species1
   rho=interpolate(x,-(6.0e-6),0.2,(10.0e-6),0.2,(11.0e-6),
            1.0,(150.0e-6),1.0,(150.5e-6),0.2,(420.0e-6),0.2,6)
   rho=rho(1)*partdens
   temp_x=300.0
   temp_y=temp_x(1)
   minrho=0.3*partdens
end:species1

begin:species2
   rho=rho(1)
   temp_x=temp_x(1)
   temp_y=temp_x(1)
   minrho=0.3*partdens
end:species2
\end{Verbatim}

This is obviously related to the input deck structure, but with a new type of
block, the ``species'' block. There is one species block for each species
specified in the input deck, and is simply specified by the addition of the
species number after the word ``species''. The ``constant'' block is exactly
the same as the ``constant'' block used in the input deck, and constants
defined in the input deck are still available in the initial conditions
file. The ``species'' block has the following possible elements. If an element
is not specified then it is left with the same value that it was specified
either at code startup (everything zero), or at the end of the early internal
initial conditions.\\
The maths parser now has the following new constants
\begin{itemize}
\item x - X coordinate in metres
\item y - Y coordinate in metres (2D and 3D only)
\item z - Z coordinate in metres (3D only)
\item dx - Grid spacing in x direction
\item dy - Grid spacing in y direction (2D and 3D only)
\item dz - Grid spacing in z direction (3D only)
\item \{x,y,z\}\_start - \{x,y,z\}\_start specified in input deck
\item \{x,y,z\}\_end - \{x,y,z\}\_end specified in input deck
\item ix - X coordinate in grid points
\item iy - Y coordinate in grid points (2D and 3D only)
\item iz - Z coordinate in grid points (3D only)
\item time - Returns current simulation time (used in the laser boundaries)
\end{itemize}

The maths parser now also has the following new functions
\begin{itemize}
\item rho(a) - Returns the density for species a
\item temp\_x(a) - Returns temperature in x direction for species a
\item temp\_y(a) - Returns temperature in y direction for species a
\item temp\_z(a) - Returns temperature in z direction for species a
\item gauss(var,centre,fwhm) - Calculate a Gaussian profile in variable {\it
    var} centred on {\it centre} with a characteristic width {\it fwhm}
\item interpolate(interp\_var,....,n\_pairs) - Linear interpolation function,
  explained later
\end{itemize}

The use of most of the new fuctions and constants is fairly simple, but
interpolate requires some additional explanation. This function allows a user
to specify a set of position value pairs and have the code linearly
interpolate the values between these control points. This function is mainly
intended for ease of converting initial conditions from other existing PIC
codes, and the same effect can usually be obtained more elegantly using the
``if'' command. The structure of the ``interpolate'' command is as follows :
The first parameter is the variable which is to be used as the axis over which
to interpolate the values. This can in general be any valid expression, but
will normally just be a coordinate axis. The next 2n entries are the
position,value pairs, and the final parameter is the number of position,value
pairs. The slightly clunky syntax of this command is unfortunatly necessary to
allow it to work with some fairly fundamental features of the maths parser
used in \EPOCH.\\
All that is required now is to give an example. A good example is to reproduce
the previous example of an isolated plasma block in 2D. This would look like
\simpleboxverbatim
begin:species1
   #first set density in the range 0->1
   #cut down density in x direction
   rho=if ((x gt -1) and (x lt 1),1.0,0.2)
   #cut down density in y direction
   rho=if ((y gt -1) and (y lt 1),rho(1),0.2)

   #multiply density by real particle density
   rho=rho(1)*100.0

   #Set the temperature to be zero
   temp_x=0.0
   temp_y=temp_x(1)

   #Set the minimum density for this species
   minrho=0.3*100.0
end:species1

begin:species2
   #Just copy the density for species 1
   rho=rho(1)

   #Just copy the temperature from species 1
   temp_x=temp_x(1)
   temp_y=temp_y(1)

   #Set the minimum density for this species
   minrho=0.3*100.0
end:species2
\end{Verbatim}

This produces the following output. Note that this is the same as that
produced previously from the internal initial conditions.\\
%Example image from visit for the external set of initial conditions
\image{./images/example3.eps}
An important point to notice is that the two parts of the logical expressions
in the input deck are enclosed within their own brackets. This helps to remove
some ambiguities in the functioning of the input deck parser. It is hoped that
this will soon be fixed, but at present ALWAYS enclose logical expressions in
brackets.

\subsubsection{Setting autoloader properties from an external binary file}
It is possible to load external data files into variables used by the
autoloader. In the input deck this is done as follows
\simpleboxverbatim
begin:species_external1
   rho=Data/data.file
   offset=80000
   temp_x=Data/data.file
   temp_y=Data/data.file
end:species_external1
\end{Verbatim}

The species\_external block is very similar to the species block, except that
where normally you would specify a functional form for a variable, you now
specify a filename. Other variables such as {\bf minrho} and {\bf maxrho}
still work as in the normal {\it species} block. It is possible to specify
multiple variables in a single file using the {\bf offset} element. When the
offset is set, the next data read from a file is read with an offset of {\bf
offset} bytes from the start of the file. {\bf offset} is reset to zero at the
start of a new {\it species\_external} block, but is not reset within a given
{\it species\_external} block. In the example above therefore, {\bf temp\_x}
and {\bf temp\_y} are set to the same. The data is immediatly loaded into the
requested variable, so it is valid to do the following.
\simpleboxverbatim
begin:species_external1
   rho=Data/data.file
   offset=80000
   temp_x=Data/data.file
end:species_external1

begin:species1
   rho=rho(1)*partdens
   temp_y=temp_x(1)
end:species1
\end{Verbatim}
It is also possible to load data from external files from the internal
autoloader routines. This is done as follows

\simpleboxverbatim
  SUBROUTINE IC_Early
     INTEGER :: iSpecies
     INTEGER :: Error
     INTEGER(KIND=MPI_OFFSET_KIND) :: offset

     DO iSpecies=1,nSpecies
        offset=0
        CALL Load_Single_Array_From_Data_File("Data/data.file",&
            InitialConditions(Species_ID)%Rho,offset&
            ,Error)
        offset=80000
        CALL Load_Single_Array_From_Data_File("Data/data.file",&
             InitialConditions(Species_ID)%Temp(:,:,1),offset&
            ,Error)
        CALL Load_Single_Array_From_Data_File("Data/data.file",&
             InitialConditions(Species_ID)%Temp(:,:,2),offset&
            ,Error)
     ENDDO

  END SUBROUTINE IC_Early
\end{Verbatim}

\subsection{Deferred Evaluation Objects (DEOs)}
In addition to custom constants it is also possible to set up deferred
execution objects. The difference between the two is that constants are
immediatly evaluated when defined, so they cannot include the spatial
information used in defining initial conditions. DEOs are evaluated at the
point in the deck where they are used so they can include spatial
information. DEOs are relativly memory intensive, so should only be used when
required. An example would be
\simpleboxverbatim
begin:deo
   r=sqrt(x^2+y^2)
end:deo

begin:species1
   #first set density in the range 0->1
   #cut down density in x direction
   rho=if ((r lt 1),1.0,0.2)

   #multiply density by real particle density
   rho=rho(1)*partdens

   #Set the temperature to be zero
   temp_x=0.0
   temp_y=temp_x(1)

   #Set the minimum density for this species
   minrho=0.3*partdens
end:species1
\end{Verbatim}
This example produces a circular rather than a square density enhancement.

\subsection{Lasers}
In the latest version of EPOCH, the ability to add EM wave sources such as
lasers at boundaries has been added. To use lasers, set the boundary that you
wish to have a laser on to be of type \inlinecode{simple\_laser} and then
specify one or more lasers attached to that boundary. Lasers may be specified
anywhere initial conditions are specified.

\subsubsection{Lasers in the external initial conditions file}
To introduce a laser into the code from the input deck, you simply add a
``laser'' block for every laser that you want. It is perfectly valid to add as
many lasers as required to a boundary. A laser block looks like

\simpleboxverbatim
begin:laser
   direction=left
   amp=3.88191e13
   profile=exp(-(y^2))
   freq=1.78e15
   pol=0.0
   phase=0.0
   t_profile=1.0
   t_start=0.0
   t_end=end
   ID=1
end:laser
\end{Verbatim}

\begin{itemize}
\item direction - The boundary to which to attach the laser. Options are left,
  right, up ,down. This must be the first element of the block.
\item amp - The amplitude of the laser.
\item profile - The spatial profile of the laser this should be a spatial
  function not including any values in the direction normal to the boundary
  which the laser is attached to, and the expression will be evaluated at the
  boundary. This is calculated at t=0, so no time dependant part may be put
  here.
\item freq - The frequency of the laser.
\item pol - The polarisation angle of the magnetic field of the laser from the
  ignorable direction. If pol=0.0 then the magnetic field perturbation is only
  in Bz.
\item phase - The phase profile of the laser wavefront. Once again this is
  calculated at t=0, so no time dependant part may be put here.
\item t\_profile - The temporal profile of the laser, this is calculated at
  each timestep, but you cannot specifiy spatial information. If this is not
  specified then the code will attempt to get a temporal profile using the
  \inlinecode{Custom\_Laser\_Time\_Profile} subroutine inside the code.
\item t\_start - The time at which to start applying the laser. Can be
  ``start'' to just start at the beginning of the simulation.
\item t\_end - The time at which to stop applying the laser. Can be ``end'' to
  just end at the finish of the simulation.
\item ID - A user supplied ID which identifies a laser. This does not have to
  be unique, and is only used when specifying temporal profiles inside the
  code.
\end{itemize}

It you add multiple laser blocks to the initial conditions file then the
multiple lasers will be additively combined on the boundary.

\subsubsection{Lasers in the internal initial conditions}
You can add lasers at any point in the internal initial conditions routines,
using the internal representation of a laser in the code, which is a Fortran
TYPE called \inlinecode{Laser\_Block}
\simpleboxverbatim
  TYPE :: Laser_Block
     !Boundary to which laser is attached
     INTEGER :: Direction
     !A unique ID number for the laser (not used directly by EPOCH)
     !Only used if hard coding time profiles
     INTEGER :: ID
     REAL(num), DIMENSION(:), ALLOCATABLE :: Profile
     REAL(num), DIMENSION(:), ALLOCATABLE :: Phase

     LOGICAL :: UseTimeFunction
     TYPE(PrimitiveStack) :: TimeFunction

     REAL(num) :: amp=0.0_num,freq=1.0_num
     REAL(num) :: pol=0.0_num, angle=0.0_num
     REAL(num) :: t_start=0.0_num, t_end=0.0_num
  END TYPE Laser_Block
\end{Verbatim}
Most of these items are the same as their equivalents in the input deck and
are set in the same way. The detailed description is
\begin{itemize}
\item Direction - The boundary to which the laser is attached. This is
  automatically set when the laser is attached to a boundary.
\item ID - Exactly the same as the ID property from the input deck.
\item Profile - The spatial profile for the laser. The array is allocated by
  the initial call to \inlinecode{Init\_Laser} and must be populated between
  (1:nx) for a boundary on the top or bottom, or (1:ny) for a boundary on the
  left or right.
\item Phase - The phase of the wavefront for the laser. See Profile.
\item UseTimeFunction - A logical variable which tests whether to use an input
  deck specified time profile or a hard coded profile. If you're setting up a
  laser inside the code, this should be false.
\item TimeFunction - The Parser Stack which represents the temporal profile of
  the laser if specified in the input deck. Don't set it to anything if
  specifying an internal initial condition.
\item amp, freq, pol etc. - The same as in the input deck.
\end{itemize}

To actually set up a laser is fairly simple, as shown below. The following
code creates a laser and attaches it to the left hand boundary.
\simpleboxverbatim
TYPE(Laser_Block),POINTER :: NewLaser

ALLOCATE(NewLaser)
CALL Init_Laser(NewLaser,BD_LEFT)
NewLaser%amp=3.88191e13_num
NewLaser%freq=1.78e15_num
NewLaser%ID=1
NewLaser%Phase=0.0_num
DO iy=1,ny
   NewLaser%Profile(iy)=exp(-y(iy)**2)
ENDDO
CALL Attach_Laser(NewLaser)
\end{Verbatim}
After the call to \inlinecode{Attach\_Laser} the laser is attached to the
correct boundary. Since NewLaser is a pointer, it is valid to then reallocate
the same variable again to create and attach further lasers. It is valid to
delete a laser without attaching it, although obviously the laser is lost. It
is not valid to call \inlinecode{Laser\_Init} on an already initialised laser.

\subsubsection{Internal laser time profiles}
If you specify a laser's time profile in the input deck then you need take no
further action. However, if you specify a laser within the code, or wish to
have more control, you can specify the laser time profile internally. In this
case, the relevant function is in
\inlinecode{user\_interaction/custom\_laser.f90}
\simpleboxverbatim
  FUNCTION Custom_Laser_Time_Profile(laser)

    TYPE(Laser_Block),INTENT(IN) :: laser
    REAL(num) :: Custom_Laser_Time_Profile

    IF (laser%id .EQ. 1) THEN
      Custom_Laser_Time_Profile=1.0
    ELSE
      Custom_Laser_Time_Profile=EXP(-((time-1.0e-12_num)/1.0-e13_num)**2)
    ENDIF

  END FUNCTION Custom_Laser_Time_Profile
\end{Verbatim}
The function returns just the time profile part of the laser, and the
amplitude specified when the laser is set up is still applied, so normally you
would want Custom\_Laser\_Time\_Profile to run between 0 and 1.

\subsection{Extended IO - Distribution functions}
PIC codes effectively represent a Lagrangian Monte-Carlo sampling of the phase
space of Vlasov's equation. Sometimes it is useful to reconstruct part of the
full phase space, this is controlled by the distribution function extended io
option. The block must be put in the extended io deck file specified in the
output section of the main input deck. Distribution function output can also
be specified in any of the initial conditions sections of the main code.

\subsubsection{Distribution function units}
Calculating distribution functions requires some degree of integration of data
leading to various possible ways of normalising the resulting distribution
function. In EPOCH, distribution functions are normalised so that the value at
every point of the distribution function is the number of particles within
that cell of the distribution function, ignoring all phase space directions
which are not considered as an axis of the distribution function. Summing the
distribution function should give the total number of real particles in the
simulation.

\subsubsection{Distribution function limitations}
At present, the code to calculate the distribution functions has one
limitation : It ignores particle shape functions when calculating properties
on the spatial axis, meaning that the result is less smooth than normal
properties from the code. This will be improved in the next release.

\subsubsection{Distribution functions in the input deck}
\simpleboxverbatim
begin:dist_fn
   name=x_px
   ndims=2
   dumpmask=always

   direction1=dir_x
   direction2=dir_px

   #range is ignored for spatial coordinates
   range1=1>1
   range2=-3.0e-20>3.0e-20

   restrict_py=-3.0e-20>3.0e-20

   #resolution is ignored for spatial coordinates
   resolution1=1
   resolution2=100

   include_species_1=T
   include_species_2=T
end:dist_fn
\end{Verbatim}
\begin{itemize}
\item name - The name that the distribution function should have in output
  dumps.
\item ndims - The number of dimensions that the distribution function should
  have. Currently only 2 or 3 are valid numbers
\item direction\{n\} - For each dimension specified in {\bf ndims} it is
  necessary to specify the direction of the full phase space which corresponds
  to the axis. Valid directions are : dir\_x, \{dir\_y\}, \{dir\_z\}, dir\_px,
  dir\_py, dir\_pz. Spatial directions are only valid in high enough dimension
  codes, i.e. EPOCH1D only has a valid dir\_x.
\item range\{n\} - The range of this dimension, specified as {\it lower}>{\it
    upper}. This is ignored for spatial dimensions. Any particle which exceeds
  the range is ignored.
\item resolution\{n\} - The number of gridpoints in each dimension. This
  number is ignored for any specified spatial dimension, due to the
  requirements of the paralellism scheme of \EPOCH.
\item restrict\_\{x,y,z,p\_x,p\_y,p\_z\} - Restrictions are specified in the
  same way as ranges, but have a subtly different behaviour. Ranges specifiy
  the range of a visible axis on the resulting distribution function, whereas
  restrictions allow you to specify a valid window of particle properties even
  for properties which are not being used as axes. It is possible to set a
  restriction that is more restrictive than the range applied. This is not
  trapped as an error and such parts of the distribution function are
  guaranteed to be empty.
\item include\_species\_\{n\} - Whether to calculate the distribution function
  for this species.
\end{itemize}

\subsubsection{Distribution functions in the internal initial conditions}
Using distribution functions within \EPOCH is similar to using them from an
input deck. To add a distribution function output in any of the initial
conditions subroutines, the sequence looks like
\simpleboxverbatim
  TYPE(Distribution_Function_Block),POINTER :: Work

  ALLOCATE(Work)
  CALL Setup_Dist_Fn(Work)
  Work%Name="x_px"
  Work%nDims=2
  Work%DumpMask=IO_ALWAYS
  Work%Directions(1)=DIR_X
  Work%Directions(2)=DIR_PX
  !Range is ignored for spatial directions, so don't bother setting
  Work%Range(2,:)=(/-3.0e-20,3.0e-20/)
  Work%Resolution(2)=100
  !The get the first index for a restriction, just count
  !Through this list, ignoring directions which do not apply to your
  !Dimensionality (i.e. DIR_Z only in EPOCH3D)
  !DIR_X,DIR_Y,DIR_Z,DIR_PX,DIR_PY,DIR_PZ
  Work%Restrictions(4,:)=(/-3.0e-20,3.0e-20/)
  Work%Use_Species(1:2)=.TRUE.
  CALL Attach_Dist_Fn(Work)

\end{Verbatim}
This code would create exactly the same distribution function as the
preceeding input deck section.

\subsection{Extended IO - Particle Probes}
Sometimes it is useful to consider all the properties of particle which pass
through a point/line/plane (depending on dimension) in the simulation. To
allow this, it is possible to specify one or more {\it Particle Probe} blocks
in the input deck. These record copies of all particles which cross a
point/line/plane in a given direction which meet minimum and maximum kinetic
energy criteria and output the particle properties into the normal output
files. Particle probes record the positions, momenta and weight of all
particles passing through the plane. To use particle probes, the code must be
compiled with the \inlinecode{-DPARTICLE\_PROBES} compiler option. It is not
currently possible to have a particle probe which is parallel to the x axis
(although arbitrarily close is acceptable). \\

At present, particle probes exist in all dimensionalities of the code, but the
way in which they are specified has only been finalised in 2D, so only this
version of the input deck parameters will be specified. To see how to use the
versions in other dimensions, please either contact the code maintainer or
look at the file \inlinecode{src/deck/deck\_eio\_particle\_probe\_block.F90}\\

In the 2D code, the probe is specified in terms of two control nodes which
specify the ends of a line. These are specified in terms of four control
values \inlinecode{x1, y1, x2, y2}. Since particles are only recorded if they
cross the line in one direction, it should be explained how this
works. Consider a vertical line where \inlinecode{x1,y1} is the bottom node
and \inlinecode{x2,y2} is the top node, the code will then record particles
travelling from left to right. If these are reversed so that
\inlinecode{x1,y1} are the top node and \inlinecode{x2,y2} are the bottom node
then particles will be recorded if they are travelling from right to left. If
you want to record particles traveling in both directions then use to particle
probes.

\subsubsection{Particle probes in the input deck}
\simpleboxverbatim
begin:probe
   name=electron_back_probe

   x1=50.0e-6
   y1=-50.0e-6

   x2=50.0e-6
   y2=50.0e-6

   probe_species=1
   ek_min=0.0
   ek_max=-1.0

   dump=always
end:probe
\end{Verbatim}
\begin{itemize}
\item name - The name that the probe should have in output dumps, the outputs
  being named using this as a prefix \inlinecode{electron\_back\_probe\_px}
  for the x momentum. The particle positions would just be called
  \inlinecode{electron\_back\_probe}.
\item x1 - The x position of the first probe node
\item y1 - The y position of the first probe node
\item x2 - The x position of the second probe node
\item y2 - The y position of the seconds probe node
\item probe\_species - The species number to which this probe should be
  applied. To probe several species, use several probe blocks in the input
  deck.
\item ek\_min - The minimum kinetic energy of particles to store information
  about. Set to 0 for no minimum kinetic energy.
\item ek\_max - The maximum kinetic energy of particles to store information
  about. Set to -1 for no maximum kinetic energy.
\item dump - The dump code for this particle probe. This is the same as that
  for the main output controls in \inlinecode{input.deck}. Note that the code
  has to store copies of particles which pass through the probe until a dump
  occurs. This means that the code's memory requirements can increase
  drastically if this code only dumps probe information infrequently. If this
  is set to \inlinecode{never} then the code effectively never uses the probe.
\end{itemize}

\subsection{Restarting \EPOCH from previous output dumps}
Another possible way of setting up initial conditions in \EPOCH is to load in
a previous output dump and use it to specify initial conditions for the
code. The effect of this is to restart the code from the state that it was in
when the dump was made. To do this, you just specify ``initial\_conditions =
restart'' in the input deck and then set the field ``restart\_snapshot'' to
the number of the output dump from which you want the code to restart. Because
of the way in which the code is written you cannot guarantee that the code can
succesfully restart from any output dump. To restart properly, the
following{\it must} have been dumped
\begin{itemize}
\item Particle positions
\item Particle momenta
\item Particle species
\item Particle weights
\item Relevant parts of the electric field (If for example it is known that Ez
  == 0 then it is not needed)
\item Relevant parts of the magnetic field
\end{itemize}
Since the autoloader completely changes the position of particles etc. it is
not possible to combine restart dumps with {\it any} of the autoloader
routines. It is possible to use the manual particle control part of the
initial conditions to make changes to a restarted initial condition after the
restart dump is loaded. The output files don't include all of the information
needed to restart the code fully, so if you wish to archive output dumps for
future use, you will need to retain a copy of all relevant input deck files
with the output file as well. In future the code may well be changed to allow
full restart from output files.\\

If specific ``restart'' dumps are specified in the input deck, or the
``force\_final\_to\_be\_restartable'' flag is set then in some cases the
output is forced to contain enough information to output all the data. These
restart dumps can be very large, and also override the ``dump'' parameter
specified for a species and output the data for that species anyway.

\subsection{Visualising \EPOCH output data}

\subsubsection{IDL}
\EPOCH is supplied with routines to allow the visualisation of data from
within the ITT IDL data analysis and visualisation language. To start IDL with
the routines loaded, just type\\
\inlinecode{idl Start}\\
in the main \EPOCH directory. To load an output, just type\\
\inlinecode{data=getdata(\{dumpnum\},wkdir='Data')}\\
the return value from this function is an IDL structure which contains all the
data which is available in the output dump. Some of the data which has been
loaded is itself a structure because of the need to store some metadata as
well as the primary data. For example particle position information in the x
direction would be accessed using\\
\inlinecode{data.particles.particlepositions(*,0)}\\
in the y direction\\
\inlinecode{data.particles.particlepositions(*,1)}\\
etc. It is also possible to get more information about the data held in a
given data dump by typing\\
\inlinecode{data=getdata(\{dumpnum\},wkdir='Data',/variables)}\\
which prints the name and type of data held in the file, but loads no data. To
load a specific variable, just add a /\{variable\_name\} to the load command\\
\inlinecode{data=getdata(\{dumpnum\},wkdir='Data',/vx)}\\

\subsubsection{LLNL VisIT}
LLNL's VisIT software is a parallel data visualisation
package(\inlinecode{https://wci.llnl.gov/codes/visit/}). \EPOCH comes with
source code for the plugin needed to allow VisIT to load the output CFD files
which are generated. There are full manuals for VisIT which can be downloaded
from the above link so no further details will be given here. To build the
plugin when the VisIT bin directory is in the user's path, just type ``make
visit'' at the root of the \EPOCH directory. For more experienced users of
VisIT, the xml file which is used to generate the plugin is supplied in the
VisIT subdirectory, called cfd.xml.

\subsubsection{Mathworks MatLab}
There are also routines to allow the loading of CFD files from Mathworks
MatLab software. These are still under development so are not shipped with the
code. If they are required, they can be supplied on demand.

\section{\EPOCH for advanced end users}

\subsection{\EPOCH internal representation of particles}
Since not all problems in plasma physics can be described in terms of an
initial distribution of thermal plasma, it is also possible to manually
control properties of each individual pseudoparticle for an initial
condition. This takes place in the subroutine \inlinecode{manual\_load} in the
user\_interaction/initial\_conditions.f90. Manual loading takes place after
all the autoloader phases, to allow manual tweaking of autoloader specified
initial conditions. To use the manual loading routines, just set\\
\simpleboxverbatim
   initial_conditions=manual
\end{Verbatim}
in the control block of the input deck. It can be combined with autoloader
options in the input deck by addition in the same way as the individual
autoloader options are used, so
\simpleboxverbatim
   initial_conditions=manual+internal_early
   initial_conditions=manual+external
   initial_conditions=manual+external+internal_late+internal_early
\end{Verbatim}
are all valid values in the input deck.

Inside the code, particles are represented by a Fortran90 TYPE called
PARTICLE. The current definition of this type (in 2D) is

\simpleboxverbatim
!Object representing a particle
  TYPE :: Particle
     REAL(num), DIMENSION(3) :: Part_P
     REAL(num),DIMENSION(2) :: Part_pos
#ifdef PER_PARTICLE_WEIGHT
     REAL(num) :: weight
#endif
#ifdef PER_PARTICLE_CHARGEMASS
     REAL(num) :: charge
     REAL(num) :: mass
#endif
     TYPE(Particle),POINTER :: Next, Prev
#ifdef PART_DEBUG
     INTEGER :: Processor
     INTEGER :: Processor_at_t0
#endif
  END TYPE Particle
\end{Verbatim}
Note the presence of the preprocessor directives, meaning that charge and mass
only exist if the \inlinecode{-DPER\_PARTICLE\_CHARGEMASS} define was put in
the makefile. If you want to access a property that does not seem to be
present, check the preprocessor defines.

These parameters can be explained as follows
\begin{itemize}
\item Part\_P - The momentum in 3 dimensions for the particle. This is always
  of size 3.
\item Part\_Pos - The position of the particle in space. This is of the same
  size as the dimensionality of the code.
\item weight - The weight of this particle. The number of real particles
  represented by this pseudoparticle.
\item charge - The particle charge. If the code was compiled without per
  particle charge, then use the charge property of the TYPE(ParticleFamily).
\item mass - The particle rest mass. If the code was compiled without per
  particle mass, then use the mass property of the TYPE(ParticleFamily).
\item Next, Prev - The next and previous particle in the linked list which
  represents the particles in the current species. This will be explained more
  later.
\item Processor - The rank of the processor which currently holds the
  particle.
\item Processor\_at\_t0 - The rank of the processor on which the particle
  started.
\end{itemize}

Collections of particles are represented by another Fortran TYPE, called
\inlinecode{ParticleList}. This type represents all the properties of a
collection of particles and is used behind the scenes to deal with
interprocessor communication of particles. The definition of the type is

\simpleboxverbatim
  TYPE :: ParticleList
     TYPE(Particle),POINTER :: Head
     TYPE(Particle),POINTER :: Tail
     INTEGER(KIND=8) :: Count
     !Pointer is safe if the particles in it are all unambiguously linked
     LOGICAL :: Safe

     TYPE(ParticleList), POINTER :: Next, Prev
  END TYPE ParticleList
\end{Verbatim}
\begin{itemize}
\item Head - The first particle in the linked list.
\item Tail - The last particle in the linked list.
\item Count - The number of particles in the list. Note that this is NOT MPI
  aware, so reading count only gives you the number of particles on the local
  processor.
\item Safe - Any ParticleList which a user should come across will be a Safe
  ParticleList. Don't change this property
\item Next, Prev - For future expansion it is possible to attach ParticleLists
  together in another linked list. This is not currently used anywhere in the
  code.
\end{itemize}

An entire species of particles is represented by another Fortran TYPE, this
time called \inlinecode{ParticleFamily}. This represents all the properties
which are common to all particles in a species. The definition is

\simpleboxverbatim

  TYPE :: ParticleFamily
     CHARACTER(EntryLength) :: Name

     TYPE(ParticleList) :: AttachedList
     TYPE(ParticleFamily),POINTER :: Next,Prev
     INTEGER :: ID
     LOGICAL :: Dump

     REAL(num) :: Charge
     REAL(num) :: Mass
     INTEGER(KIND=8) :: Count

  END TYPE ParticleFamily

\end{Verbatim}

\begin{itemize}
\item Name - The name of the particle species, used in the output dumps etc.
\item Next,Prev - Particle Species are also linked together in a linked
  list. This is used internally by the output dump routines, but should not be
  used by end users.
\item ID - The species number for this species. This is the same number as is
  used in the input deck to designate the species.
\item Charge - The charge in Coulombs. Even if PER\_PARTICLE\_CHARGEMASS is
  specified, this is still populated from the input deck, and now refers to
  the reference charge for the species.
\item Mass - The mass in kg.
\item Count - The number of particles of this species globally (NOTE may not
  be accurate). This will only ever be the number of particles on this
  processor when running on a single processor. While this property will be
  accurate when setting up initial conditions, it is only guaranteed to be
  accurate for the rest of the code if the code is compiled with the correct
  preprocessor options.
\end{itemize}

\subsection{Linked Lists}
Linked lists are a standard computer programming technique which is still
slightly unusual in Fortran, and may well be unfamiliar to many Fortran
programmers. They effectively allow you to have an array of arbitrary length,
although this comes with various tradeoffs about memory locality and speed of
accessing elements. The general concept is that of a chain where each link in
the chain only knows about the previous link in the chain and the next link in
the chain. Although there are schemes for doing this in languages which don't
have pointers, the normal method of implementing linked lists is to use
pointers to point to previous and next elements in the list, and this is how
they are implemented in \EPOCH. Since both linked lists and Fortran pointers
are slightly esoteric concepts, while being key to the operation of \EPOCH a
brief overview of them is presented here.\\

The simplest possible form of a linked list element would be a TYPE which
looks like

\simpleboxverbatim
TYPE :: Linked_List
    TYPE(Linked_List),POINTER :: Next
    TYPE(Linked_List),POINTER :: Prev
END TYPE Linked_List
\end{Verbatim}

You also have to have a pointer to the start of the list, and to speed up
adding a new elements to the list, you normally also keep a pointer to the
last element of the list. Therefore you would also have variables which look
like
\simpleboxverbatim
TYPE(Linked_List) :: Head, Tail
\end{Verbatim}

Since Fortran pointers are not initialised in any particular state, you have
to remember to set the Head and Tail pointers to explictly point nowhere
(normally called a null pointer by analogy with the older C style
pointers). This is done using the nullify command
\simpleboxverbatim
NULLIFY(Head)
NULLIFY(Tail)
\end{Verbatim}

The same thing is important when creating a new linked list element, so you
would normally have a creation function for linked list elements

\simpleboxverbatim
SUBROUTINE Create_Element(Element)

   TYPE(Linked_List),POINTER,INTENT(INOUT) :: Element

   ALLOCATE(Element)
   NULLIFY(Element%Next)
   NULLIFY(Element%Prev)

END SUBROUTINE Create_Element
\end{Verbatim}
Note that the allocate function can be used on pointers in the same way that
it can be used with variables which have the allocatable attribute. There is
however, one important difference between a pointer and an allocatable
variable. If you attempt to allocate an already allocated variable which has
the allocatable attribute then the code will fail, whereas allocating an
already allocated pointer is perfectly valid, and will allocate the new
variable and point the pointer to it. This does not deallocate the memory that
the pointer previously pointed to, and Fortran does not have a ``garbage
collector'' which deallocates memory which is no longer accesible. So if you
allocate a pointer which already points to a variable, it is very important
that you have another pointer somewhere which points to the same memory. Once
you no longer have a pointer to an area of memory that area of memory is
completely inaccessible and cannot even be deallocated. This is termed a
memory leak and for programs which run for many cycles and have a memory leak
on each cycle, the entire memory can very quickly be used up.

So, to add a new element to the list you would have a subroutine which looks
like
\simpleboxverbatim
SUBROUTINE Add_Element(Element)

   TYPE(Linked_List),POINTER,INTENT(IN) :: Element

   IF (.NOT. ASSOCIATED(Head)) THEN
      !Adding first element to list, so just set
      !both head and tail to the element
      Head=>Element
      Tail=>Element
      RETURN
   ENDIF

   Tail%Next=>Element
   Element%Prev=>Tail
   Tail=>Element

END SUBROUTINE Add_Element
\end{Verbatim}
This subroutine adds the new Fortran operator of ``=>'' which means ``points
to'' unlike C or similar languages, Fortran pointers type to be partially
transparent to the end user, so the following code would fail

\simpleboxverbatim
PROGRAM test

      REAL,TARGET :: a=10.0
      REAL,POINTER :: b

      b=a

END PROGRAM test
\end{Verbatim}

because Fortran will try to copy the value of a into b, but b is a pointer
which hasn't been initialised, so the code will crash when it tries to copy
the data in (in theory, the code may not crash if the uninitialised b pointer
happens to point somewhere in memory which is a valid target, but this is very
unlikely). Note also that a has the attribute ``TARGET''. The target attribute
means that it is possible to point a pointer to this variable, you can only
point a pointer to a variable which is either a pointer itself or has the
target attribute. This is to try and keep Fortran pointers ``safer'' than C
style pointers. The correct code would use \inlinecode{b=>a}, at which point b
is set to point to a and can then be used everywhere in place of a.

So, to set up a linked list of n elements, you would use the following code

\simpleboxverbatim
TYPE(Linked_List),POINTER :: New
NULLIFY(New)

DO i=1,n
   CALL Create_Element(New)
   CALL Add_Element(New)
ENDDO
\end{Verbatim}

To then run through the elements of your newly created linked list, you would
use code like
\simpleboxverbatim
TYPE(Linked_List),POINTER :: Current

Current=>Head
DO WHILE(ASSOCIATED(Current))
   !Do stuff
   Current=>Current%Next
ENDDO
\end{Verbatim}

This code snippet introduces one new function ``ASSOCIATED'', which tells you
whether a pointer is a null pointer or not (this is why it is so important to
nullify new pointers, because ASSOCIATED on it's own doesn't check whether a
pointer is valid, just whether or not it is a null pointer). You can also use
ASSOCIATED to check whether a pointer points to a particular object or not, in
which case the syntax is \inlinecode{RESULT=ASSOCIATED(b,TARGET=a)}, which
returns true if b points to a, or false if it doesn't, even if b is a valid
pointer pointing to something else. It also introduces the way in which you
must use linked lists in \EPOCH. The execution flow is as follows
\begin{itemize}
\item Point Current to the current element to the start of the linked list
  (head)
\item Iterate while Current points to a valid element
\item Perform whatever actions you want on current
\item Point Current to the next element in the chain
\end{itemize}
This leads to the slightly counter intuitive behaviour where even though the
loop only acts on the variable named ``Current'', all of the elements in the
list are operated on. Although there are many tricks which can be performed
with linked lists, the only other element which needs to be explained is how
to delete elements. A subroutine to remove a single element from a linked list
would look like

\simpleboxverbatim
SUBROUTINE Remove_Element(Element)
TYPE(Linked_List),POINTER,INTENT(INOUT) :: Element

IF (ASSOCIATED(Element%Prev)) THEN
   !Previous element exists
   Element%Prev%Next=>Element%Next
ELSE
   !Previous element does not exist therefore
   !Element is the head. When Element is removed
   !The head is the element after the element being removed
   Head=>Element%Next
ENDIF

IF (ASSOCIATED(Element%Next)) THEN
   !Next element exists
   Element%Next%Prev=>Element%Prev
ELSE
   !Next element does not exists therefore
   !Element is the tail. When element is removed
   !The head is the element before the element being removed
   Tail=>Element%Prev
ENDIF

END SUBROUTINE Remove_Element
\end{Verbatim}

Once again, this code looks slightly counter-intuitive, but if you go through
step by step, it's fairly simple. In the following discussion the element
being removed is called ``C'', the element before ``C'' (if it exists) is
called ``P''and the element after the element being removed (if it exists) is
called ``N''
\begin{itemize}
\item Check whether \inlinecode{C}'s Prev element exists, this means that
  \inlinecode{P} exists
\item If \inlinecode{P} exists then the element to be removed isn't at the
  start of the chain. When \inlinecode{C} is removed, we need
  \inlinecode{P}\%Next to point to \inlinecode{C}\%Next. This leads to the odd
  looking Element\%Prev\%Next=>Element\%Next syntax
\item If \inlinecode{P} does not exist then \inlinecode{C} is at the the start
  of the chain. In order to not leave the chain orphaned when \inlinecode{C}
  is removed, we need Head to point to \inlinecode{C}\%Next
\item Exactly the same logic applies for updating the element after
  \inlinecode{C}
\item Check whether \inlinecode{C}'s Next element exists, this means that
  \inlinecode{N} exists
\item If \inlinecode{N} exists then the element to be removed isn't at the end
  of the chain. When \inlinecode{C} is removed, we need \inlinecode{N}\%Prev
  to point to \inlinecode{C}\%Prev.
\item If \inlinecode{P} does not exist then \inlinecode{C} is at the the start
  of the chain. In order to not leave the chain orphaned when \inlinecode{C}
  is removed, we need Head to point to \inlinecode{C}\%Next
\end{itemize}

Therefore, code to remove some elements from a linked list would look like
\simpleboxverbatim
TYPE(Linked_List),POINTER :: Current,Next

Current=>Head
DO WHILE(ASSOCIATED(Current))
   Next=>Current%Next
   IF (Dealloc) THEN
      CALL Remove_Element(Current)
      DEALLOCATE(Current)
   ENDIF
   Current=>Next
ENDDO
\end{Verbatim}
Note that current must be deallocated explicitly even after it has been
removed from the linked list to prevent a memory leak. Note also that the
pointer to the next element is saved before current is deallocated. This is
not necessary but means that there is only one IF statement rather than the
two otherwise needed.

\subsection{Setting the particle properties}
After all the descriptions of the types, actually setting the properties of
the particles is fairly simple. The following is an example which positions
the particles correctly in 2D space, but doesn't set any momentum

\simpleboxverbatim

SUBROUTINE Manual_Load

TYPE(Particle),POINTER :: Current
INTEGER :: iSpecies
INTEGER :: idum,clock
REAL(num) :: rpos

!Seed the random number generator off the system clock
CALL SYSTEM_CLOCK(clock)
!Correct using the rank to ENSURE that different
!processors have different random numbers
idum=-(clock+rank+1)

DO iSpecies=1,nSpecies
   Current=>ParticleSpecies(iSpecies)%AttachedList%Head
   DO WHILE(ASSOCIATED(Current))
      rpos=(random(idum) - 0.5_num)*2.0_num
      Current%Part_Pos(1)=rpos
      rpos=random(idum)*length_x + x_start

      Current%Weight=1.0_num
      Current=>Current%Next
   ENDDO
ENDDO


END SUBROUTINE Manual_Load

\end{Verbatim}
This once again produces the now familiar example output. Note that now there
are no stripes since I made no attempt to use a quiet start algorithm when
positioning particles. Note also that I completely ignored the question of
domain decomposition when setting up the particles. The code automatically
moves the particles onto the correct processor without user interaction.
%Example image from visit for these initial conditions
\image{./images/example4.ps}
In the above example note that particle momentum was not specified and
particle weight was set to be a simple constant. Setting particle weight can
be very simple if you can get the pseudoparticle distribution to match the
real particle distribution, or quite tricky if this isn't possible. Remember
that the weight of each pseudoparticle is the number which locally transforms
the pseudoparticle number density into the real particle number density. If
the pseudoparticle distribution matches the real particle distribution then
this is simply a constant, i.e the ratio of the number of pseudoparticles in
the domain to the number of real particles in the domain. In more complicated
cases, it is probably better to use the autoloader than to manually set up the
density distribution.

If you want to set up thermal distributions manually, then there is a helper
function {\bf MomentumFromTemperature} which returns a momentum sampled from
the correct distribution for a given temperature and particle mass. At present
{\bf MomentumFromTemperature} uses a simple Maxwellian distribution to
describe the thermal distribution of the particles. This is correct for
particles which do not have a strongly relativistic thermal speed, where the
Maxwell-Juttner distribution is correct. The next version of \EPOCH will have
an option to use the Maxwell-Juttner distribution rather than a Maxwellian
distribution. An example of using {\bf MomentumFromTemperature} is given
below.

\simpleboxverbatim

SUBROUTINE Manual_Load

TYPE(Particle),POINTER :: Current
INTEGER :: iSpecies
INTEGER :: idum,clock
REAL(num) :: rpos, Temp

!Seed the random number generator off the system clock
CALL SYSTEM_CLOCK(clock)
!Correct using the rank to ENSURE that different
!processors have different random numbers
idum=-(clock+rank+1)

!Simple uniform temperature
Temp=1.0e6_num

DO iSpecies=1,nSpecies
   Current=>ParticleSpecies(iSpecies)%AttachedList%Head
   DO WHILE(ASSOCIATED(Current))
      rpos=(random(idum) - 0.5_num)*2.0_num
      Current%Part_Pos(1)=rpos
      rpos=random(idum)*length_x + x_start

      Current%Weight=1.0_num

      Current%Part_P(1) = MomentumFromTemperature&
        (ParticleSpecies(iSpecies)%Mass,Temp,idum)
      Current%Part_P(2) = MomentumFromTemperature&
        (ParticleSpecies(iSpecies)%Mass,Temp,idum)

      Current=>Current%Next
   ENDDO
ENDDO


END SUBROUTINE Manual_Load

\end{Verbatim}

While the autoloader is capable of dealing with most required initial thermal
distributions, you may want to set up non-thermal initial conditions. The code
includes a helper function to select a point from an arbitrary distribution
function which can be used to deal with most non-thermal distributions. To use
the helper function, you need two to define two 1D arrays which are the x and
y axes for the distribution function. An example of using the helper function
is given below
\simpleboxverbatim

SUBROUTINE Manual_Load

TYPE(Particle),POINTER :: Current
INTEGER,PARAMETER :: nx_local=100
INTEGER :: iSpecies
INTEGER :: idum, clock, ix
REAL(num) :: rpos, dx_local
REAL(num) :: min_p, max_p, var, temperature
REAL(num),DIMENSION(nx_local) :: x_axis, y_axis

!Seed the random number generator off the system clock
CALL SYSTEM_CLOCK(clock)
!Correct using the rank to ENSURE that different
!processors have different random numbers
idum=-(clock+rank+1)

min_p=-3.0e-20
max_p=3.0e-20

dx_local=(max_p-min_p)/REAL(nx_local,num) + min_p
x_axis(1)=min_p
DO ix=2,nx_local
   x_axis(ix)=x_axis(ix-1)+dx_local
ENDDO

temperature=10000.0_num
DO iSpecies=1,nSpecies
   var=temperature*kb*ParticleSpecies(iSpecies)%Mass
   DO ix=1,nx_local
      y_axis(ix)=EXP(-x_axis(ix)**2/var)
   ENDDO
   Current=>ParticleSpecies(iSpecies)%AttachedList%Head
   DO WHILE(ASSOCIATED(Current))
      Current%Part_P(1)=Sample_Dist_Function(x_axis,y_axis,idum)
      Current=>Current%Next
   ENDDO
ENDDO


END SUBROUTINE Manual_Load

\end{Verbatim}
This is a very simple example where the distribution function is a Maxwellian
which could have been set up using the {\bf MomentumFromTemperature} function
more easily, but it does demonstrate how the {\bf Sample\_Dist\_Function}
function works. It is not necessary to normalise the distribution function, as
this is done automatically by the {\bf Sample\_Dist\_Function} function.

\section{Customising \EPOCH}
This section details how to setup \EPOCH with additional parameters so that it
can be handed as a black box to new and/or inexperienced users. There are
various ways of doing this, ranging from simply giving the end user
parameterized input decks to adding new functions to the input deck parser. It
is assumed here that the end user will be using external (input deck) initial
conditions, otherwise simply point the end user to the internal autoloader
initial conditions in this manual.

\subsection{Parameterizing input decks}
The simplest way to allow someone to use \EPOCH as a black box is to give them
the input.deck and ic.deck files that control the setup and initial conditions
of the code. The input deck is simple enough that a quick read through of the
relevant section of the manual should make it fairly easy for a new user to
control those features of the code, but the initial conditions can be complex
enough to be require significant work on the part of an unfamiliar user to
understand. In this case, it can be helpful to use the ability to specify
constants in an input deck to parameterize the file. So to go back to a slight
variation on an earlier example


 \simpleboxverbatim
begin:species1
   #first set density in the range 0->1
   #cut down density in x direction
   rho=if ((x gt -1) and (x lt 1),1.0,0.2)
   #cut down density in y direction
   rho=if ((y gt -1) and (y lt 1),rho(1),0.2)

   #multiply density by real particle density
   rho=rho(1)*100.0

   #Set the temperature to be zero
   temp_x=0.0
   temp_y=temp_x(1)

   #Set the minimum density for this species
   minrho=0.3*100.0
end:species1

begin:species2
   #Just copy the density for species 1
   rho=rho(1)

   #Just copy the temperature from species 1
   temp_x=temp_x(1)
   temp_y=temp_y(1)

   #Set the minimum density for this species
   minrho=0.3*100.0
end:species2
\end{Verbatim}

The particle density (100.0) is hard coded into the deck file in several
places. It would be easier if this was given to a new useras

\simpleboxverbatim
begin:constant
   particle_density=100.0 #Particle number density
end:constant

begin:species1
   #first set density in the range 0->1
   #cut down density in x direction
   rho=if ((x gt -1) and (x lt 1),1.0,0.2)
   #cut down density in y direction
   rho=if ((y gt -1) and (y lt 1),rho(1),0.2)

   #multiply density by real particle density
   rho=rho(1)*particle_density

   #Set the temperature to be zero
   temp_x=0.0
   temp_y=temp_x(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species1

begin:species2
   #Just copy the density for species 1
   rho=rho(1)

   #Just copy the temperature from species 1
   temp_x=temp_x(1)
   temp_y=temp_y(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species2
\end{Verbatim}

It is also possible to parameterize other elements of initial conditions in a
similar fashion. This is actually a generally good idea, since it makes the
initial conditions easier to read an maintain.

\subsection{Using DEOs to further parameterize initial conditions}
Again this is just a readability change to the normal ic.deck file, but it
also makes changing and understanding external initial conditions rather
simpler. In this case, entire parts of the initial conditions are moved into a
DEO in order to make changing them at a later date easier. For example

\simpleboxverbatim
begin:constant
   particle_density=100.0 #Particle number density
end:constant

begin:deo
   profile_x=if((x gt -1) and (x lt 1),1.0,0.2)
   profile_y=if((y gt -1) and (y lt 1),1.0,0.2)
end:deo

begin:species1
   #multiply density by real particle density
   rho=particle_density * profile_x * profile_y

   #Set the temperature to be zero
   temp_x=0.0
   temp_y=temp_x(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species1

begin:species2
   #Just copy the density for species 1
   rho=rho(1)

   #Just copy the temperature from species 1
   temp_x=temp_x(1)
   temp_y=temp_y(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species2
\end{Verbatim}

Which creates the same output as before. It is now trivial to modify the profiles later, for example

\simpleboxverbatim
begin:constant
   particle_density=100.0 #Particle number density
end:constant

begin:deo
   profile_x=gauss(x,0.0,1.0)
   profile_y=gauss(y,0.0,1.0)
end:deo

begin:species1

   #multiply density by real particle density
   rho=particle_density * profile_x * profile_y

   #Set the temperature to be zero
   temp_x=0.0
   temp_y=temp_x(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species1

begin:species2
   #Just copy the density for species 1
   rho=rho(1)

   #Just copy the temperature from species 1
   temp_x=temp_x(1)
   temp_y=temp_y(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species2
\end{Verbatim}

changes the code to run with a Gaussian density profile rather then a step
function. Again, this can be extended as far as required.

\subsection{Adding new elements to the maths parser}
Sometimes the complexity in changing the ic.deck file is due to the fact that
a function which must be used is fairly complex in form and is not supplied
with the core code. It must therefore be represented in the input deck maths
parser. This can be a significant cause of complexity for some problems, and
in this case, there are three options : Put up with it and implement in the
deck, use the internal initial conditions rather than the deck or extend the
maths parser to include your function. Extending the maths parser can either
be permanent (described later in the manual) or temporary (described
here). Temporarily adding elements to the parser is much the easier. It is
possible to add new constants and functions to the maths parser. It is hoped
that in the next release of \EPOCH this will be extended to allow custom
operators as well.\\

As an example, lets looking at adding a new function (lorentz) for a
Lorentizan distribution, and adding a new constant, phi.

\subsubsection{Registering your new constant/function}
All of the routines used in extending the maths parser are in the file
src/user\_interaction/custom\_parser.f90.  Before a new constant or function
can be defined it must be registered. In the registration phase the text
representation of the function or constant is given to the parser subroutines
and the user is returned an integer handle for the registered object. The
numerical handle must be stored so that that all of the functions in this
module can access it, so they should be placed after the \inlinecode{IMPLICIT
NONE} statement at the top of the file and defined as

\simpleboxverbatim
INTEGER :: FUNC_LORENTZ
INTEGER :: CONST_PHI
\end{Verbatim}

Note that the names given to the constants is obviously at the developers
discretion, but these names comply with the \EPOCH style guide (the end of
this manual). Actually registering the objects is done in the
\inlinecode{RegisterObjects} subroutine. In this subroutine, should be put the
lines to register functions and constants, which should look like

\simpleboxverbatim
  SUBROUTINE RegisterObjects
       FUNC_LORENTZ=RegisterFunction("lorentz")
       CONST_PHI=RegisterConstant("phi")
  END SUBROUTINE RegisterObjects
\end{Verbatim}

Note that the input deck parser is case sensitive, so the strings which are
given to \inlinecode{RegisterFunction} and \inlinecode{RegisterConstant}
should be in the case that they will appear in the input deck. To follow the
\EPOCH style guide this should be all lowercase. At this point, the maths
parser would start to recognize the new function/constant, but would still
give error messages since they haven't been implemented yet.

\subsubsection{Setting up new constants}

Once a new constant has been registered it must be described using the
\inlinecode{CustomConstant} function. In 2D this function looks like

\simpleboxverbatim
  FUNCTION CustomConstant(opcode,ix,iy,errcode)
    INTEGER, INTENT(IN) :: opcode,ix,iy
    INTEGER, INTENT(INOUT) :: errcode
    REAL(num) :: CustomConstant

    !Leave these lines in place. They cause the code to throw an error if
    !The opcode is unknown
    CustomConstant=0.0_num
    errcode=IOR(errcode,ERR_UNKNOWN_ELEMENT)

  END FUNCTION CustomConstant
\end{Verbatim}

The parameters are

\begin{itemize}
\item opcode - The operator code of the constant requested. This will be the
  integer handle returned from \inlinecode{RegisterConstant}
\item ix,iy,iz - Some constants are actually evaluated at specific points in
  space, and ix,iy,iz are the gridpoint number of the location currently being
  evaluated. If you are just specifying a simple constant then just ignore
  these. If your constant does depend upon space then directly subscript your
  array with ix,iy,iz as needed to read the correct location.
\item errcode - The error code which is should be passed back to the
  parser. If for some reason you cannot evaluate your constant then you should
  \inlinecode{IOR} errcode with the appropriate error code (All the error
  codes are listed in appendix A). Note that errcode should never be SET to
  any specific error code when extending the parser, since this might
  overwrite errors put in place earlier in the parsing sequence. This is
  different to extending the input deck where the error code is set.
\end{itemize}

The function should just return the evaluated value of the constant requested
by \inlinecode{opcode}. This might look like

\simpleboxverbatim
  FUNCTION CustomConstant(opcode,ix,iy,errcode)
    INTEGER, INTENT(IN) :: opcode,ix,iy
    INTEGER, INTENT(INOUT) :: errcode
    REAL(num) :: CustomConstant

    IF (opcode == CONST_PHI) THEN
    	CustomConstant=pi
	RETURN
    ENDIF

    !Leave these lines in place. They cause the code to throw an error if
    !The opcode is unknown
    CustomConstant=0.0_num
    errcode=IOR(errcode,ERR_UNKNOWN_ELEMENT)

  END FUNCTION CustomConstant
\end{Verbatim}

Note that when \inlinecode{opcode} is successfully recognized, the code sets
the return value and returns straight away. This is how all constants should
work, since the last lines forces the function to return an error code. This
last line is in place to trap people registering constants but never defining
them, and without this line, it is possible to define a constant which is
never specified and have the code complete OK with a random value for that
constant.

The constant "phi" should now work fine when used anywhere in the input deck
and will return a value of $\pi$.

\subsubsection{Setting up new functions}

Setting up the new function \inlinecode{lorentz} is very similar to setting up
the new constant. The relevant function is \inlinecode{CustomFunction} and
when empty looks like

\simpleboxverbatim
  FUNCTION CustomFunction(opcode,ix,iy,errcode)
    INTEGER, INTENT(IN) :: opcode,ix,iy
    INTEGER, INTENT(INOUT) :: errcode
    REAL(num) :: CustomFunction
    REAL(num) :: Values(5)

    !Leave these lines in place. They cause the code to throw an error if
    !The opcode is unknown
    CustomFunction=0.0_num
    errcode=IOR(errcode,ERR_UNKNOWN_ELEMENT)

  END FUNCTION CustomFunction
\end{Verbatim}

The parameters are

\begin{itemize}
\item opcode - The operator code of the constant requested. This will be the
  integer handle returned from \inlinecode {RegisterFunction}
\item ix,iy,iz - Some functions are evaluated differently at specific points
  in space, and ix,iy,iz are the gridpoint number of the location currently
  being evaluated. If you are just specifying a simple function then just
  ignore these. If your function does depend upon space then directly
  subscript your array with ix,iy,iz as needed to read the correct location.
\item errcode - The error code which is should be passed back to the
  parser. If for some reason you cannot evaluate your function then you should
  \inlinecode{IOR} errcode with the appropriate error code. Note that errcode
  should never be SET to any specific error code, since this might overwrite
  errors put in place earlier in the parsing sequence.
\end{itemize}

The function should return the value of your evaluated constant. The
parameters which are passed to the function can be retrieved by the function
\inlinecode {GetValues(n,values)}, where \inlinecode {n} is the number of
parameters to be returned and \inlinecode{values} is a \inlinecode{REAL(num)}
array of length \inlinecode{n} which will hold the returned values .  In this
implementation of the Lorentizian function there are three parameters : The
dependent variable, the location parameter and the scale parameter. The code
to implement the function therefore looks like

\simpleboxverbatim
  FUNCTION CustomFunction(opcode,ix,iy,errcode)
    INTEGER, INTENT(IN) :: opcode,ix,iy
    INTEGER, INTENT(INOUT) :: errcode
    REAL(num) :: CustomFunction
    REAL(num) :: Values(5)

    IF (opcode == FUNC_LORENTZ) THEN
    	CALL GetValues(3,Values(1:3))
	!Values(1) - Dependent variable
	!Values(2) - location parameter
	!Values(3) - scale parameter
	CustomFunction=Values(3)**2/((Values(1)-Values(2))**2+Values(3)**2)
	RETURN
    ENDIF

    !Leave these lines in place. They cause the code to throw an error if
    !The opcode is unknown
    CustomFunction=0.0_num
    errcode=IOR(errcode,ERR_UNKNOWN_ELEMENT)

  END FUNCTION CustomFunction
\end{Verbatim}

This function is then available at any point in the input deck and if I return
to the previous example ic.deck file, it would be used as follows

\simpleboxverbatim
begin:constant
   particle_density=100.0 #Particle number density
end:constant

begin:deo
   profile_x=lorentz(x,0.0,1.0)
   profile_y=lorentz(y,0.0,1.0)
end:deo

begin:species1
   #multiply density by real particle density
   rho=particle_density * profile_x * profile_y

   #Set the temperature to be zero
   temp_x=0.0
   temp_y=temp_x(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species1

begin:species2
   #Just copy the density for species 1
   rho=rho(1)

   #Just copy the temperature from species 1
   temp_x=temp_x(1)
   temp_y=temp_y(1)

   #Set the minimum density for this species
   minrho=0.3*particle_density
end:species2
\end{Verbatim}

It is therefore clear that the new lorentz function is essentially the same as
the built in gauss function. Note that due to the way that the parser works,
the end user is not required to deal with parameters which are themselves
maths expressions, they have been fully evaluated by the time they are
returned by \inlinecode{GetValues}. Note that the parser is not guaranteed to
be bulletproof. If a user calls \inlinecode{GetValues} requesting more
parameters than have been passed to the function then it will scramble the
stack which is used by the parser and cause the code to fail. Note that
calling \inlinecode{GetValues(2,Values)} is not the same as calling
\inlinecode{GetValues(1,Values)} twice, in fact calling
\inlinecode{GetValues(1,Values)} multiple times will return the parameters in
{\it reverse} order. This is normal and is a feature of how the maths parser
operates. It is possible to use this property to write functions which have a
variable number of parameters, but this is not recommended.

\subsection{Adding new elements to the input deck}

For some types of changes to the code it is more convenient to have the end
user pass new parameters into the code. This can be for several reasons, and
the section on permanent additions to the input deck is later in this
manual. At this stage, this manual will describe how to temporarily add new
elements to the input deck parser routines, allowing parameterizing of
internal and manual initial conditions.

Custom input deck elements are setup in the file
\inlinecode{src/user\_interaction/custom\_deck.f90}. The function
\inlinecode{HandleCustomBlock} is called when a new block is started which the
core parser is not familiar with, and once for each element of a block. The
function \inlinecode{CheckCustomBlocks} is called once then entire deck has
been parsed and is used to check that all the elements which are required for
the code to run.

\subsubsection{HandleCustomBlock}
There are three parameters passed to \inlinecode{HandleCustomBlock}, which are
\begin{itemize}
\item blockname - The name of the block specified in the
  \inlinecode{begin:blockname} part of the input deck.
\item Element - The name of the element in an input deck
  \inlinecode{element=value} pair.
\item Value - The string representation of the value in an input deck
  \inlinecode{element=value} pair.
\end{itemize}

\inlinecode{HandleCustomBlock} is first called when a new block is begun
\inlinecode{begin:blockname} which cannot be recognized by the core input deck
parser. The first thing that it does is test whether or not it is a valid
custom block. The code does this by passing in the blockname with
\inlinecode{Element} and \inlinecode{Value} set to the special constant called
"Blank". When extending the input deck, an end user should check for either
\inlinecode{Element} or \inlinecode{Value} begin the special constant Blank
and if they are then test to see whether the blockname is known or not. If the
blockname is known then the code should return the error code
\inlinecode{ERR\_NONE} (No error), if the blockname is not known then the code
should return \inlinecode{ERR\_UNKNOWN\_BLOCK} and the deck parser will just
skip the block. In operation, this looks like

\simpleboxverbatim
  FUNCTION HandleCustomBlock(blockname,Element,Value)

    CHARACTER(len=entrylength),INTENT(IN)::blockname,Element,Value
    INTEGER :: HandleCustomBlock
    TYPE(primitivestack) :: output
    INTEGER :: ix,iy
    IF (StrCmp(blockname,"custom")) THEN
    	IF (Element == Blank .OR. Value == Blank) THEN
              !If element or value are blank, then just testing block so return ERR_NONE
              HandleCustomBlock=ERR_NONE
              RETURN
         ENDIF
     ENDIF

    !The following line must always be present
    HandleCustomBlock=ERR_UNKNOWN_BLOCK

  END FUNCTION HandleCustomBlock
\end{Verbatim}

In order to simply Fortran's rather annoying string handling behaviour several
helper functions have been defined, and the most used one is
\inlinecode{StrCmp(String1,String2)} which is a simple routine which returns
true if String1==String2 and false otherwise. It is case sensitive but can
deal with differing string lengths etc. The next stage is to deal with the
actual \inlinecode{Element=Value} pairs in the deck. Each time that a new pair
is read from the deck \inlinecode{HandleCustomBlock} is called with
\inlinecode{Element} and \inlinecode{Value} having the values read from the
deck. To test for known elements they should just be checked against a known
list of names using \inlinecode{StrCmp} and return the error code
\inlinecode{ERR\_UNKNOWN\_ELEMENT} if the element isn't a known element. This
looks like

\simpleboxverbatim
  FUNCTION HandleCustomBlock(blockname,Element,Value)

    CHARACTER(len=entrylength),INTENT(IN)::blockname,Element,Value
    INTEGER :: HandleCustomBlock
    TYPE(primitivestack) :: output
    INTEGER :: ix,iy
    IF (StrCmp(blockname,"custom")) THEN
    	IF (Element == Blank .OR. Value == Blank) THEN
              !If element or value are blank, then just testing block so return ERR_NONE
              HandleCustomBlock=ERR_NONE
              RETURN
         ENDIF
         HandleCustomBlock=ERR_UNKNOWN_ELEMENT
         !Now test for the real elements
         IF (StrCmp(Element,"int_element")) THEN
             HandleCustomBlock=ERR_NONE
         ENDIF
         IF (StrCmp(Element,"real_element")) THEN
             HandleCustomBlock=ERR_NONE
         ENDIF
         IF (StrCmp(Element,"logical_element")) THEN
             HandleCustomBlock=ERR_NONE
         ENDIF
         RETURN
     ENDIF

     !The following line must always be present
     HandleCustomBlock=ERR_UNKNOWN_BLOCK

  END FUNCTION HandleCustomBlock
\end{Verbatim}

This version of the code will allow you to add a new block called "custom"
with elements "int\_element", "real\_element" and "logical\_element" and the
code will parse them successfully, while any other block or any other element
in the block "custom" will throw errors. However at this stage, the code
doesn't actually read any of the values from the deck. To make it useful, any
variable which is read from the input deck must be stored in a global
variable. Defining global variables are explained in more detail in the
relevant section of the manual, but in short any variable defined in the
module \inlinecode{shared\_data} in the file \inlinecode{src/shared\_data.F90}
will be a global variable. Once the variables have been setup, there are once
again helper functions to make converting the text from the deck into a normal
Fortran90 variable. These helper functions are

\begin{itemize}
\item AsInteger - Attempts to convert a string to an integer. Invokes the
  maths parser.
\item AsReal - Attempts to convert a string to a REAL(num). Invokes the maths
  parser.
\item AsLogical - Attempts to convert a string to a logical. Does not invoke
  the maths parser (must be either T or F).
\end{itemize}

They are used pretty much as expected, except that the return value is passed
to the functions so that they can report errors while trying to parse the
string. An example would then be

\simpleboxverbatim
  FUNCTION HandleCustomBlock(blockname,Element,Value)

    CHARACTER(len=entrylength),INTENT(IN)::blockname,Element,Value
    INTEGER :: HandleCustomBlock
    TYPE(primitivestack) :: output
    INTEGER :: ix,iy
    IF (StrCmp(blockname,"custom")) THEN
    	IF (Element == Blank .OR. Value == Blank) THEN
	     !If element or value are blank, then just testing block so return ERR_NONE
	     HandleCustomBlock=ERR_NONE
	     RETURN
	 ENDIF
	 HandleCustomBlock=ERR_UNKNOWN_ELEMENT
	 !Now test for the real elements
	 IF (StrCmp(Element,"int_element")) THEN
	     HandleCustomBlock=ERR_NONE
	     int_element=AsInteger(Value,HandleCustomBlock)
	 ENDIF
	 IF (StrCmp(Element,"real_element")) THEN
	     HandleCustomBlock=ERR_NONE
	     real_element=AsReal(Value,HandleCustomBlock)
	ENDIF
	IF (StrCmp(Element,"logical_element")) THEN
	    HandleCustomBlock=ERR_NONE
	    logical_element=AsLogical(Value,HandleCustomBlock)
	    ENDIF
	RETURN
    ENDIF

    !The following line must always be present
    HandleCustomBlock=ERR_UNKNOWN_BLOCK

  END FUNCTION HandleCustomBlock
\end{Verbatim}

It is possible to perform more advanced types of evaluation of maths
expressions such as reading arrays etc. but this is beyond the scope of this
manual at present. Hopefully future releases of the manual will explain how
this would be implemented.

\subsubsection{CheckCustomBlocks}
This function is called when all the blocks in the input deck have been
evaluated and is used to check that all required parameters have been set. If
all required elements have been set then you should just return
\inlinecode{ERR\_NONE}, otherwise, return
\inlinecode{ERR\_MISSING\_ELEMENTS}. How you test that required elements have
been set is up to the developer, and for testing and personal use (which is
all that the custom deck parts of the code should be used for) it is
acceptable to just not check and always return \inlinecode{ERR\_NONE}. If
permanently expanding the deck error trapping should always be written.

\input{./devtitle.tex}

\section{\EPOCH developers manual}
This section of the manual is intended for people who intend to develop \EPOCH
to extend or modify existing features, add new diagnostics or develop new
physics packages. It is expected that anyone reading this part of the manual
will be familiar with the material covered in the main manual, particularly
the notices about the layout of particle, particlelist and particlefamily
structures in the "\EPOCH for advanced end users" section of the main
manual. A good working knowledge of linked lists is also critical to the
understanding of the code and again an introduction to linked lists is given
in the "\EPOCH for advanced end users" section.

A quick note : Some files have the normal Fortran file extension .f90, while
some have the slightly unusual .F90. The difference is that files with the
.F90 extension are passed through the preprocessor before they are compiled
allowing the user of precompiler directives (the \#ifdef commands).

\section{General layout of the \EPOCH code}

The names of the source files in \EPOCH are fairly self explanatory, but for
clarity, they are explained here.

\subsection{Directories}
All source files are contained in the \inlinecode{src} directory and it's
subdirectories. There is a stylistic reason for the layout of the files, which
is explained here

\begin{itemize}
\item \inlinecode{src} - Files in this directory are the core files for the
  basic \EPOCH code, such as the field solvers, the particle pusher, the
  boundary conditions and the lasers.
\item \inlinecode{src/deck} - Files in this directory are responsible for
  dealing with the permanent input deck parser, and include the core parts of
  the deck handler and also the routines which deal with the blocks in the
  input, initial conditions and extended IO deck files.
\item \inlinecode{src/housekeeping} - Files in this directory deal with those
  parts of the operation of the code which are not physics, including the load
  balancer, the MPI setup routines and the moving window.
\item \inlinecode{src/io} - The files involved in all IO activities, including
  the distribution functions and the particle probes.
\item \inlinecode{src/multigrid} - The files for the multigrid solver for
  Poisson's equation. These routines are only used initially if the flag
  "neutral\_background" is set to false.
\item \inlinecode{src/parser} - The files for the maths expression parser are
  in here, including both the core implementation of the shunting yard
  algorithm and the routines for implementing the permanent functions,
  constants and operators for the input deck.
\item \inlinecode{src/physics\_packages} - Contains routines which implement
  additional physics for the code.
\item \inlinecode{src/user\_interaction} - Contains any Fortran routines which
  a user has to modify to use the code with internal initial conditions, or to
  temporarily extend the maths parser or the input deck.
\end{itemize}

\subsection{The files in \inlinecode{src}}
\begin{itemize}
\item boundary.f90 - Includes all boundary conditions except laser and
  transmissive boundaries, including field and particle MPI boundaries and
  field and particle domain boundaries.
\item epoch\{n\}d.F90 - Main driver for the code. Reading this routine give
  the basic layout of the code flow.
\item fields.f90 - The Maxwell field solver
\item laser.f90 - Includes laser and transmissive boundary conditions for each
  boundary and also the housekeeping routines for the laser objects.
\item particles.F90 - The particle pusher
\item shared\_data.F90 - This file includes all the global variable and type
  definitions. Usually new variables should be defined in this file.
\end{itemize}

\subsection{The files in \inlinecode{src/deck}}
\begin{itemize}
\item deck.F90 - The main input deck routines. Deals with opening files,
  reading data and MPI distribution of the data to all processes. Also
  includes the routines which deal with calling the right reader routines to
  deal with a given block.
\item deck\_boundaries\_block.f90 - Reader routine for the "boundaries" block
  of the input deck
\item deck\_constant\_block.f90 - Reader routine for "constants" blocks in the
  input deck.
\item deck\_control\_block.f90 - Reader routine for "control" block in the
  input deck.
\item deck\_deo\_block.f90 - Reader routine for "deo" blocks in the input
  deck.
\item deck\_eio\_dist\_fn\_block.f90 - Reader routine for "dist\_fn" blocks in
  the extended io deck.
\item deck\_eio\_particle\_probe\_block.f90 - Reader routine for
  "particle\_probe" blocks in the extended io deck.
\item deck\_ic\_external\_block.f90 - Reader routines for "species\_external"
  and "field\_external" blocks in the initial conditions deck.
\item deck\_ic\_fields\_block.f90 - Reader routine for "fields" blocks in the
  initial conditions deck.
\item deck\_ic\_laser\_block.f90 - Reader routine for "laser" blocks in the
  initial conditions deck.
\item deck\_ic\_species\_block.f90 - Reader routine for "species" blocks in
  the initial conditions deck.
\item deck\_io\_block.F90 - Reader routine for the "io" block in the input
  deck.
\item deck\_species\_block.F90 - Reader routine for the "species" block in the
  input deck.
\item deck\_window\_block.f90 - Reader routine for the "window" block in the
  input deck.
\item strings.F90 - Basic string handling routines such as "StrCmp" and
  routines for converting strings to numbers WITHOUT using the maths parser
  are covered in this routine.
\item strings\_advanced.F90 - The routines which pass maths along to the maths
  parser routines are here.
\end{itemize}

\subsection{The files in \inlinecode{src/housekeeping}}
\begin{itemize}
\item balance.F90 - Contains the routines for the load balancer and related
  routines.
\item mpi\_routines.f90 - Contains the routines dealing with the setup of the
  MPI layer and the creation of the communicator. Also allocates all arrays
  for the first time before load balancing.
\item mpi\_subtype\_control.F90 - Contains the routines that setup the mpi
  types required by the IO subsystem.
\item particlepointeradvance.F90 - Contains subroutines which walk through the
  lists of particles and species for IO purposes.
\item partlist.F90 - Contains the routines which deal with the particle lists
  which are used for interprocessor communication of particles.
\item setup.F90 - Deals with the setup of the grids and domains and restarting
  from previous output dumps.
\item split\_particles.F90 - Is the implementation of a demonstration of
  particle splitting routines.
\item welcome.F90 - The routine which prints the banner message and compiler
  options info.
\item window.F90 - The routines which deal with the moving window.
\end{itemize}

\subsection{The files in \inlinecode{src/io}}
\begin{itemize}
\item calc\_df.F90 - Despite the slightly confusing name, this subroutine
  deals with derived functions like number density, charge density and mass
  density.
\item diagnostics.F90 - Contains the routines which actually dump the data,
  decide what to dump and also the routine to calculate the timestep.
\item dist\_fn.F90 - Contains the routines to calculate the distribution
  functions, and also the routines handling the requests for distribution
  functions.
\item input.f90 - Core part of the CFD file format. Contains the general
  routines needed for reading data from CFD files.
\item input\_arb.f90 - Core part of the CFD file format. Contains the routines
  needed to read arbitrary data blocks from CFD files.
\item input\_cartesian.f90 - Core part of the CFD file format. Contains the
  routines needed to read Cartesian meshes and variables from CFD files.
\item input\_particle.f90 - Core part of the CFD file format. Contains the
  routines needed to read particles meshes and variables from CFD files.
\item inputfunctions.f90 - Core part of the CFD file format. Contains the
  routines needed to traverse the block structure of a CFD file without
  reading any block specific metadata.
\item iocommon.f90 - Core part of the CFD file format. Contains constants and
  definitions needed by the CFD format. If attempting to implement a CFD
  reader then look here for values of named constants.
\item iocontrol.f90 - Core part of the CFD file format. Contains the routines
  needed to open and close files etc.
\item iterators.f90 - Contains the iterator functions used to write particle
  data into CFD files.
\item output.f90 - Core part of the CFD file format. Contains the basic
  routines needed to write data to a CFD file.
\item output\_arb.f90 - Core part of the CFD file format. Contains the
  routines needed to write arbitrary data blocks to a CFD file.
\item output\_cartesian.f90 - Core part of the CFD file format. Contains the
  routines needed to write Cartesian meshes and variables.
\item output\_particles.f90 - Core part of the CFD file format. Contains the
  routines needed to write particles meshes and variables.
\item probes.F90 - Contains the routines which write the data from the
  particle probes. Also includes the routines which deal with user requests to
  add new particle probes.
\end{itemize}

\subsection{The files in \inlinecode{src/multigrid}}
\begin{itemize}
\item FMC\_MPI.f90 - Implements the full-multigrid-cycle algorithm using a W
  cycle to solve Poisson's equation.
\item solve\_gauss.f90 - Sets up and runs the multigrid algorithm and the
  calculates the electric fields.
\end{itemize}

\subsection{The files in \inlinecode{src/parser}}
\begin{itemize}
\item evaluate.f90 - Contains the routines which actually evaluate a tokenized
  expression. The core of this is a simple implementation of an RPN
  calculator.
\item evaluator\_blocks.f90 - Contains the routines which evaluate a given
  token into a numerical values. Actually implements the functions, constants
  and operators in EPOCH's maths parser.
\item shunt.F90 - EPOCH's implementation of the "shunting yard" algorithm used
  to simultaneously tokenize the input and convert it from infix notation to
  RPN.
\item stack.f90 - Deals with routines for poping and pushing off and onto
  stacks.
\item tokenizer\_blocks.f90 - Deal with converting strings found in a string
  being tokenized into tokens. Essentially a large collection of "StrCmp"
  commands testing a string against a known name.
\end{itemize}

\subsection{The files in \inlinecode{src/parser}}
\begin{itemize}
\item ionise.F90 - This is a demonstration of how to implement a physics
  package. It implements a field ionisation routine using a 1 level Saha
  equation. It is more intended of a demonstration of how a physics package
  could be implemented that a "research ready" ionisation routine.
\end{itemize}

\subsection{The files in \inlinecode{src/user\_interaction}}
\begin{itemize}
\item control.F90 - The file which allows the code to be compiled entirely
  without an input deck. If the code is compiled in this fashion then this
  file contains all the data which would otherwise be in the "input.deck"
  file.
\item custom\_deck.f90 - This file is where and end user can temporarily
  extend the input deck. Described in the "Extending EPOCH" section.
\item custom\_laser.f90 - The file where an end user specifies laser time
  profiles without using the input deck.
\item custom\_parser.f90 - The file where an end user can temporarily add new
  functions and constants to the input deck. It is described in the "Extending
  EPOCH" section of this manual.
\item helper.F90 - This file contains all the internal workings of the
  autoloader. This is in user\_interaction for historical reasons, since early
  versions of the code required the end user to modify some parts of the
  functions contained in this file. As the autoloader has increased in
  complexity, this has ceased to be the case, so it is likely that soon this
  file will be move to "housekeeping"
\item initial\_conditions.f90 - This file is where the internal and manual
  initial conditions are set.
\end{itemize}

\section{\EPOCH makefile}
The makefile supplied with \EPOCH is a standard GNU make makefile, which must
be user modified to allow a developer to add new files to the code. EPOCH's
makefile is quite large, so an explanation of how to add new files and new
directories is given below.

\subsection{Adding a new file to be compiled with \EPOCH}
There are three things that must be done to cause \EPOCH to compile a new file
into the final code. Assume that you're adding a file called
"newfile.F90". First, find the line which sets the environment variable
\inlinecode{OBJFILES} and add a new parameter which reads\\
\\
newfile.o\\
\\ This tells the makefile to compile the final code using your new file, the
next thing to do is to add a line which tells the code about the dependencies
for your file. Lower down in the makefile, you'll find a section with lines
which look like
\simpleboxverbatim
iocontrol.o:iocontrol.f90 iocommon.o input.o output.o shared_data.o
\end{Verbatim}
Add a new line for describing all the FILES (NOT modules) which are used by
your new file. If you USE shared\_data, mpi\_subtype\_control and stack in
your file then the line would look like
\simpleboxverbatim
newfile.o:newfile.F90 shared_data.o mpi_subtype_control.o stack.o
\end{Verbatim}
Note the structure of the line with ONLY the source file for the new file
specified, all other used files specify the intermediate .o files. The
remaining element of the makefile which needs to be modified is to add your
new file as a dependency to all the files which USE modules contained in your
new file. This is achieved very simply by adding "newfile.o" to the dependency
list for those files which USE your modules. For example if you've written new
IO routines and USE your modules in diagnostics, you'd just change the line
for diagnostics from

\simpleboxverbatim
diagnostics.o:diagnostics.F90 shared_data.o boundary.o input.o \
	output.o iocontrol.o iocommon.o output_particle.o \
	output_cartesian.o output_arb.o balance.o iterators.o dist_fn.o \
	calc_df.o probes.o mpi_subtype_control.o
\end{Verbatim}
to
\simpleboxverbatim
diagnostics.o:diagnostics.F90 shared_data.o boundary.o input.o\
	 output.o iocontrol.o iocommon.o output_particle.o \
	output_cartesian.o output_arb.o balance.o iterators.o dist_fn.o \
	calc_df.o probes.o mpi_subtype_control.o \
	newfile.o
\end{Verbatim}

Note that the backslash characters are line continuation marks in makefiles.

\subsection{Adding new directories to EPOCH's makefile}
If you want to add an entire new directory to the \EPOCH compile path then you
need to add it to the definition of the environment variable
\inlinecode{VPATH}. Remember to use the environment variable \inlinecode{\$
(SRCDIR)} rather than hardcoding \inlinecode{src} into the path.

\section{\EPOCH core programming}
\EPOCH is designed so that it can fairly easily be extended while still being
written in (more or less) standard Fortran90 and MPI1.2. This section details
in increasing complexity what a programmer needs to know to extend \EPOCH with
new diagnostics, new physics or even new core solvers. The first few entries
in this section range between style points and explanations of fairly trivial
parts of the \EPOCH code, but the end of this section gives an overview of how
one would perform major changes to the complete \EPOCH core solver.

\subsection{Physical constants}
In order to ensure that different parts of the code run at the same precision
common physical constants are defined in \inlinecode{shared\_data.F90} and any
new physical constants required by extensions to the code should be placed in
the same location. The constants available in the code are
\begin{itemize}
\item Q0 - Charge on electron
\item M0 - Rest mass of electron
\item C - Speed of light in vaccum
\item kb - Boltzmann's constant
\item epsilon0 - Permittivity of free space
\item mu0 - Permeability of free space.
\item h\_planck - Plank's constant
\item ev - The value of an electron volt
\end{itemize}

Any new constants required should be specified in the same place in
\inlinecode{shared\_data.F90}.

\subsection{Important variables, arrays and array length}
As well as the physical constants, there are some important variables which
you will have to use to do any development with \EPOCH. As a general note,
since \EPOCH is written with separate 1D, 2D and 3D versions, definitions will
be given for the 3D version of the code and irrelevant dimensions should just
be cut out.

\subsubsection{Shape and size variables}
\begin{itemize}
\item INTEGER :: nx. ny, nz - The number of gridpoints on the current
  processor in each direction. This may change when the load balancer
  activates, so always use these variables rather than local copies.
\item INTEGER :: nx\_global, ny\_global, nz\_global - The number of gridpoints
  in each direction of the whole domain. These numbers will never change and
  will be the numbers read in from the input deck.
\item INTEGER(KIND=8) :: npart\_global - The global number of particles
  specified in the input deck. This is not updated as particles leave the
  domain through boundaries etc. so it is not guaranteed to be accurate.
\item INTEGER :: nSpecies - The number of species of particles specified.
\item INTEGER :: nSteps - The maximum number of steps that the core solver
  should take.
\item INTEGER,DIMENSION(1:nproc\_{\it direction}),ALLOCATABLE :: cell\_{\it
    direction}\_start, cell\_{\it direction}\_end - Replace direction with one
  of x, y, z and see note at end
\item INTEGER :: data\_dir\_max\_length - The maximum number of characters in
  the name of the output directory.
\item INTEGER :: nZeros - The number of leading zeros in the output filenames
  from \EPOCH.
\end{itemize}
The variables \inlinecode{cell\_{\it direction}\_start} and
\inlinecode{cell\_{\it direction}\_end} represent the part of a global array
which is held by the current processor. Since \EPOCH is an MPI code, there
doesn't exist a single copy of any of the global arrays anywhere, but if there
did then each processor would be responsible for the slice which runs\\
(cell\_x\_start(rank):cell\_x\_end(rank),
cell\_y\_start(rank):cell\_y\_end(rank),
cell\_z\_start(rank):cell\_z\_end(rank))\\
These variables are used internally in the load balancer, where it is updated,
but is also used when calculating distribution functions, where it is used to
define the extents of the MPI type which is used to write the distribution
function to disk.
\pagebreak

\subsubsection{Input deck variables}
\begin{itemize}
\item CHARACTER(LEN=Entry\_Length) :: Blank - A special string which the input
  deck parser uses to indicate that it's passing a blank string rather than a
  string read from the deck which just happens to be blank.
\item INTEGER :: Deck\_State - An integer determining which type of input deck
  is being read by the deck parse
\item INTEGER,PARAMETER :: num\_vars\_to\_dump - A variable describing the
  number of variable which should be selectable in the input deck as possible
  variables to dump.
\item CHARACTER(LEN=Entry\_Length) :: Extended\_Error\_String - String used by
  some error codes in the deck parser to give more user friendly error
  messages.
\item CHARACTER(LEN=Entry\_Length) :: Project\_Name - String read from the
  input deck and written into the output files to allow the project to be
  recognised by a reader.
\end{itemize}
\pagebreak

\subsubsection{Initial conditions (autoloader) variables}
Initial conditions for the autoloader for a given species are described in
\EPOCH by the Fortran TYPE \inlinecode{Initial\_Conditions\_Block}. The
definition (in 3D) is

\simpleboxverbatim
  TYPE :: Initial_Condition_Block

     REAL(num),DIMENSION(:,:,:),POINTER :: Rho
     REAL(num),DIMENSION(:,:,:,:),POINTER :: Temp

     REAL(num) :: minrho
     REAL(num) :: maxrho

  END TYPE Initial_Condition_Block
\end{Verbatim}

In 1D, the arrays have one fewer index, and in 3D they have one more.
\begin{itemize}
\item REAL(num) :: Rho - NUMBER density for the particles in the species. When
  defined runs (-2:nx+3,-2:ny+3,-2:nz+3)
\item REAL(num) :: Temp - Temperature in Kelvin of the species in space. When
  defined runs (-2"nx+3, -2:ny+3, -2:nz+3,1:3). The final index of the array
  is a direction index, used to give anisotropic thermal distributions.
\item minrho - The minimum density below which the autoloader should not load
  particles.
\item maxrho - The maximum density above which the autoloader should clip the
  density function
\end{itemize}

The initial conditions themselves are in the variable
\simpleboxverbatim
  TYPE(Initial_Condition_Block),DIMENSION(:),ALLOCATABLE :: InitialConditions
\end{Verbatim}
which is allocated \inlinecode{1:nSpecies}
\pagebreak

\subsubsection{Particles and particle species}
Particles are represented as linked lists of Fortran TYPES. The definition of
the particle type is
\simpleboxverbatim
  !Object representing a particle
  TYPE :: Particle
     REAL(num), DIMENSION(3) :: Part_P
     REAL(num),DIMENSION(2) :: Part_pos
#ifdef PER_PARTICLE_WEIGHT
     REAL(num) :: weight
#endif
#ifdef PER_PARTICLE_CHARGEMASS
     REAL(num) :: charge
     REAL(num) :: mass
#endif
     TYPE(Particle),POINTER :: Next, Prev
#ifdef PART_DEBUG
     INTEGER :: Processor
     INTEGER :: Processor_at_t0
#endif
  END TYPE Particle
\end{Verbatim}
And the descriptions are
\begin{itemize}
\item REAL(num) :: Part\_P(3) - The particle momentum. Always dimension 3 even
  in 1D and 2D codes.
\item REAL(num) :: Part\_pos({\it ndims}) - The particle position. Has
  dimensions of dimensonality of the code.
\item REAL(num) :: weight - The particle weight if the code is running with
  per particle weighting.
\item REAL(num) :: charge - The particle charge in Coulombs if the code is
  running with per particle charge.
\item REAL(nun) :: Mass - The particle mass in kilograms if the code is
  running with per particle mass.
\item TYPE(Particle),POINTER :: Next, Prev - The pointers to the next and
  previous elements of the linked list.
\item INTEGER :: Processor - The rank of the processor that the particle
  thinks it is on. Used for debugging.
\item INTEGER :: Processor \_at\_t0 - The rank of the processor that the
  particle started on. Used for debugging.
\end{itemize}
Simply adding a new parameter to the definition of the particle type is NOT
sufficient to extend the particle type, since the communications when the
particle crosses a processor boundary do not know about the new parameter and
it will not be transmitted with the particle. How to add new properties to the
particle communication layer is described later.\\
\pagebreak

The entire linked list of particles is encapsulated in another Fortran TYPE,
called \inlinecode{ParticleList}, which is defined as
\simpleboxverbatim
  !Object representing a collection of particles
  !Used internally by the MPI particle transfer code
  TYPE :: ParticleList
     TYPE(Particle),POINTER :: Head
     TYPE(Particle),POINTER :: Tail
     INTEGER(KIND=8) :: Count
     !Pointer is safe if the particles in it are all unambiguously linked
     LOGICAL :: Safe

     TYPE(ParticleList), POINTER :: Next, Prev
  END TYPE ParticleList
\end{Verbatim}
And the descriptions are
\begin{itemize}
\item TYPE(Particle),POINTER :: Head - The first particle in the linked list.
\item TYPE(Particle),POINTER :: Tail - The last particle in the linked
  list. New particles added to the end of the list are added onto the end of
  the tail element, and the new last particle becomes the new tail element.
\item INTEGER(KIND=8) :: Count - The number of particles in this particle
  list. Note that the \inlinecode{particlelist} type is not directly MPI
  aware, so this is literally the number of particles in {\it this} particle
  list, not the number of particles of this species on all processors.
\item LOGICAL :: Safe - A particle list is {\it safe} if the particles in it
  are unambiguously linked. That is that the \inlinecode{Count}th particle is
  guaranteed to have it's \inlinecode{Next} property be null. Most particle
  lists within \EPOCH are safe, but sometimes it is useful to be able to have
  particle lists which are subsets of longer particles lists, and these
  particle lists are not {\it safe}.
\item TYPE(ParticleList),POINTER :: Next, Prev - At present, \EPOCH does not
  use these pointers, which are intended to allow multiple particle lists to
  be attached together. Certain parts of EPOCH, such as the IO system are
  aware of these pointers and will automatically use them if they are ever
  set. They are reserved for future use.
\end{itemize}
\pagebreak

The \inlinecode{ParticleList} objects are used to abstract all the functions
of the linked list, including adding and removing particles and transporting
particles between processors.\\
\\
The particle species are represented by yet another Fortran TYPE, this time
called \inlinecode{ParticleFamily}, which is defined as
\simpleboxverbatim
  !Object representing a particle species
  TYPE :: ParticleFamily
     !Core properties
     CHARACTER(EntryLength) :: Name
     TYPE(ParticleFamily),POINTER :: Next,Prev
     INTEGER :: ID
     LOGICAL :: Dump

     REAL(num) :: Charge
     REAL(num) :: Mass
     INTEGER(KIND=8) :: Count
     TYPE(ParticleList) :: AttachedList

#ifdef TRACER_PARTICLES
     LOGICAL :: Tracer
#endif

     !Particle cell division
#ifdef PARTICLE_CELL_DIVISION
     LOGICAL :: Split
     INTEGER(KIND=8) :: npart_max
#endif
     !Secondary list
#ifdef USE_SECONDARY_LIST
     TYPE(ParticleList),DIMENSION(:,:,:),POINTER :: SecondaryList
#endif

     !Injection of particles
     INTEGER(KIND=8) :: npart_per_cell
     REAL(num),DIMENSION(:,:),POINTER :: Density
     REAL(num),DIMENSION(:,:,:),POINTER :: Temperature

     !Species_ionisation
#ifdef PART_IONISE
     LOGICAL :: ionise
     INTEGER :: ionise_to_species
     INTEGER :: release_species
     REAL(num) :: ionisation_energy
#endif
     !Attached Probes for this species
#ifdef PARTICLE_PROBES
     TYPE(Particle_Probe),POINTER :: AttachedProbes
#endif
  END TYPE ParticleFamily
\end{Verbatim}
Again, most of these properties are self explanatory, but they are detailed
below
\begin{itemize}
\item CHARACTER(LEN=EntryLength) :: Name - The name of the particle
  species. Used when constructing things like "ekbar\_electron" and similar
  names.
\item TYPE(ParticleFamily),POINTER :: Next, Prev - Particle species are
  connected to each other as a linked list using pointers as well as being
  available through a simple array. These pointers are used behind the scenes
  in the IO.
\item INTEGER :: ID - The number of the species, so for the species
  \inlinecode{ParticleSpecies(1)}, the ID field would be 1. For
  \inlinecode{ParticleSpecies(2)}, the ID field would be 2 etc.
\item LOGICAL :: Dump - Whether or not this species should be dumped in
  diagnostic output.
\item REAL(num) :: Charge - The charge on a single particle of the species in
  Coulombs
\item REAL(num) :: Mass - The mass of a single particle of the species in
  kilograms.
\item INTEGER(KIND=8) :: Count - The number of particles of this species on
  all processors. NOTE that this is only accurate if the code is compiled with
  the correct preprocessor options. Without the correct preprocessor options,
  this will be accurate at the start of the code runtime, but will not be if
  any particles enter or leave the domain. This is mainly a debugging
  parameter.
\item TYPE(ParticleList) :: AttachedList - This is the
  \inlinecode{ParticleList} object which holds the particles assigned to this
  species on this processor. Particles are attached to this list at all times
  EXCEPT when they are explicitly split when the code is compiled with the
  \inlinecode{PARTICLE\_CELL\_DIVISION}. When the code is compiled with
  \inlinecode{PARTICLE\_CELL\_DIVISION} then the particles are attached to
  \inlinecode{AttachedList} except between the calls to
  \inlinecode{Reorder\_Particles\_To\_Grid} and
  \inlinecode{Reattach\_Particles\_To\_mainlist} in \inlinecode{epoch{\it
      n}d.F90} where the particles are instead attached to
  \inlinecode{SecondaryList} which is explained later.
\item LOGICAL :: Tracer - Whether or not this species is a tracer particle. If
  a species is a tracer species then it moves under the fields as normal for a
  particle with it's mass and charge but contributes no current.
\item LOGICAL :: Split - \EPOCH includes a very early version of a particle
  splitting operator. It works mechanically but has undesirable properties at
  present. If this flag is true then the code attempts to split the particles
  when the pseudoparticle number density drops too low.
\item INTEGER(KIND=8) :: npart\_max - Used with the particle splitting
  operator. When the total number of particles equals this number further
  particle splitting is supressed.
\item TYPE(ParticleList),DIMENSION(:,:,:)POINTER :: SecondaryList - When the
  code is compiled with the \inlinecode{-DPARTICLE\_CELL\_DIVISION} the code
  allocates \inlinecode{SecondaryList(0:nx+1,0:ny+1,0:nz+1)} and then loops
  over all particles. It calculates the cell in which each particle is and
  moves the particle from \inlinecode{AttachedList} to the correct element of
  \inlinecode{SecondaryList} for that cell. This means the particles which are
  nearby in space are now linked together in an array of linked lists. This
  allows things such as collision operators which require direct interaction
  between nearby particles.
\item INTEGER(KIND=8) :: npart\_per\_cell - The number of pseudoparticles per
  cell in the initial conditions. This is used with the moving window function
  to ensure that the same number of particles per cell are used for the new
  material introduced at the leading edge of the window.
\item REAL(num),DIMENSION(:,:),POINTER :: Density - The density of the plasma
  at the leading edge of the window at the start of the simulation. This is
  used to structure the density of the new material introduced at the leading
  edge of the plasma.
\item REAL(num),DIMENSION(:,:,:),POINTER :: Density - The temperature in of
  the plasma at the leading edge of a moving window at the start of the
  simulation. The final index of the array is the direction in which the
  temperature is set (1=x,2=y,3=z)
\item LOGICAL :: ionise - If the ionisation model is activated then this
  species should ionise
\item INTEGER :: ionise\_to\_species - The species number for the next ionised
  state of this species
\item INTEGER :: release\_species - When this species ionises what type of
  particle should be release (i.e. which species is the electron)
\item REAL(num) :: ionisation\_energy - The ionisation energy for the next
  ionisation of this species.
\item TYPE(Particle\_Probe),POINTER :: AttachedProbes - A pointer pointing to
  the head of an attached linked list of particle probe diagnostics.
\end{itemize}

\pagebreak

\subsubsection{EM Fields}
There are nine variables which are used in updating the EM field solver. These
are
\begin{itemize}
\item Ex - Electric field in the X direction
\item Ey - Electric field in the Y direction
\item Ez - Electric field in the Z direction
\item Bx - Magnetic field in the X direction
\item By - Magnetic field in the Y direction
\item Bz - Magnetic field in the Z direction
\item Jx - Current in the X direction
\item Jy - Current in the Y direction
\item Jz - Current in the Z direction
\end{itemize}
The EM fields in \EPOCH are simple allocatable arrays, which are of size
(-2:nx+3,-2:ny+3,-2:nz+3) although this includes the ghost cells. The length of
the core domain is different for each variable due to the grid stagger.

The \EPOCH field solver is a Yee staggered 2nd order FDTD scheme, directly
based on the scheme in the PSC by Hartmut Ruhl and is contained in the file
\inlinecode{fields.F90}. To locate a variable on the grid there is a simple
rule.
\begin{itemize}
\item Start at the cell centre
\item For an E field component, move the field half a grid point in the
  direction that the field points if possible.
\item For a B field component, move the field half a grid point in all
  directions {\it except} the one it points.
\end{itemize}

\image{./images/stagger.eps}

The grid stagger means that you have to be careful with boundary conditions
since some variables are defined on the domain boundaries whereas others are
defined on either side of a domain boundary. This is handled automatically by
the built in boundary routines, but must be understood if developing other
boundary conditions. To explain it, consider only the left/right boundary in 1D
and consider Ex and Bx.\\

Ex is defined on the cell boundary, so Ex(0) is the value of Ex on the left
boundary, similarly on the right, Ex(nx) is the value on the right
boundary. Conversely, in the 1D code Bx is cell centred (in reality, Bx is
never used in the field update and is unimportant since any gradients in Bx in
1D automatically break the solenoidal condition, but this is still a useful
example.). This means that Bx(1) is the centre of the first cell in the domain,
and Bx(0) is the value at the centre of the first left hand ghost cell. This
means the you must do different things as boundary conditions for the two
fields for some boundary conditions.\\

For example, if you want to clamp the value of Ex to be zero on the boundary,
then just set Ex(0)=0.0\_num since Ex(0) lies on the boundary. To do the same
for Bx on the boundary you have to set Bx(0)=-Bx(1). This is because if you use
a linear reconstruction of Bx (i.e second order) then the point between Bx(0)
and Bx(1) has the value $Bx\bigl( \frac{1}{2} \bigr) =
\frac{Bx(1)+Bx(0)}{2}$. Similarly, if you want to set zero gradient on the
boundary then for Ex you set Ex(-1)=Ex(1), whereas for Bx you would set
Bx(0)=Bx(1). This is explained in more detail in the section which describes
the existing \EPOCH boundary conditions.

In the particle pusher, time centered field variables are needed for second
order accuracy, so an FDTD scheme is used to advance the fields. This looks
like

\begin{itemize}
\item $\vec{E}^{n+\frac{1}{2}} = \vec{E}^n + \frac{\Delta t}{2} \bigl( c^2
  \nabla \wedge \vec{B}^{n} -\vec{j}^{n} \bigr)$
\item $\vec{B}^{n+\frac{1}{2}} = \vec{B}^n - \frac{\Delta t}{2} \bigl( \nabla
  \wedge \vec{E}^{n+\frac{1}{2}} \bigr)$
\item Call particle pusher which calculates $j^{n+1}$ currents
\item $\vec{B}^{n+1} = \vec{B}^{n+\frac{1}{2}} - \frac{\Delta t}{2} \bigl(
  \nabla \wedge \vec{E}^{n+\frac{1}{2}} \bigr)$
\item $\vec{E}^{n+1} = \vec{E}^{n+\frac{1}{2}} + \frac{\Delta t}{2} \bigl( c^2
  \nabla \wedge \vec{B} ^{n+1} - \vec{j}^{n+1} \bigr)$
\end{itemize}
Note that all spatial derivatives are calculated using the staggered grid, so
the final derivatives in the code appear one sided. However, this is not the
case, and all spatial derivates are second order accurate. Higher order spatial
derivatives schemes for \EPOCH are being developed to improve the dispersion
properties of the code when resolving small timescales.

\pagebreak

\subsection{The particle pusher}
EPOCH's particle pusher is based on the one from the PSC by Hartmut Ruhl, and
is a Birdsall and Landon type PIC scheme using Villasenor and Buneman current
weighting. It is contained in the file \inlinecode{particles.F90}. The
operation of the particle pusher is fairly simple, but there are a few elements
which need some clarification.
\begin{itemize}
\item The update to the particle momenta etc. does not explicitly include the
  particle weight function. This means that the pseudoparticle momenta etc. are
  the momentum for a single real particle of the collection of real particles
  represented by that pseudoparticle, NOT the momentum of the whole collection
  of real particles.
\item \inlinecode{root} - The variable root which appears in various places is
  essentially the multiplicative factor which is needed to convert the particle
  momentum into the particle velocity. If \EPOCH was not relativistic then this
  would simply be $\frac{1}{part\_m}$ where part\_m is the particle mass. Since
  \EPOCH is relativistic, root is defined as $\frac{1}{(part\_m^2 +
    \vec{p}.\vec{p}/c^2)^\frac{1}{2}}$.
\item \inlinecode{cell\_x1=cell\_x1+1} - There are lines like this after all
  the sections of the routine where the cell a particle is in is
  calculated. This is because, for a cell centered variable, the domain runs
  (1:nx,1:ny,1:nz) rather than (0:nx-1,0:ny-1,0:nz-1).
\end{itemize}

\subsubsection{Particle shape functions}
The key feature of a PIC code controlling the smoothness of the solution is the
particle shape function. That is the function that describes the assumed
distribution of the real particles making up a pseudoparticle. The simplest
solution is to assume that the pseudoparticles uniformly fill the cell in which
the pseudoparticle is located. This has the advantages of speed and simplicity
but produces very noisy solutions. The next simplest approach is to assume a
triangular shape function with the peak of the triangle located at the position
of the pseudoparticle and a width of $ 2 \Delta x$. This is the approach used
in \EPOCH and is a good tradeoff between cleanness of solution and
speed. Higher order methods based on spline interpolation can be used and do
produce smoother solutions, but they are significantly slower and the benefits
of the schemes can easily be overstated. \EPOCH does now include an option to
use 4th order spline interpolation in all parts of the code. This option is
enabled with the \inlinecode{-DSPLINE\_FOUR} compile time option in the
makefile.\\
\begin{eqnarray*}
S(w)&=&1-\frac{x_i-w}{\Delta x}, (x_i-w) \le \Delta x\\
&=&0, else\\
\end{eqnarray*}
\\
Functions derived from the particle shape function appears in two places in the
core solver: when the EM fields are interpolated to the position of the
pseudoparticle and when the current is updated and properties of the
pseudoparticle are copied onto the grid. These two uses of the shape function
are conceptually similar, but have different forms.

To derive the equations for how to calculate the field acting on a particle,
you calculate the overlap of the particle shape function with the function
representing the fields on the grid. In EPOCH, the fields are approximated at
first order so that the field is constant over each cell. Consider a particle
with position $X$, where $X$ lies in the cell centered at $x_i$ and grid
spacing $\Delta x$. The integral is split into four parts, that part of the
shape function which overlaps with the cell $x_{i-1}$, the part of the shape
function from the left boundary of $x_i$ to the point of the triangle, the part
of the shape function from the point of the triangle to the right hand edge of
$x_i$ and finally that part of the shape function which overlaps cell
$x_{i+1}$. Assuming that fields are constant inside each cell, this takes the
form
\begin{eqnarray*}
  F_{part} = \frac{1}{\Delta x} \int^{x_{i-1}+\frac{\Delta x}{2}}_{X-\Delta x} F_{i-1} \bigl( 1-\frac{X-x}{\Delta x} \bigr) dx + \\ \int^{X}_{x_i-\frac{\Delta x}{2}} F_i \bigl( 1-\frac{X-x}{\Delta x} \bigr) dx + \\ \int^{x_i+\frac{\Delta x}{2}}_{X} F_i \bigl(  1-\frac{x-X}{\Delta x}\bigr) dx + \\ \int^{X+\Delta x}_{x_{i+1} - \frac{\Delta x}{2}} F_{i+1} \bigl( 1-\frac{x-X}{\Delta x}\bigr) dx
\end{eqnarray*}

Performing these integrals and remembering that $x_{i-1}+\frac{\Delta x}{2}$ is
equal to $x_i-\frac{\Delta x}{2}$ since the grid is uniformly spaced with
spacing $\Delta x$ this gives a final formula for the field at a particle of

\begin{eqnarray*}
  F_{part} = \frac{1}{2} F_{i-1} \bigl( \frac{1}{2} + \frac{x_i-X}{\Delta x} \bigr)^2 \\
  + F_i \bigl( \frac{3}{4} - \frac{(x_i-X)^2}{\Delta x^2} \bigr)\\
  +\frac{1}{2} F_{i+1} \bigl( \frac{1}{2} - \frac{x_i-X}{\Delta x} \bigr)^2
\end{eqnarray*}

If you are running the code with the \inlinecode{-DSPLINE\_FOUR} high order
particle weight function option then the triangular shape function is replaced
by a 4th order spline function which has a basis of 5 cells rather than 3
cells. The form of this function is

In the code calculating the strength of a cell centered field on the particle
is done as follows.
\simpleboxverbatim

	REAL(num) :: cell_x_r, cell_frac_x
	INTEGER :: cell_x
	REAL(num) :: gx(-2:2)
	TYPE(Particle),POINTER :: Current
	
          !Work out number of grid cells in the particle is
          !Not in general an integer
          cell_x_r = (Current%Particle_Pos(1)-x_start_local)/dx
          !Round cell position to nearest cell
          cell_x=NINT(cell_x_r)
          !Calculate fraction of cell between nearest cell boundary and particle
          cell_frac_x = REAL(cell_x,num) - cell_x_r
          cell_x=cell_x+1

    	 CALL GridToParticle(cell_frac_x,gx)
	
	 F_Part=0.0_num
	 DO ix = -sf_order,sf_order
	          F_Part = F_Part + F(cell_x+ix) * gx(ix)
	  ENDDO

\end{Verbatim}

where \inlinecode{F\_Part} is the field at the particle location. The variable
\inlinecode{sf\_order} contains the shape function order parameter which
indicates the number of cells each side of the cell containing the particle
which are overlapped by the particle shape function. It is defined in
\inlinecode{shared\_data.F90} and should only be changed by the developer if a
new particle shape function is being added.  In 2D or 3D, you just calculate gy
in the same manner as gx and calculate the weight over all the cells affected
by the individual 1D shape functions. In 2D this looks like
{\small
\simpleboxverbatim
          CALL GridToParticle(cell_frac_x,gx)
          CALL GridToParticle(cell_frac_y,gy)
          F_Part=0.0_num
	 DO iy = -sf_order, sf_order
		 DO ix = -sf_order, sf_order
		          F_Part = F_Part + F(cell_x+ix,cell_y+iy) * gx(ix) *gy(iy)
		  ENDDO
 	 ENDDO
\end{Verbatim}
}
Inside the particle pusher the E and B fields are not cell centered fields, but
Yee staggered. This means that there is a small change to the above mentioned
example. In 1D this change looks like
\simpleboxverbatim

	REAL(num) :: cell_x_r, cell_frac_x
	INTEGER :: cell_x1, cell_x2
	REAL(num) :: gx(-2:2),hx(-2:2)
	TYPE(Particle),POINTER :: Current
	
          !Work out number of grid cells in the particle is
          !Not in general an integer
          cell_x_r = (Current%Particle_Pos(1)-x_start_local)/dx
          !Round cell position to nearest cell
          cell_x=NINT(cell_x_r)
          !Calculate fraction of cell between nearest cell boundary and particle
          cell_frac_x = REAL(cell_x,num) - cell_x_r
          cell_x=cell_x+1

          CALL GridToParticle(cell_frac_x,gx)

          cell_x_r = (Current%Particle_Pos(1)-x_start_local)/dx - 0.5_num
          cell_x2  = NINT(cell_x_r)
          cell_frac_x = REAL(cell_x2,num) - cell_x_r
          cell_x2=cell_x2+1

          CALL GridToParticle(cell_frac_x,hx)

          !Bx is cell centred
          Bx_Part=0.0_num
	 DO ix = -sf_order,sf_order
	          Bx_Part = Bx_Part + Bx(cell_x1+ix) * gx(ix)
	  ENDDO

          !Ex is staggered 1/2 a cell to the right
          Ex_Part=0.0_num
	 DO ix = -sf_order,sf_order
	          Ex_Part = Ex_Part + Ex(cell_x2+ix) * hx(ix)
	  ENDDO

\end{Verbatim}

In 2D and 3D, you just combine the shifted and unshifted shape functions and associated cell positions depending on the position of the variable in the cell. Therefore, in 3D  and using the loop notation for clarity you would get

\simpleboxverbatim
    DO iz=-sf_order,sf_order
        DO iy=-sf_order,sf_order
            DO ix=-sf_order,sf_order
                 Ex_Part = Ex_Part + hx(ix)*gy(iy)*gz(iz) * &
                     Ex(cell_x2+ix,cell_y1+iy,cell_z1+iz)
            ENDDO
        ENDDO
    ENDDO

    DO iz=-sf_order,sf_order
        DO iy=-sf_order,sf_order
            DO ix=-sf_order,sf_order
                 Bx_Part = Bx_Part + gx(ix)*hy(iy)*hz(iz) * &
                     Bx(cell_x2+ix,cell_y1+iy,cell_z1+iz)
            ENDDO
        ENDDO
    ENDDO

\end{Verbatim}

Since Ex is staggered half a grid cell in the x direction, whereas Bx is
staggered by half a grid cell in the y and z directions.

The next stage is to consider how to calculate how to copy pseudoparticle
properties on the grid. This is very similar to the function for calculating
grid variables at the particle location and for each grid point $x_i$ to
consist of integrating the part of the particle shape function which overlaps
the $i^{th}$ cell. That is

\[
F(i) = Data  \int^{x_i+\frac{\Delta x}{2}}_{x_i-\frac{\Delta x}{2}} S(X-x) dx
\]

Where $Data$ is the particle property to be copied onto the grid. In EPOCH,
since the particle shape function is known to go to zero outsize a distance of
$2 \Delta x$ from the maximum, the maximum number of cells that can possibly be
overlapped by a given particle shape function is 3 : the cell containing the
particle maximum and the two cells to either side. Performing the integration
using the triangular shape function given above gives the result

\begin{eqnarray*}
  F(i) &=& \frac{1}{2} \bigl(\frac{3}{2} - \frac{|X - x_i|}{\Delta x} \bigr)^2, \frac{\Delta x}{2} < |X-x_i| \le \frac{3 \Delta x}{2}\\
  &=& \frac{3}{4} - \frac{|X-x_i|^2}{\Delta x^2}, |X-x_i| \le \frac{\Delta x}{2}\\
  &=& 0, |X-x_i| > \frac{3 \Delta x}{2}\\
\end{eqnarray*}

Again, when using high order particle shape functions using the
\inlinecode{-DSPLINE\_FOUR} option this is replaced with an equivalent form for
a 4th order spline.

When this is translated into the code, it looks very similar to that presented
for the case where grid properties are interpolated to the particle
position. This form is used in the particle pusher to perform the current
update and in the routines in \inlinecode{src/io/calc\_df.F90} to copy particle
properties onto the grid for output. The form from calc\_df is rather clearer
and easier to see in operation. In 1D it looks like

\simpleboxverbatim
          cell_x_r = part_x / dx
          cell_x  = NINT(cell_x_r)
          cell_frac_x = REAL(cell_x,num) - cell_x_r
          cell_x=cell_x+1

	CALL ParticleToGrid(cell_frac_x,gx)

          DO ix=-sf_order,sf_order
              DataArray(cell_x+ix) = DataArray(cell_x+ix) + &
                 gx(ix)  * Data
          ENDDO
\end{Verbatim}

Once again multi-dimensional codes just have the weighting functions multiplied
together
\simpleboxverbatim
	DO iy=-sf_order,sf_order
	          DO ix=-sf_order,sf_order
         		     DataArray(cell_x+ix,cell_y+iy) = DataArray(cell_x+ix,cell_y+iy) + &
	                 gx(ix) *gy(iy) * Data
         		 ENDDO
	ENDDO
\end{Verbatim}

\subsubsection{Current calculation}
\EPOCH uses the Villasenor and Buneman(Villasenor and Buneman, Computer Physics
Communications 69(1992) 306-316) current calculating scheme which solves the
additional equation $\frac{\partial \rho}{\partial t} = \nabla . \vec{J}$ to
calculate the current at each timestep. The main advantage of this scheme is
that it conserves charge {\it on the grid} rather than just globally conserving
charge on the particles. This means that the error in the solution of Poisson's
equation is conserved, so if Poisson's equation is satisfied for $t=0$ it
remains satisfied for all time.\\

The Villasenor and Buneman scheme works because exactly the same charge added
to one cell is subtracted from another cell, which in turn means that exactly
the same current added to one cell is subtracted from another cell. This is
intuitively correct since a point particle crossing a cell boundary would
represent the loss of that particle's contribution to the current from the
source cell, and the gain of that particle's contribution to the current by the
destination cell, and in fact this simple type of cell boundary crossing
current calculation was used in classical Buneman type PIC codes.\\

The scheme is in practice messy, but simple. After the main particle push, the
particle is advanced a further half timestep into the future to first order
using the velocities calculated at the end of the particle push. The particle
position at $t +dt/2$ were stored earlier, and combined with the newly
calculated particle position at $t+\frac{3dt}{2}$ this allows a time centered
evaluation of $\frac{\partial \rho}{\partial t}$ meaning that the current
update is second order accurate in time. The spatial order of the scheme
matches the spatial order of the particle weight function.\\

The weight functions for transfering particle properties onto the grid at the
two timesteps are calculated including a shift when necessary to allow for the
particle having crossed a cell boundary. Since the charge associated with the
particle is spatially distributed using the weight function, all that is
necessary to calculate $\frac{\partial \rho}{\partial t}$ is to subtract the
two functions, multiply by the charge on the pseudoparticle and the
pseudoparticle weight and finally divide by $dt$. The spatial derivative of
$\vec{J}$ is then converted to a one sided finite difference form and solved
directly. In multiple dimensions this is slightly complicated by the effects of
offsets in directions other than the direction that a given current component
is pointing in, with this adding additional weight factors based on the overlap
of the shape functions in other directions. This is explained in full in the
Villasenor and Buneman paper already quoted.\\

Currents in ignorable directions are simply calculated using $J=n\rho\vec{v}$
with the correct shape functions to ensure that the current is placed in the
correct places.
\pagebreak

\subsection{The timestep}

The timestep is calculated in the subroutine \inlinecode{set\_dt} in the file
\inlinecode{src/io/diagnostics.F90}. All that the subroutine has to do is set
the variable \inlinecode{dt} to set the timestep for the whole code. Any
additional timestep constraints should be coded into this subroutine. This
should be implemented after the existing \inlinecode{dt=} lines but before the
line \inlinecode{dt=dt\_multiplier * dt}. Such a modification should be set so
that it only changes the timestep if the timestep is MORE restrictive than that
calculated from the core code. An example would be

\simpleboxverbatim
   dt=dtx*dty/SQRT(dtx**2+dty**2)
   dt=MIN(dt,my_new_dt)
\end{Verbatim}

In the core \EPOCH code the timestep can be calculated identically on each
processor, so there is no requirement to synchronize the timestep across
multiple processors. If your new timestep restriction use information local to
each processor then some additional lines must be added to the
\inlinecode{set\_dt} after the timestep has been calculated routine which
should read

\simpleboxverbatim
	REAL(num) :: dt_global
		.
		.
		.
	CALL MPI_ALLREDUCE(dt_global,dt,1,mpireal,MPI_MIN,comm,errcode)
	dt=dt_global
\end{Verbatim}

This uses another MPI command to determine the most restrictive timestep across
all processors. \EPOCH is not written in a way that permits operation with
different timesteps on different processors, and the behaviour of the code is
undefined (and likely wrong) if the code runs with different timesteps on
different processors.

\pagebreak

\subsection{Boundary conditions}
Boundary conditions in \EPOCH are split into three types
\begin{itemize}
\item Simple field boundaries
\item Laser and outflow boundaries
\item Particle boundaries
\end{itemize}

These boundaries can be combined in different ways to give different
effects. From the end user perspective there are 4 boundaries which can be
applied to each edge of the simulation domain. These are
\begin{itemize}
\item Periodic
  \subitem Particles periodic
  \subitem Fields periodic
  \subitem Lasers off
\item Other
  \subitem Particles reflect
  \subitem Fields clamped zero
  \subitem Lasers off
\item Simple Laser
  \subitem Particles transmissive
  \subitem Fields clamped zero
  \subitem Lasers applied at half timestep for B field
\item Simple outflow
  \subitem Particles transmissive
  \subitem Fields clamped zero
  \subitem No lasers applied at half timestep, but outflow conditions applied
  to B field at half timestep
\end{itemize}
The boundary conditions are applied in too many places in the code to give a
full description of them, but the laser boundaries are only applied in
\inlinecode{src/fields.f90}. The boundaries requested by the user are converted
into the conditions on the fields and particles in the routine
\inlinecode{Setup\_Particle\_Boundaries} in
\inlinecode{src/boundaries.F90}. For each of the six possible boundaries
(right, left, up, down, front, back) there is a variable which will be named
something like \inlinecode{xbc\_right\_particle} or
\inlinecode{ybc\_down\_field} which controls the boundary condition which will
be applied to either the field or the particles.

\subsubsection{Simple field boundaries}
There are two subroutines which apply the standard boundary conditions :
\inlinecode{Field\_Zero\_Gradient} and \inlinecode{Field\_Clamp\_Zero}. The
type of boundary condition that the two apply is obvious from the name, but
unfortunately the two functions have different calling conventions.

\pagebreak
{\Large \inlinecode{SUBROUTINE Field\_Zero\_Gradient\\
\HRule \\[0.5cm]
    REAL(num),DIMENSION(-2:,-2:,-2:),INTENT(INOUT) :: Field\\
    LOGICAL,INTENT(IN) :: Force}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/boundary.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Field\_Zero\_Gradient} is the routine which applies zero gradient
boundary conditions to a field variable passed in the parameter
\inlinecode{Field}. It can be used as a global field boundary condition by
setting one of the field boundary conditions to BC\_ZERO\_GRADIENT in
\inlinecode{Setup\_Particle\_Boundaries}, but it is mostly used to give
boundary conditions for the autoloader, where the \inlinecode{Force} parameter
is set to \inlinecode{.TRUE.} to override the boundary condition values.
\\[0.5cm]
{\Large Notes\\ \\}

\pagebreak
{\Large \inlinecode{SUBROUTINE Field\_Clamp\_Zero\\
\HRule \\[0.5cm]
    REAL(num),DIMENSION(-2:,-2:,-2:),INTENT(INOUT) :: Field\\
    INTEGER,DIMENSION(nDims),INTENT(IN) :: Stagger}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/boundary.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Field\_Clamp\_Zero} is the routine which clamps the field given by
the \inlinecode{Field} variable to zero on the boundary. Since this routine
explicitly sets the field to zero {\it on} the boundary it needs to know about
the grid stagger which is provided in the parameter \inlinecode{Stagger}. At
present stagger is simply an array of 1/0 values which indicates whether a
given field is staggered in that direction, so a cell centered field has
stagger \inlinecode{(/0,0,0/)} while Ex has stagger \inlinecode{(/1,0,0/)} and
Bx has stagger \inlinecode{(/0,1,1/)}.
\\[0.5cm]
{\Large Notes\\}
\pagebreak

Additional boundary conditions should follow the same basic principle as these
routines. Note that all of the routines test for things like \inlinecode{left
== MPI\_PROC\_NULL} etc. these tests confirm that a given processor is at the
edge of the real domain, and so should have a real boundary condition applied
to it. This also explains why there are no explicit periodic boundary condition
routines, since by connecting the processors cyclically in a periodic direction
the domain boundary effectively becomes another internal processor boundary.

\subsubsection{Laser and outflow boundaries}
Setting up lasers is explained in the relevant section in the first part of the
manual and the way in which the laser specification in the input deck works is
described later, so this section just describes how the actual laser and
outflow routines in \inlinecode{laser.F90} work. \\

The laser boundaries in \EPOCH are based on a rewriting of Maxwell's equations
in a new form which expresses the fields explicitly in terms of wave
propagating in both directions along each co-ordinate axis with both S and P
polarization states. In the X direction, these
\[
\partial_t(E_y \pm B_z) \pm \partial_x(E_y \pm B_z) = \pm \partial_yE_x
+ \partial_zB_x -\frac{j_y}{\epsilon_0}
\]
\[
\partial_t(E_z \mp B_y) \pm \partial_x(E_z \mp B_y) = \pm \partial_yE_x
- \partial_zB_x -\frac{j_y}{\epsilon_0}
\]
It is then possible to rewrite these equations to provide a boundary condition
on $B_z$ and $B_y$ to give propagating EM waves at the boundary. For waves
traveling into the boundary, this gives a transmissive boundary, and if the
components for waves propagating out from the boundary are set to be non-zero
then it also introduces an EM wave propagating from the left boundary.\\

This boundary condition is found in the file \inlinecode{laser.F90} which also
includes the routines for handling the \inlinecode{Laser\_Block} objects which
represent how lasers are represented in \EPOCH.

\subsubsection{Particle boundaries}
Due to the time that is required to loop over all the particles the particle
boundary conditions \EPOCH combines the interprocessor boundary conditions with
the real boundary conditions. The boundary conditions for particles are in the
routine \inlinecode{Particle\_bcs} in the file \inlinecode{boundary.f90} \\
Currently \EPOCH includes only three particle boundary conditions
\begin{itemize}
\item BC\_PERIODIC - Particles which leave one side of the box reappear on the
  other side.
\item BC\_REFLECT - Particles reflect off the boundary as if it was a hard
  boundary
\item BC\_OPEN - Particles pass through the boundary and are destroyed. Total
  pseudoparticle number is not conserved in this mode.
\end{itemize}

Although the routine looks rather messy, it is fairly easy to understand. The
sequence goes
\begin{itemize}
\item Loop over all species
\item Createparticle list objects for particles to be sent to and received from
  other processors.
\item Loop over all particles
\item If particle has crossed the domain boundary and that boundary has
  reflecting boundary conditions then reflect the particle.
\item If particle has crossed the processor boundary then set the variables
  \inlinecode{xbd} and \inlinecode{ybd} which are used to identify which
  processor relative to the current processor the particle should be moved to.
\item Check whether a particle has crossed an open domain boundary.
\item If a particle has crossed a processor boundary or an open domain boundary
  then remove the particle from the particle list for it's species.
\item If the particle has crossed a processor boundary but not an open domain
  boundary then add it to the list to be sent to it's new processor using
  \inlinecode{xbd} and \inlinecode{ydb} to identify which processor it should
  be on.
\item If the particle has crossed an open domain boundary then either add it to
  another list to be dumped to disk if the user has requested this, or
  otherwise just deallocate the particle to reclaim memory.
\item End particle loop
\item Loop over all possible neighboring processors for the current processor
  and exchange particle lists with that processor
\item Add any received particles onto the particle list for the current
  species.
\item Although particles which have crossed a periodic boundary are now on the
  correct processor, they have the wrong position in space, so subtract the
  length of the domain from the particles position.
\item End Species Loop
\end{itemize}

Note that unlike for fields there is explicit periodic boundary code. This is
because although the MPI routines place the particle on the correct processor
after the MPI routines, the particle's position variable still places it beyond
the other end of the domain. The MPI parallelism for exchanging particles is
hidden in the routines which deal with the particle list objects and are
described in the next section.
\pagebreak

\subsubsection{MPI Boundaries}
There are three routines which deal with MPI exchange for field variables in
\EPOCH. Two are closely related and will be considered together. The third
deals with using MPI to sum variables at processor boundaries rather than
synchronize ghost cells.\\\\

{\Large \inlinecode{SUBROUTINE Field\_BC\\
\HRule \\[0.5cm]
    REAL(num),DIMENSION(-2:,-2:,-2:),INTENT(INOUT) :: Field\\}}
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/boundary.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Field\_BC} exchanges the information in the ghost cells between
adjacent processors. Any field variable which is used in a calculation which
requires operations which involve information from points other than the
current point should call this routine each time the variable is updated to
ensure that the ghost cells are populated from adjacent processors. (i.e. if
you only need to access field(ix,iy,iz) there is no need to update ghost cells,
if you use field(ix-1,iy,iz) you do)
\\[0.5cm]
{\Large Notes\\}
The \inlinecode{Field\_BC} routine just calls the
\inlinecode{Do\_Field\_MPI\_With\_Lengths} routine which is a more general
routine which allows ghost cell information to be exchanged for fields with
arbitrary number of cells, rather than fields which are
(-2:nx+3,-2:ny+2,-2:nz+3). This routine is used internally in the load
balancing routine when fields with both the old and new sizes must be handled
at the same time.
\pagebreak

{\Large \inlinecode{SUBROUTINE Processor\_Summation\_BCS\\
\HRule \\[0.5cm]
    REAL(num),DIMENSION(-2:,-2:,-2:),INTENT(INOUT) :: Field\\}}
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/boundary.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Processor\_Summation\_BCS} is a routine which is used to deal with
variables, like $\vec{j}$ or number density which should be added at boundaries
to include contributions from particles on both sides of a processor
boundary. The routine is used for current inside the particle pusher and inside
most of the routines for calculating derived variables. If you have a variable
which needs to add contributions from adjacent processors then you should
calculate the quantity on each processor, including contributions from the
particles to the ghost cells and then call this routine.
\\[0.5cm]
{\Large Notes\\}
\pagebreak

These routines can be used for most MPI which is needed for all but the most
extreme modifications to \EPOCH. More details on the internals of the parallel
implementation of \EPOCH is given in the section {\it MPI in \EPOCH}, which
includes information on more extreme changes to EPOCH, but realistically one
should already be a proficient MPI programmer before attempting to perform
extensive modification to \EPOCH.

\subsection{Particle List control functions}
Collections of particles in \EPOCH are represented by Particle List
object. These objects abstract much of the operation of the linked lists,
including adding and removing particles and sending particles to other
processors. The functions are as follows:
\pagebreak

{\Large \inlinecode{FUNCTION Create\_Empty\_PartList(PartList)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Empty\_PartList} is a function which takes a ParticleList
object and sets it up so that it points to no particles at all. It should be
used on newly allocated ParticleList objects and when a ParticleList has served
it's purpose. It DOES NOT destroy the particles linked in the list at the point
that it is called. If the user wishes to delete all the particles in a
ParticleList then the routine \inlinecode{Destroy\_PartList} should be used
instead.
\\[0.5cm]
{\Large Notes\\}

\pagebreak

{\Large
\inlinecode{FUNCTION Create\_Unsafe\_PartList(PartList,aParticle,n\_elements)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
TYPE(Particle), POINTER :: aParticle\\
INTEGER(KIND=8),INTENT(IN) :: n\_elements}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Unsafe\_PartList} is a routine which allows the creation of
a ParticleList which represents a subset of another particle list. This subset
is defined as starting at the particle pointed to by \inlinecode{aParticle} and
extending for \inlinecode{n\_elements} elements. The new ParticleList is then
flagged as "unsafe" because if it is destroyed for any reason then it will
affect other particle lists. Many ParticleList functions can only work on safe
particle lists.
\\[0.5cm]
{\Large Notes\\}

\pagebreak

{\Large
\inlinecode{FUNCTION Create\_Unsafe\_PartList\_By\_Tail(PartList,Head,Tail)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
TYPE(Particle), POINTER :: Head, Tail}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Unsafe\_PartList\_By\_Tail} is almost identical to
\inlinecode{Create\_Unsafe\_PartList}, but instead of specifying a the first
particle and a number of elements, the user specifies the first and last
elements of the subset of the particle list. If the particle objects specified
for head and tail are not in the same partlist or tail actually comes before
head then the routine will fail in an undefined manner.
\\[0.5cm]
{\Large Notes\\}

\pagebreak

{\Large
\inlinecode{FUNCTION Create\_Allocated\_PartList(PartList, n\_elements)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
INTEGER(KIND=8), INTENT(IN) :: n\_elements}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Allocated\_PartList} is a helper routine to setup a new
ParticleList and create \inlinecode{n\_elements} new Particle objects already
in place in the list.
\\[0.5cm]
{\Large Notes\\}
You should always use this routine when creating large numbers of new particle
objects since there is no guarantee that the internal structure of the
ParticleList objects will not change in the future. This routine will however
be modified to reflect any changes in the underlying code.
\pagebreak

{\Large
\inlinecode{FUNCTION Create\_Filled\_PartList(PartList, DataIn, n\_elements)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
REAL(num),DIMENSION(:),INTENT(IN) :: DataIn\\
INTEGER(KIND=8), INTENT(IN) :: n\_elements}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Filled\_PartList} is a helper routine to setup a new
ParticleList and create \inlinecode{n\_elements} new Particle objects already
in place in the list. These new particle objects are then assigned properties
from the array \inlinecode{DataIn} where the particle properties are contained
in packed form. The particle data is unpacked from the array using the
\inlinecode{UnPack\_Particle} routine.
\\[0.5cm]
{\Large Notes\\}
You should always use this routine if possible when copying particles out of
packed format since there is no guarantee that the internal structure of the
ParticleList objects will not change in the future. This routine will however
be modified to reflect any changes in the underlying code.
\pagebreak

{\Large \inlinecode{FUNCTION Test\_PartList(PartList)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Test\_PartList} is a routine which tests for various possible types
of error within a ParticleList object. It has various possible return codes for
different errors, with the different possible error codes either signified by a
specific negative value for errors so severe that the main tests cannot be run,
or with a bitmask for errors in the main tests. The possible specific value
return codes are
\begin{itemize}
\item 0 - No error, ParticleList has passed all tests
\item -1 - Either the head or tail of the ParticleList object is NULL. This is
  a serious error and usually means that there is a serious error inside the
  ParticleList routines.
\end{itemize}
The other error codes are returned as a bitmask and means the following
\begin{itemize}
\item 1 - A ParticleList marked as safe has a head element which is linked to a
  preceding particle object.
\item 2 - A ParticleList marked as safe has a tail element which is linked to a
  succeeding particle object.
\item 4 - The count property of a ParticleList does not correspond to the
  actual number of objects linked between the head and tail objects. This error
  code on it's own usually means that the Count property has been modified
  improperly.
\end{itemize}
A
\\[0.5cm]
{\Large Notes\\}
Note that this routine is only intended for debugging and is very slow. It
should never be used by the code in normal operation and all routines should be
written in such a way that it is impossible for a ParticleList object to become
corrupted.
\pagebreak

{\Large \inlinecode{FUNCTION Destroy\_PartList(PartList)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Destroy\_PartList} is a helper routine to delete all the particles
attached to a ParticleList and free up the memory that they use. It also
guarantees to leave the ParticleList object itself in a blank state where new
particles can be added to it. It DOES NOT delete the ParticleList object
itself, since it does not know whether or not the ParticleList is dynamically
allocated. If using dynamically allocated ParticleList objects then it is up to
the user to deallocate them AFTER the attached particles are destroyed using
\inlinecode{Destroy\_PartList}
\\[0.5cm]
{\Large Notes\\}
If a ParticleList is deleted without deleting the attached Particle objects
either using this routine or explicitly by the user then the particles will
become orphaned and sit around using memory until the code ends. If this
happens regularly then the code will quickly crash, usually with a SIG\_SEGV
error.
\pagebreak

{\Large \inlinecode{FUNCTION Copy\_PartList(PartList1, PartList2)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList1, PartList2}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Copy\_PartList} is a routine which sets \inlinecode{PartList2} to
point to the same linked list of particles as \inlinecode{PartList1}. It does
not copy the particles, just sets the head and tail pointers of
\inlinecode{PartList1} to point to the same Particle objects as
\inlinecode{PartList1}
\\[0.5cm]
{\Large Notes\\}
\pagebreak

{\Large \inlinecode{FUNCTION Append\_PartList(Head, Tail)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: Head, Tail}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Append\_PartList} is a routine which attaches the particles
attached to the ParticleList object \inlinecode{Tail} and adds them to the end
of the linked list for ParticleList \inlinecode{Head}. The ParticleList
\inlinecode{Tail} is then set to be an empty ParticleList.
\\[0.5cm]
{\Large Notes\\}
This routine can only append one safe ParticleList to another safe ParticleList.
\pagebreak

{\Large
\inlinecode{FUNCTION Add\_Particle\_To\_PartList(PartList, NewParticle)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
TYPE(Particle),POINTER :: NewParticle}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Add\_Particle\_To\_PartList} is the routine which adds a new particle(\inlinecode{NewParticle})
to the end of the linked list of particles in the ParticleList object
\inlinecode{PartList}. It deals with cases of empty ParticleList objects
automatically.
\\[0.5cm]
{\Large Notes\\}
If you want to add a new particle to the end of a particle list you should
always use this routine.
\pagebreak

{\Large
\inlinecode{FUNCTION Remove\_Particle\_From\_PartList(PartList, aParticle)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
TYPE(Particle),POINTER :: aParticle}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Remove\_Particle\_From\_PartList} removes the Particle object
specified by \inlinecode{aParticle} from the ParticleList object given by
\inlinecode{PartList}. Be very careful that \inlinecode{aParticle} is indeed in
the linked list pointed to by \inlinecode{PartList}, otherwise it is possible
for the ParticleList object which really does contain \inlinecode{aParticle} to
be left with an invalid pointer as it's head or tail element if
\inlinecode{aParticle} is either the head or tail element.
\\[0.5cm]
{\Large Notes\\}
Although this routine does work with unsafe ParticleList objects, you should be
very careful using it in this case as it can break the head or tail element of
the primary ParticleList which the unsafe ParticleList is a subset of. As a
general rule, you should only use this routine to remove particles from a
simple ParticleList which is a singly referenced primary, safe ParticleList.
\pagebreak


{\Large \inlinecode{SUBROUTINE Setup\_PartLists()\\
\HRule \\[0.5cm]}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Setup\_PartLists} is a routine which is called once when \EPOCH
first starts. It sets the variable \inlinecode{nvars} which is the number of
REAL(num) values which are required to contain all the information about a
single Particle object which is needed when a particle is transfered to another
processor. How the information is packed and unpacked from the Particle object
into an array of REAL(num) values is controlled in the functions
\inlinecode{Pack\_Particle} and \inlinecode{UnPack\_Particle}.
\\[0.5cm]
{\Large Notes\\}
If the Particle type gains additional properties as the result of preprocessor
directives then there should be a line which increments \inlinecode{nvars} by
the correct number when that preprocessor directive is active. For example
\simpleboxverbatim
#ifdef PER_PARTICLE_CHARGEMASS
    nvar=nvar+2
#endif
\end{Verbatim}
\pagebreak

{\Large \inlinecode{SUBROUTINE Pack\_Particle(Data, aParticle)\\
\inlinecode{SUBROUTINE UnPack\_Particle(Data, aParticle)}\\
\HRule \\[0.5cm]
REAL(num),DIMENSION(:),INTENT(INOUT) :: Data\\
TYPE(Particle),POINTER :: aParticle\\
}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Pack\_Particle} and \inlinecode{UnPack\_Particle} are subroutines
which are used to transfer all the information about a particle which is
necessary for the particle to be transfered to another processor into a
temporary array before sending to another processor. If a new particle property
has been added to the particle then these routines must be modified to allow
the copying of the new data into the array. The parameter \inlinecode{Data} is
a REAL(num) array of length \inlinecode{nvars} and is the array into which the
data either must be packed or from which it must be
unpacked. \inlinecode{aParticle} is the Particle object which must either have
it's data copied into the array or the blank particle object which must be
populated with the data from the array. No restriction is placed on how the
data should be packed into the Data array, but obviously
\inlinecode{Pack\_Particle} and \inlinecode{UnPack\_Particle} must be inverse
operations so that particles packed by one processor can be unpacked correctly
by another processor.
\\[0.5cm]
{\Large Notes\\}
Since it is very unlikely that \EPOCH will be run on anything other than a
homogenous cluster, it is acceptable to use the Fortran \inlinecode{TRANSFER}
function to pack incompatible data types into the \inlinecode{Data} array. Just
make sure that \inlinecode{nvars} is defined in \inlinecode{Setup\_PartLists}
to be long enough to contain all the information. More documentation on the
\inlinecode{TRANSFER} function (which is rarely used and dangerous!) can be
found at
http://www.macresearch.org/advanced\_fortran\_90\_callbacks\_with\_the\_transfer\_function.
\pagebreak

{\Large \inlinecode{SUBROUTINE Display\_Particle(aParticle)\\
\HRule \\[0.5cm]
TYPE(Particle),POINTER :: aParticle}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
Displays the key information about a particle given by the parameter
\inlinecode{aParticle}. Used by \inlinecode{Compare\_Particles}.
\\[0.5cm]

{\Large \inlinecode{FUNCTION Compare\_Particles(Particle1, Particle2)\\
\HRule \\[0.5cm]
TYPE(Particle),POINTER :: Particle1, Particle2\\
LOGICAL :: Compare\_Particles
}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
Compares all the properties of two Particle objects and displays the
information if they don't match. Used internally by
\inlinecode{Test\_Packed\_Particles}. If the Particle object is extended then
this routine should also be modified to test for equivalence of the new
properties.
\\[0.5cm]

{\Large
\inlinecode{SUBROUTINE Test\_Packed\_Particles(Partlist, Data, npart\_in\_data)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(IN) :: PartList\\
REAL(num),DIMENSION(:),INTENT(IN) :: Data\\
INTEGER(KIND=8), INTENT(IN) :: npart\_in\_data
}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Test\_Packed\_Particles} is a routine which checks that a packed
array of particles can be successfully unpacked back into Particle Objects. The
parameters are
\begin{itemize}
\item \inlinecode{PartList} - The ParticleList corresponding to the original
  unpacked particles.
\item \inlinecode{Data} - The REAL(num) array containing the packed data.
\item \inlinecode{npart\_in\_data} - The number of particles which were packed
  into the \inlinecode{Data} array.
\end{itemize}
The routine tests that the number of particles in the ParticleList match the
number believed to be in the Data array, that the length of the Data array is
correct and the unpacks each particle in turn from the Data array and uses the
\inlinecode{Compare\_Particles} function to compare the particles with the
original versions in the ParticleList. If any particles fail the comparison
then the error is output to stdout. The error message includes the processor
rank on which the problem occurs but the routine does not specifically include
any MPI commands, so it is possible to call the routine on a subset of
processors.
\\[0.5cm]
\pagebreak

{\Large \inlinecode{FUNCTION PartList\_Send(PartList, Dest)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
INTEGER ,INTENT(IN) :: Dest}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{PartList\_Send} is a routine for sending all the particles in the
ParticleList object \inlinecode{PartList} to another processor. The destination
processor is identified by it's rank which is given by the \inlinecode{Dest}
parameter. The routine does not destroy the ParticleList object which is given
to it.
\\[0.5cm]
{\Large Notes\\}
\inlinecode{PartList\_Send} uses MPI blocking sends, so unless a matching
\inlinecode{PartList\_Recv} has been posted on \inlinecode{Dest} then the
routine will deadlock. It would be fairly simple to write a non-blocking
version of \inlinecode{PartList\_Send}, but at present no need for such a
routine has been found.
\pagebreak

{\Large \inlinecode{FUNCTION PartList\_Recv(PartList, Src)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\\
INTEGER ,INTENT(IN) :: Src}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{PartList\_Recv} is a routine for receiving Particles sent by a call
to \inlinecode{PartList\_Send} and loading them into the ParticleList object
\inlinecode{PartList}. The source processor is identified by it's rank which is
given by the \inlinecode{Src} parameter. The routine destroys the ParticleList
which it is given and indeed will leave orphaned particles if it is not given
an empty ParticleList to receive the data.
\\[0.5cm]
{\Large Notes\\}
\begin{itemize}
\item \inlinecode{PartList\_Recv} uses MPI blocking receives, so unless a
  matching \inlinecode{PartList\_Send} has been posted on \inlinecode{Src} then
  the routine will deadlock. It would be fairly simple to write a non-blocking
  version of \inlinecode{PartList\_Recv}, but at present no need for such a
  routine has been found.

\item Although it is not possible to directly use \inlinecode{PartList\_Recv}
  to add new particles onto an existing ParticleList, it is only two lines to
  do this. First call \inlinecode{PartList\_Recv} with a temporary ParticleList
  to receive the data and then use \inlinecode{Append\_PartList} to attach the
  particles to the end of the already populated list.
\end{itemize}
\pagebreak

{\Large
\inlinecode{FUNCTION PartList\_Send\_Recv(PartList\_Send,PartList\_Recv, Dest, Src)\\
\HRule \\[0.5cm]
TYPE(ParticleList),INTENT(INOUT) :: PartList\_Send, PartList\_Recv\\
INTEGER ,INTENT(IN) :: Dest, Src}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{PartList\_SendRecv} is a routine equivalent to
\inlinecode{MPI\_SENDRECV} in that it allows overlapping sends and receives to
be written in a single line rather than the end user having to split processors
into red/black ordered pairs for communication. It sends the particle data in
\inlinecode{PartList\_Send} to the processor with rank \inlinecode{Dest} and
receives particle data sent by processor \inlinecode{Src} and stores it in the
ParticleList \inlinecode{PartList\_Recv}. The routine is destructive to both
sending and receiving ParticleLists, and can lead to orphaned particles if a
filled ParticleList is passed as \inlinecode{PartList\_Recv}. This is the
routine which is used in the particle boundary conditions.
\\[0.5cm]
{\Large Notes\\}
\begin{itemize}
\item \inlinecode{PartList\_SendRecv} uses MPI blocking sendrecv commands, so
  should be used in matching pairs the routine will deadlock.

\item Although it is not possible to directly use
  \inlinecode{PartList\_SendRecv} to add new particles onto an existing
  ParticleList, it is only two lines to do this. First call
  \inlinecode{PartList\_SendRecv} with a temporary ParticleList to receive the
  data and then use \inlinecode{Append\_PartList} to attach the particles to
  the end of the already populated list.
\end{itemize}
\pagebreak


\subsection{MPI in \EPOCH}
\EPOCH is a massively parallel code written using standard MPI1.2, and likely
to be upgraded to MPI2 in the near future. Due to the massively parallel nature
of EPOCH, there are MPI commands scattered throughout many parts of the code,
although the MPI has been hidden as far as possible from the end user. The main
use of MPI occurs during IO, in the boundary conditions and during load
balancing. The MPI setup routines are all in
\inlinecode{src/housekeeping/mpi\_routines.f90}, and the routines which are
used to create the MPI types used by MPIIO are in
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}.

\subsubsection{General MPI in \EPOCH}
\EPOCH uses Cartesian domain decomposition for parallelism and creates an MPI
Cartesian topology using \inlinecode{MPI\_CART\_CREATE}.  The use of MPI in
\EPOCH is deliberately kept as simple as possible, but there are some points
which must be made and some variables which must be explained.
\begin{itemize}
\item MPI decomposition is reversed compared to array ordering. Due to the
  layout of arrays in Fortran, you get slightly faster performance if you split
  arrays so that the first index remains as long as possible. Since \EPOCH uses
  \inlinecode{MPI\_DIMS\_CREATE} to do array subdivision, this means that the
  MPI coordinate system ordered backwards compared to the main arrays. This
  means that the \inlinecode{coordinates} array which holds the coordinates of
  the current processor in the Cartesian topology is ordered as \{coord\_z,
  coord\_y, coord\_x\}.
\item To make this easier, there are some helper variables. The simplest of
  these just give the processors attached to each face of the domain on the
  current processor. These variables are named \inlinecode{right, left, up,
    down, front} and \inlinecode{back} and are in the x, y and z directions
  respectively.
\item Since it is possible for particles to cross boundaries diagonally there
  is another variable \inlinecode{neighbour} which identifies every possible
  neighbouring processor including those meeting at single edges and at
  corners. \inlinecode{neighbour} is an array which runs (-1:1,-1:1,-1:1) and,
  perhaps inconsistently, is ordered in normal order rather than reversed
  order. This means that \inlinecode{left==neighbour(-1,0,0)} and
  \inlinecode{front==neighbour(0,0,1)}.
\item The variable \inlinecode{comm} is the handle for the Cartesian
  communicator returned from MPI\_CART\_CREATE.
\item The variable \inlinecode{errcode} is the standard error variable for all
  MPI communications. However, \EPOCH uses the standard MPI\_ERRORS\_ARE\_FATAL
  error handler so this variable is never tested.
\item \EPOCH uses a single variable, \inlinecode{status}, to hold all MPI
  status calls. Since there is no non-blocking communication this variable
  isn't ever checked.
\item The rank of the current processor is stored in the variable
  \inlinecode{rank}
\item The number of processors is stored in \inlinecode{nproc}
\item The number of processors assigned to any given direction of the Cartesian
  topology is given by \inlinecode{nproc\_\{x,y,z\}}
\end{itemize}

There are some other variables which are not technically part of the MPI
implementation, but which only exist because the code is running in
parallel. These are
\begin{itemize}
\item \inlinecode{REAL(num) :: \{x,y,z\}\_start\_local} - The location of the
  start of the domain on the local processor in real units.
\item \inlinecode{REAL(num) :: \{x,y,z\}\_end\_local} - The location of the end
  of the domain on the local processor in real units.
\item \inlinecode{INTEGER, DIMENSON(1:nproc\{x,y,z\}) ::
    cell\_\{x,y,z\}\_start} - The cell number for the start of the local part
  of the global array in each direction
\item \inlinecode{INTEGER, DIMENSON(1:nproc\{x,y,z\}) :: cell\_\{x,y,z\}\_end}
  - The cell number for the end of the local part of the global array in each
  direction
\end{itemize}

\subsubsection{\inlinecode{mpi\_routines.f90}}
\inlinecode{mpi\_routines.f90} is the file which contains all the MPI setup
code. It contains the following routines
\begin{itemize}
\item mpi\_minimal\_init - Routine contains enough code to start MPI enough to
  allow the input deck reader to work. The default \EPOCH code setup means that
  it needs to initialise MPI, obtain the rank and the number of processors.
\item Setup\_Communicator - Routine which creates the Cartesian communicator
  used by the code after the input deck has been parsed. It also populates
  \inlinecode{left, right} etc. It is in it's own subroutine so that it can be
  recalled after the start of the window move when the code is using a moving
  window. This is needed since it is valid to have a non-periodic boundary
  before the window starts to move and a periodic boundary afterwards.
\item mpi\_initialise - This routine calls \inlinecode{Setup\_Communicator} and
  then allocates all the arrays to do with fields etc. It also sets up the
  Particle List objects for each species. If the code is running with only
  manual initial conditions then this routine loads the requested number of
  particles on each processor, otherwise either the restart or the autoloader
  code load the particles.
\item mpi\_close - This routine performs all the needed cleanup before the
  final call to \inlinecode{MPI\_FINALIZE}.
\end{itemize}

\subsubsection{\inlinecode{mpi\_subtype\_control.F90}}
This file contains all the routines which are used to create the MPI types
which are used in the CFD io system. Most of the routines in this section are
used to create the default types used for writing the default variables, and
when modifying the code, it is possible to output anything which has the same
shape and size on disk as the default variables without ever having to use the
routines in this file. However, if you are creating more general modification
which can include variables of different sizes with different layouts across
processors then you may wish to use these routines to create new MPI types to
match your data layout. Any valid MPI type describing the data layout will work
with the CFD library, so there is no absolute need to use these routines. Only
the general purpose subroutines are described here, since most of the other
routines are fairly clear and use these routines internally.
\pagebreak

{\Large \inlinecode{FUNCTION Create\_Particle\_Subtype(nPart\_Local)\\
\HRule \\[0.5cm]
INTEGER(KIND=8) ,INTENT(IN) :: nPart\_Local}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Particle\_Subtype} is a routine which creates an MPI type
representing particles which are spread across different processors with
\inlinecode{nPart\_Local} particles on each
processor. \inlinecode{nPart\_Local} does not have to be the same number on all
processors.
\\[0.5cm]
{\Large Notes\\}
If you use this routine to write data from multiple species of particle then
the data will be written out in a way which is unhelpful for data analysis,
since the layout will be "All particles on processor 1, All Particles on
processor 2 etc." rather than "All of species 1, All of species 2". To create
this type of layout use \inlinecode{Create\_Ordered\_Particle\_Subtype}
\pagebreak

{\Large
\inlinecode{FUNCTION Create\_Ordered\_Particle\_Subtype(n\_species\_dump,\\ nPart\_Local)\\
\HRule \\[0.5cm]
INTEGER,INTENT(IN) :: n\_species\_dump\\
INTEGER(KIND=8), DIMENSION(n\_species\_dump), INTENT(IN) \\:: nPart\_Local}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Ordered\_Particle\_Subtype} is a routine which creates an
MPI type representing particles from \inlinecode{n\_species\_dump} which are
spread across different processors with \inlinecode{nPart\_Local(iSpecies)}
particles of each species on each processor. \inlinecode{nPart\_Local} does not
have to be the same number on all processors and does not have to be the same
number for each species.
\\[0.5cm]
{\Large Notes\\}
This routine causes the data to be written to disk as "All of species 1, All of
Species 2 etc." as opposed to \inlinecode{Create\_Particle\_Subtype}. It does
however need rather more memory and is rather slower.
\pagebreak

{\Large
\inlinecode{FUNCTION Create\_Field\_Subtype(n\{x,y,z\}\_local, \\cell\_start\_\{x,y,z\}\_local)\\
\HRule \\[0.5cm]
INTEGER,INTENT(IN) :: n\_x\_local, n\_y\_local, n\_z\_local
INTEGER,INTENT(IN) :: cell\_start\_x\_local, cell\_start\_y\_local, cell\_start\_z\_local
}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{Create\_Field\_Subtype} is a routine which creates an MPI type
representing a field which is defined across some or all of the processors. The
\inlinecode{n\_\{x,y,z\}\_local} parameters are the number of points in the x,
y, z directions (if they exist in the version of the code that you are working
on) that are on the local processor. The
\inlinecode{cell\_start\_\{x,y,z\}\_local} parameters are the offset of the
top, left, back corner of the local subarray in the global array that would
exist if the code was running on one processor. This is an {\it offset}, not a
position and so it begins at \{0,0,0\} NOT \{1,1,1\}.
\\[0.5cm]
{\Large Notes\\}
In EPOCH3D there is also a routine called
\inlinecode{Create\_Field\_Subtype\_2D} which is exactly equivalent to
\inlinecode{Create\_Field\_Subtype} in EPOCH2D and is used for writing the 2D
distribution functions. At present, there are not equivalent 1D functions
except in EPOCH1D, but these could easily by added if required.

\pagebreak

\subsection{The load balancer}
One of the major limiting factors in the scalability of PIC codes is load
balancing. Due to the synchronization of the currents required for the update
of the EM fields the entire code runs at the speed of the slowest
processor. Since most of the time in the main \EPOCH cycle is taken by the
particle pusher, this equates to the code with the highest number of particles
being the slowest. Since the location of particles is dependent upon the
solution of the problem under consideration, in general the code will not have
exactly the same number of particles on each processor. The load balancer is
used to move the interprocessor boundaries so that the number of particles is
as close to the same on each processor as possible. The load balancer is
invoked at the start of the code and when the ratio of the least loaded
processor to the most loaded processor falls below a user specified critical
point.\\

EPOCH's load balancer works by rearranging the processor boundaries in 1D
sweeps in each direction, rather than attempting to perform multidimensional
optimisation. Also, at present the MPI in \EPOCH requires each processor to be
simply connected at every point, so it must have one processor to the left, one
to the front etc. which introduces a further restriction on the load
balancer. Otherwise, the load balancer is fully general. The load balancer is
implemented in the file \inlinecode{src/housekeeping/balance.F90} and is called
by the routine \inlinecode{Balance\_Workload(Override)}. The parameter
\inlinecode{Override} is used to force the code to perform a load balancing
sweep even when it would normally determine that the imbalance is not large
enough to force a load balancing sweep. Although the load balancer is hard
coded to load balance in all available directions, the code is written in such
a way that it is possible to modify the code to load balance in only one
direction, or to automatically determine which single direction gives the best
performance.

\image{./images/sweep.eps}

The details of the load balancer are fairly intricate, and if major
modification to the load balancer is required, it is recommended that the
original authors be contacted for detailed advice on how to proceed. However,
the general layout of the routine is as follows.

\begin{itemize}
\item Use MPI\_ALLGATHER to get the total number of particles on each processor
  and determine the global minimum and maximum number of particles. If the
  ratio of the minimum to the maximum is above the load balance threshold then
  just return from the subroutine.
\item The code uses the routines \inlinecode{GetDensityInX},
  \inlinecode{GetDensityInY} and \inlinecode{GetDensityInZ} to determine the
  pseudoparticle number density along each direction. Each of these routines
  integrates in both other directions.
\item This section of the code fills the arrays \inlinecode{starts\_\{x,y,z\}}
  and \inlinecode{ends\_\{x,y,z\}}. These arrays contain the starting and
  ending cell numbers of the hypothetical global array in each direction for
  each processor.
\item The routine \inlinecode{Redistribute\_Fields} is then called to move the
  information about field variables which cannot be recalculated. If new field
  variables are created that cannot be recalculated after the load balancing is
  completed then \inlinecode{Redistribute\_Fields} has to be modified for these
  new variables.
\item The next section of the routine deals with those variables which can be
  recalculated after the load balance sweep is complete, such as the coordinate
  axes and the arrays which hold the particle kinetic energy.
\item The penultimate section of the routine then changes the variables which
  tell the code where the edges of it's domain lie in real space to reflect the
  changed shape of the domains.
\item The final part is the call to \inlinecode{Distribute\_Particles} which
  finally moves the particles to the correct new processor. Once this is
  finished, the code should have as near as possible the same number of
  particles on each processor.
\end{itemize}

Most of the load balancer is purely mechanical and should only be changed if
the way in which the code is to perform load balancing is fundamentally to be
changed. The redistribution of particles that takes place in
\inlinecode{Distribute\_Particles} uses the standard ParticleList objects, so
that if the necessary changes have been made to the routines in
\inlinecode{src/housekeeping/partlist.F90} have been made to allow correct
boundary swaps of particles then the load balancer should work with no further
modification. The only part of the load balancer which should need modifying is
\inlinecode{Redistribute\_Fields} which requires explicit modification if new
field variables are required. For fields which are the same shape as the main
array there is significant assistance provided within the code to make the
rebalancing simpler. There are also routines which can help with rebalancing
variables which are the size of only one edge or face of the domain. Variables
which are of a completely different size but still need to be rebalanced when
coordinate axes move have to have full load balancing routines implemented by
the developer. This is beyond the scope of this manual and any developer who
need assistance with developing such a modification should contact the original
developer. The field balancer is fair simple and mostly calls one of three
routines: \inlinecode{Redistribute\_Field} and either
\inlinecode{Redistribute\_Field\_2D} or \inlinecode{Redistribute\_Field\_1D}
depending on the dimensionality of your code. To redistribute full field
variables the routine to use is \inlinecode{Redistribute\_Field}, and an
example of using the code looks like

\simpleboxverbatim
    temp=0.0_num
    CALL Redistribute_Field(new_domain,Bz,temp)
    DEALLOCATE(Bz)
    ALLOCATE(Bz(-2:nx_new+3,-2:ny_new+3))
    Bz=temp
\end{Verbatim}

This is a very obvious calling sequence where the
\inlinecode{Redistribute\_Field} subroutine is used to redistribute the field
given (in this case \inlinecode{Bz}) with the newly redistributed field copied
into \inlinecode{temp} which is an array which is already allocated to the
correct size. The \inlinecode{new\_domain} parameter is an array indicating the
location of the start and end points of the new domain of the current processor
in gridpoints offset from the start of the global array. It is passed into the
\inlinecode{Redistribute\_Fields} subroutine as a parameter from the
\inlinecode{Balance\_Workload} subroutine and should not be changed. The
\inlinecode{Temp} variable is needed since Fortran standards before Fortran2000
do not allow the deallocation and reallocation of parameters passed to a
subroutine, and the partial implementation of Fortran2000 in many modern
compilers means that the more elegant solution where \inlinecode{Temp} is
hidden inside the \inlinecode{Redistribute\_Field} subroutine will work with
some compilers, fail to compile with others and generate hard to diagnose
compiler errors with other compilers. It was decided to use the less elegant
but more compatible form here.\\

The routine for rebalancing variables which lie along an edge of the domain are
very similar and are demonstrated in the \inlinecode{Redistribute\_Fields}
subroutine for the lasers which are attached to different boundaries. It is
recommended that a developer examine this code when developing new routines.

\subsection{\EPOCH IO}

\EPOCH uses a file format called {\it CFD} which was custom developed for use
with codes developed by CFSA at the University of Warwick. The internal
structure of CFD files is documented in the CFD documentation available from
CFSA, but it is not necessary to have a full understanding of the file format
to add the output of new variables to \EPOCH. To add a new variable to EPOCH's
output, you simple have to use the supplied subroutines of the CFD library
which is part of \EPOCH. The file output from \EPOCH takes place in the file
{\it diagnostics.F90}, so to add new variables to the output you must add
additional code there. Looking through the listings, you will see two lines

\simpleboxverbatim
       CALL cfd_Open(filename,rank,comm,MPI_MODE_CREATE + MPI_MODE_WRONLY)

       CALL cfd_Close()
\end{Verbatim}

These, as may be expected, are the commands which open and close the CFD
file. It is perfectly possible to create new CFD files containing only your own
data, but currently the CFD routines only permit one open file at a time. There
are various commands in-between which actually write the data into the
file. Most of these commands start with \inlinecode{cfd\_} which marks them as
CFD file commands. Some more complex areas of IO, such as the particle probes
and the distribution function routines call other subroutines in their
respective source files, but these too make use of the CFD routines to actually
write data. A user should never try to write data directly to the output file,
since this will cause problems with internal parts of the CFD format and
generate a non-sensical file. There are routines in CFD which allow the writing
of arbitrary data INTO a CFD file which are described later.

\subsubsection{DumpMask}
Looking through {\it diagnostics.F90} there are many lines with commands which
begin \inlinecode{cfd\_}, but they are all prepended with a command which looks
like
\simpleboxverbatim
     IF (IAND(DumpMask(28),code) .NE. 0) THEN
\end{Verbatim}
This is the way in which \EPOCH allows the end user to specify whether a
variable should be dumped, and whether it should only be dumped at
full/partial/restart dumps. DumpMask is an integer array the length of which is
defined by the variable \inlinecode{num\_vars\_to\_dump} in
\inlinecode{shared\_data.f90} and contains the bitmask representing all the
types of output which should be written for the associated variable. The
possible values in the bitmask are

\begin{itemize}
\item \inlinecode{IO\_NEVER} - Never dump this variable
\item \inlinecode{IO\_ALWAYS} - Dump this variable at every output dump
\item \inlinecode{IO\_FULL} - Dump this variable at full dumps
\item \inlinecode{IO\_RESTARTABLE} - Dump this variable for restart dumps
\item \inlinecode{IO\_SPECIES} - If meaningful for this variable write
  information for each species rather than integrated for all species
\end{itemize}

When adding a new variable to be written to disk the value of
\inlinecode{num\_vars\_to\_dump} should be increased to match the number of new
written variables. Then open the file \inlinecode{src/deck/deck\_io\_block.F90}
and find the line
\simpleboxverbatim
  CHARACTER(len=EntryLength),DIMENSION(IOBlockElements) ::   IOBlockName =  ...
\end{Verbatim}

and simply add new strings for your new variables to the end of the
definitions. These new variable names should then be placed in your input decks
in the same place as the existing IO information and take the same parameters.

\subsubsection{Actually writing the variables}
There is a full manual for the CFD file format describing all the commands
already in existence and all planned commands for the future, so in this
manual, CFD commands will only be presented in the section where they are used.

\subsection{Adding a derived variable}

As already stated, derived variables are variables which are defined on the
Cartesian spatial grid, but are not directly updated by the solver. They are
calculated when needed for output or for use in other physics packages. The
final form of a derived variable is an array on each processor with the same
size as the field arrays.

\subsubsection{Writing your variable to disk}
A derived variable is defined on the same grid as the main simulation variables
and must be written to disk in such a way as to stitch the parts of the grid
from each processor together. This is acheived using one of the routines
\simpleboxverbatim
CALL cfd_Write_1D_Cartesian_Variable_Parallel(Name,GroupName,Dims,Stagger,GridName&
            ,GridGroup,Variable(1:nx),subtype_field)

CALL cfd_Write_2D_Cartesian_Variable_Parallel(Name,GroupName,Dims,Stagger,GridName&
            ,GridGroup,Variable(1:nx,1:ny),subtype_field)

CALL cfd_Write_3D_Cartesian_Variable_Parallel(Name,GroupName,Dims,Stagger,GridName&
            ,GridGroup,Variable(1:nx,1:ny,1:nz),subtype_field)
\end{Verbatim}
The parameters have the following types and meanings

\begin{itemize}
\item Name - The name of the variable
\item GroupName - The group of the variable. In IDL and Matlab a variable can
  be loaded either by GroupName or Name, and in VisIt, the variable name
  appears under a submenu of the variable groupname.
\item Dims - An nD integer array containing the GLOBAL length of the variable
  across all processors. In \EPOCH a variable actually called ``Dims'' exists
  for variables which are the same size as the default field variables.
\item Stagger - An nD REAL(num) array containing the stagger of a variable from
  the cell centre in fractions of a cell. This property is not used in EPOCH,
  so the default variable ``Stagger'' can be used safely.
\item GridName - The name of the grid to which the variable is attached. In
  EPOCH, the main grid is just called ``Grid''. Note that this property is case
  sensitive.
\item GridGroup - The groupname of the grid to which the variable is
  attached. in EPOCH, the main gridgroup is just called ``Grid''. Note that
  this property is case sensitive.
\item Variable - The actual variable to be written to disk. The variable passed
  here must be a REAL(num) array(1:nx,1:ny,1:nz),(1:nx,1:ny),(1:nx) depending
  on dimensionality of code. It is acceptable to pass an array subsection to
  this routine.
\item subtype\_field - This is an MPI type representing the layout of the data
  across the processors. For a standard field variable, there is an
  automatically created type called ``subtype\_field'' which should be used
  here.
\end{itemize}

It's probably easiest to see how the code implements the output of simple
variables like Ex or Ey for an example of how this works. Once this line has
been added to the code, and the code compiled and run, there is no further work
to be done. The IDL, Matlab and VisIt routines will all read the existence of
the variable from the metadata in the CFD file, and it will now be available to
view in all CFD reading packages.

There is a working variable called \inlinecode{Data} which is large enough to
contain the data which is large enough to store a derived variable. It is
therefore recommended that to calculate derived variables a new subroutine
should be created which populates \inlinecode{Data} with the required variable
and then write it to disk. An example would look like
\simpleboxverbatim
IF (IAND(dumpmask(30),code)) THEN
	CALL Calc_My_Variable(Data)
	CALL cfd_Write_2D_Cartesian_Variable_Parallel("my_variable","derived",Dims,Stagger,GridName&
            ,GridGroup,Data(1:nx,1:ny),subtype_field)
\end{Verbatim}
where \inlinecode{Calc\_My\_Variable} is a function which calculates the
variable which you wish to write. The form of this function depends on the type
of variable to be calculated and is given in the next section.


\subsection{Adding a particle variable}
The next simplest type of output to add is a new property for all particles. To
add a new particle variables dump two things are needed : a call to the CFD
command to write the data and an iterator function to iterate through all the
particles. The iterators are stored in the file {\it iterators.F90}. An example
iterator is

\simpleboxverbatim
  !Iterator for particle processor
  SUBROUTINE iterate_species(data,n_points,start)

    REAL(num),DIMENSION(:),INTENT(INOUT) :: data
    INTEGER(8),INTENT(INOUT) :: n_points
    LOGICAL, INTENT(IN) :: start
    TYPE(Particle),POINTER,SAVE :: Cur
    INTEGER(8) :: partcount
    REAL(num) :: root

    TYPE(ParticleList),POINTER,SAVE :: CurrentList
    TYPE(ParticleFamily),POINTER,SAVE :: CurrentFamily

    IF (start)  THEN
       CALL Start_ParticleFamily(CurrentFamily,CurrentList,Cur)
    ENDIF
    partcount=0
    DO WHILE (ASSOCIATED(CurrentFamily) .AND. (partcount .LT. n_points))
       DO WHILE (ASSOCIATED(CurrentList) .AND. (partcount .LT. n_points))
          DO WHILE (ASSOCIATED(Cur) .AND. (partcount .LT. n_points))
             partcount=partcount+1
             data(partcount)=REAL(CurrentFamily%ID,num) !This is
                !the line which writes the data
             Cur=>Cur%Next
          ENDDO
          !If the current partlist is exhausted, switch to the next one
          IF (.NOT. ASSOCIATED(Cur)) CALL Advance_ParticleList(CurrentList,Cur)
       ENDDO
       !If the current particlefamily is exhausted, then switch to the next one
       DO WHILE (.NOT. ASSOCIATED(Cur))
          CALL Advance_ParticleFamily(CurrentFamily,CurrentList,Cur)
          IF (.NOT. ASSOCIATED(CurrentFamily)) EXIT
          IF ((.NOT. CurrentFamily%Dump) .AND. (.NOT. Iterator_Settings%Restart))&
             NULLIFY(Cur)
       ENDDO
    ENDDO
    n_points=partcount

  END SUBROUTINE iterate_species
\end{Verbatim}

This is a fairly complicated routine, and includes routines to deal with the
possibility of particle species not being dumped, and other similar
effects. Luckily, there is only one line in the routine which needs to change
to output a new routine. The is the line
\simpleboxverbatim
             data(partcount)=REAL(CurrentFamily%ID,num)
\end{Verbatim}

To write a new iterator, you just have to copy the skeleton of an existing
iterator and change this line to copy your particle property into the ``data''
array. The details of how this routine works is explained in the ``particles,
particle\_lists and particle\_families'' of the ``deep internals'' section of
the developer guide. Once your new iterator has been written and added into the
{\it iterators.F90} file, it's time to add the CFD routine to actually write
the data. The routine is
\simpleboxverbatim
CALL cfd_Write_nD_Particle_Variable_With_Iterator_All(name,groupname&
            ,iterator_name,npart_dump_global,n_part_per_it,gridname,gridgroup,subtype_particle_var)
\end{Verbatim}

The parameters this time are
\begin{itemize}
\item name - The name of the variable to be output
\item groupname- The name of the group that the variable is in. Normally all
  \EPOCH particle variables are in group ``particle'', but there is no reason
  to enforce this.
\item iterator\_name - The name of the iterator function that you created in
  the previous step. Note that this is not a string but simply the name of the
  function.
\item npart\_dump\_global - The number of particles to be written to disk
  across all processors. When writing a standard particle variable this is the
  named variable ``npart\_dump\_global''.
\item npart\_per\_it - The number of particles to write for each loop of the
  iterator. This should normally be the named variable ``npart\_per\_it''.
\item gridname - The name of the grid (particle positions) that the variable
  corresponds to. In EPOCH, this is ``Particles''.
\item gridgroup - The group of the grid (particle positions) that the variable
  corresponds to. In EPOCH, this is ``Part\_Grid''.
\item subtype\_particle\_var - An MPI type representing the layout of particles
  across processors species by species. For a default particle variable, this
  is the named variable ``subtype\_particle\_var''.
\end{itemize}

Once again, looking at how this is implemented for one of the existing
variables (e.g. Px) is probably the most enlightening way to see how it
works. As for the fluid variables, the new variable will appear in IDL, Matlab
and VisIt.

At this point, it is possible to write any property which is similar to the
default field variables or the default particle properties. It becomes slightly
more challenging if you want to write other types of variable into an output
file. Before you can do this, you really need to fully understand how the MPI
parallelism is implemented in \EPOCH by reading the section {\it MPI in
\EPOCH}. A full description of how to do this is beyond the scope of this
manual, but the same basic commands should be used to write to the CFD file as
are used to write more normal variables, and the CFD manual should be consulted
if more sophisticated changes are needed.

\pagebreak

\subsection{Precompiler directives}
\EPOCH uses precompiler directives to switch certain features of the code on or
off. The precompiler directives all begin with \# and look like
\simpleboxverbatim
#ifdef MY_PRECOMPILER_DIRECTIVE
	SOME_FORTRAN_OF_SOME_KIND
#else
	SOME_OTHER_FORTRAN
#endif
\end{Verbatim}
and they behave in a very simple manner. The precompiler runs BEFORE the
Fortran compiler and until it reaches a precompiler directive, it just creates
a temporary file which is an exact copy of the source file. When it reaches a
precompiler directive of this kind it treats the \#ifdef commands as
if/then/else statements. If the IF test passes and
\inlinecode{MY\_PRECOMPILER\_DIRECTIVE} was defined in the makefile then
\inlinecode{SOME\_FORTRAN\_OF\_SOME\_KIND} is pushed out to the temporary
file. Otherwise \inlinecode{SOME\_OTHER\_FORTRAN} is sent to the temporary
files. The precompiler directives themselves are never output to the temporary
file. The Fortran compiler then compiles this temporary file (or named pipe or
some other implementation of the same idea), unaware that this wasn't then
entire source file as written by the human programmer.

\subsubsection{When to use precompiler directives}
\begin{itemize}
\item When adding properties to the \inlinecode{Particle} structure
\item When adding time consuming calculations to the particle pusher
\end{itemize}
It is perfectly acceptable to use precompiler directives in other cases as
well, but they should not be used as a substitute for having input deck flags
controlling new parts of the code.

\subsubsection{The directive printing routine on code startup}
When \EPOCH starts it prints the precompiler directives that it was built with
and what they mean. This isn't required, but has proved very useful and is
implemented in a very simple way.  Simply open the file
\inlinecode{src/housekeeping/welcome.F90} and find the subroutine
\inlinecode{compiler\_directives}. There are a large block of precompiler
directives which read

\simpleboxverbatim
#ifdef TRACER_PARTICLES
    WRITE(*,*) "Tracer particle support -DTRACER_PARTICLES"
#endif
\end{Verbatim}

Simply add a new element to the end of the list
\simpleboxverbatim
#ifdef MY_PRECOMPILER_DIRECTIVE
    WRITE(*,*) "My new physics -DMY_PRECOMPILER_DIRECTIVE"
#endif
\end{Verbatim}

\subsubsection{Precompiler directives and the input deck}
In theory, it is possible for someone to request a feature of the code in the
input deck which this version of the code hasn't been compiled with. In this
case, there is a special error code \inlinecode{ERR\_PP\_OPTIONS\_WRONG} which
causes the input deck parser to give a meaningful error. You should also set
the string \inlinecode{Extended\_Error\_String} to be the define command for
the missing preprocessor directive i.e
\inlinecode{Extended\_Error\_String="-DMY\_PRECOMPILER\_DIRECTIVE"}

\section{\EPOCH front end programming}

\subsection{Strings in \EPOCH}
Fortran is not a language famous for it's string handling capabilities, but due
to the presence of the input deck \EPOCH has fairly extensive string handling
routines. Strings used are all of the standard Fortran \inlinecode{CHARACTER}
type and are defined as
\simpleboxverbatim
CHARACTER(LEN=EntryLength) :: String
\end{Verbatim}
\inlinecode{EntryLength} is a global constant defined in
\inlinecode{src/shared\_data.F90} which can be increased to allow \EPOCH to
handle longer strings. There may be reasons to increase this length if you wish
to use long complex expressions in the input deck. Note that many Fortran
compilers do not allow strings to exceed 512 characters in length.

\subsubsection{\EPOCH string handling routines}

Listed here are all the string handling routines (other than the core maths
parser routine which are documented elsewhere) which are still currently used
in \EPOCH. Simply looking at the code reveals some other routines which are
historical remnants, left in place to make testing current versions of \EPOCH
against earlier versions easier, and they will probably not remain in
place. Any routines in \inlinecode{src/deck/strings.F90} and
\inlinecode{src/deck/strings\_advanced.F90} which are not mentioned in this
documentation are legacy routines and SHOULD NOT BE USED.

\pagebreak
{\Large \inlinecode{FUNCTION StrCmp(StrIn,StrTest)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn, StrTest\\
LOGICAL :: StrCmp}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{StrCmp} is the routine which does all the string comparisons in
\EPOCH. It deals with leading and trailing whitespace automatically and
automatically tests for length differences. It does not test for strings being
valid substrings of each other, only for full equality.
\\[0.5cm]
{\Large Notes\\}
A developer should always use \inlinecode{StrCmp} rather than doing their own
string testing to ensure consistent behaviour across the entire of \EPOCH.
\pagebreak

\pagebreak
{\Large \inlinecode{FUNCTION AsRealSimple(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR\\
REAL(num) :: AsRealSimple}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsRealSimple} is a routine to convert a string into a real number
without invoking the maths parser. It can cope with standard form as well as
simple decimal reals. It is significantly faster than the maths parser, but
should only be used when the user explicitly {\it shouldn't} be able to use a
mathematical expression. If the string cannot be parsed then the routine sets
the bitmask \inlinecode{ERR\_BAD\_VALUE} on the parameter \inlinecode{ERR}
\\[0.5cm]
{\Large Notes\\}
If you have a string which has to be converted into a real quickly then this is
the routine to use. You probably shouldn't use it when parsing a string from
the input deck, since there is no reason to restrict the user from specifying a
mathematical expression. The routine is used inside the maths parser to parse
simple numbers.
\pagebreak

\pagebreak
{\Large \inlinecode{FUNCTION AsIntegerSimple(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR\\
INTEGER :: AsIntegerSimple}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsIntegerSimple} is a routine to convert a string into an integer
without invoking the maths parser. It can cope with standard form as well as
simple decimal integers. It is significantly faster than the maths parser, but
should only be used when the user explicitly {\it shouldn't} be able to use a
mathematical expression. If the string cannot be parsed then the routine sets
the bitmask \inlinecode{ERR\_BAD\_VALUE} on the parameter \inlinecode{ERR}
\\[0.5cm]
{\Large Notes\\}
This routine is used internally in several parts of the code when parsing
things like numbers which are parts of strings (i.e. the 1 in
\inlinecode{begin:species1}). It probably shouldn't be used to directly parse
input deck parameters, since there is no reason to restrict the user from
specifying mathematical expressions.
\pagebreak

{\Large \inlinecode{FUNCTION AsLongIntegerSimple(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR\\
INTEGER(KIND=8) :: AsLongIntegerSimple}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsLongIntegerSimple} is equivalent to \inlinecode{AsIntegerSimple}, but returns a the larger \inlinecode{INTEGER(KIND=8)} rather than a normal \inlinecode{INTEGER(KIND=4)}.
\\[0.5cm]
{\Large Notes\\}
\pagebreak

\pagebreak
{\Large \inlinecode{FUNCTION AsDirection(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR\\
INTEGER :: AsDirection}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsDirection} is used when assigning a laser to a boundary and
recognizes the strings
\begin{itemize}
\item left - BD\_LEFT
\item right - BD\_RIGHT
\item up - BD\_UP
\item down - BD\_DOWN
\item front -BD\_FRONT
\item back - BD\_BACK
\end{itemize}
and returns the associated direction code (given after the dash in the
definition).
\\[0.5cm]
{\Large Notes\\}
If you're writing something which required attaching something to a boundary,
whether a boundary condition, a diagnostic or some other routine then this is
the routine that should be used. Note that in order to prevent confusion when
moving input decks between different dimension versions of EPOCH, each code
only recognises the strings for boundaries that it actually has.
\pagebreak

\pagebreak
{\Large \inlinecode{FUNCTION AsLogical(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR
Logical :: AsLogical}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsLogical} simply tests for the strings "T" and "F" to determine a
boolean value. The default behaviour of \inlinecode{AsLogical} is to treat any
string that isn't "T" as a false value.
\\[0.5cm]
{\Large Notes\\}
You should use this rather than using a 0/1 boolean flag in the input deck for
consistency.
\pagebreak

\pagebreak
{\Large \inlinecode{SUBROUTINE  SplitOffInt(StrIn,StrOut,IntOut,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
CHARACTER(LEN=EntryLength),INTENT(OUT) :: StrOut\\
INTEGER,INTENT(OUT) :: IntOut\\
INTEGER,INTENT(INOUT) ::ERR}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{SplitOffInt} is a routine which splits a string of the format {\bf
string{\it n}} into a string {\bf string} and an integer {\it n} which are
returned separately in the \inlinecode{StrOut} and \inlinecode{IntOut}
parameters respectively.  If it can't split the string successfully then it
sets the \inlinecode{ERR\_BAD\_VALUE} bitfield of the ERR parameter.
\\[0.5cm]
{\Large Notes\\}
This is used in the core of the deck parser to deal with blocks like the
numbered species blocks in the initial conditions, and also in some of the
specific block parsers. Again, this routine should be used to split strings
like this rather than coding a new routine.
\pagebreak

\pagebreak
{\Large \inlinecode{SUBROUTINE  SplitRange(StrIn,Real1,Real2,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
REAL(num),INTENT(OUT) :: Real1, Real2\\
INTEGER,INTENT(INOUT) ::ERR}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{SplitRange} is a routine which splits a string of the format
{\bf{\it n} > {\it m}} into two reals {\it n} and {\it m} which are returned
separately in the \inlinecode{Real1} and \inlinecode{Real2} parameters
respectively.  If it can't split the string successfully then it sets the
\inlinecode{ERR\_BAD\_VALUE} bitfield of the ERR parameter.
\\[0.5cm]
{\Large Notes\\}
This is used when specifying ranges in the extended IO decks at present. Any
ranges which should be specified in a single parameter should be specified in
this form and this routine used to split the string. {\bf IMPORTANT NOTE. This
routine has proved somewhat unsatisfactory and may be replaced by another
routine in the future. It is expected that the function will have the same name
and behaviour, but might have subtle differences.}
\pagebreak

\pagebreak
{\Large \inlinecode{FUNCTION AsInteger(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR\\
INTEGER :: AsInteger}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsInteger} is the routine which returns integers from strings using
the maths parser. If a mathematical expression resolves to a non-integer result
then this routine rounds to the NEAREST integer. There are explicit rounding
routines in the maths parser to force other behaviour.
\\[0.5cm]
{\Large Notes\\}
This routine should be used when evaluating most strings into integers. Note
that this routine evaluates spatially dependent quantities at (0,0) on each
processor, so will give unpredictable results when spatially dependent
quantities are given to it (like rho, ex etc.). To evaluate a spatially varying
quantity use \inlinecode{EvaluateStringInSpace}.
\pagebreak

\pagebreak
{\Large \inlinecode{FUNCTION AsLongInteger(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR\\
INTEGER(KIND=8) :: AsLongInteger}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsLongInteger} is the routine which returns long integers from
strings using the maths parser. If a mathematical expression resolves to a
non-integer result then this routine rounds to the NEAREST integer. There are
explicit rounding routines in the maths parser to force other behaviour.
\\[0.5cm]
{\Large Notes\\}
This routine should be used when evaluating strings which are likely to be too
large to be stored in an INTEGER(KIND=4).
\pagebreak

\pagebreak
{\Large \inlinecode{FUNCTION AsReal(StrIn,ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
INTEGER,INTENT(INOUT) ::ERR\\
REAL(num) :: AsReal}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{AsReal} is the routine which returns reals from strings using the
maths parser.
\\[0.5cm]
{\Large Notes\\}
This routine should be used when evaluating most strings into reals. Note that
this routine evaluates spatially dependent quantities at (0,0) on each
processor, so will give unpredictable results when spatially dependent
quantities are given to it (like rho, ex etc.). To evaluate a spatially varying
quantity use \inlinecode{EvaluateStringInSpace}.
\pagebreak

\pagebreak
{\Large \inlinecode{SUBROUTINE EvaluateStringInSpace(StrIn, DataOut, xrange, \{yrange\}, \{zrange\}, ERR)\\
\HRule \\[0.5cm]
CHARACTER(LEN=EntryLength),INTENT(IN) :: StrIn\\
REAL(num),DIMENSION(1:,\{1:\},\{1:\}),INTENT(OUT) :: DataOut\\
INTEGER,DIMENSION(2),INTENT(IN) :: xrange, \{yrange\}, \{zrange\}
INTEGER,INTENT(INOUT) ::ERR}}\\
\\[0.5cm]
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{EvaluateStringInSpace} is a routine which is used to evaluate a
tokenized maths expression over a region of the domain. The dimensionality of
\inlinecode{DataOut}, and the presence or absence of \inlinecode{yrange} and
\inlinecode{zrange} depend on the dimensionality of the code being used. The
\inlinecode{{\it $\alpha$}range} parameters represent the indices in that
direction over which the expression should be evaluated. For example, in 2D to
evaluate an expression over the entire domain, the code would look like
\simpleboxverbatim
REAL(num),DIMENSION(:,:),ALLOCATABLE :: Data
ALLOCATE(Data(0:nx+1,0:ny+1)
CALL EvaluateStringInSpace(String,Data,(/0,nx+1/),(/0:ny+1/),ERR)
\end{Verbatim}
{\Large Notes\\}
This routine is suitable to evaluate expressions over the entire or parts of
the domain, and is used in this way in the initial condition deck parser
routines. However, the routine does have one significant weakness, which is
that it tokenizes the string each time it is called. Tokenizing the string is a
time consuming process, so if the string is to be evaluated several times for
different reasons (for example, the time profile for the laser) then a
different procedure should be followed using the lower level parser routines,
which are described in the section on the maths parser.
\pagebreak

\subsection{Permanently adding blocks to the input deck}

While using the \inlinecode{Custom\_Deck} subroutine is a good way of passing
parameters into the code or for developing the code, it is not suitable for
permanent additions to the code. Adding new blocks to the code permanently is
very similar to doing it temporarily, but requires changes to some of the
subroutines in \inlinecode{deck.F90}.\\

There are four subroutines which may need to be changed to add new blocks to
the deck. These are
\begin{itemize}
\item \inlinecode{StartBlock(BlockName)} - Called when the deck directive
  \inlinecode{begin:{\it BlockName}} appears in a deck file.
\item \inlinecode{EndBlock(BlockName)} - Called when the deck directive
  \inlinecode{end:{\it BlockName}} appears in a deck file.
\item \inlinecode{HandleBlock(BlockName,BlockElement,BlockValue)} - Called once
  for each element in a block.
\item \inlinecode{CheckCompulsoryBlocks(errcode\_deck)} - Called once when the
  deck file has been read to check that all necessary blocks have been
  populated.
\end{itemize}

There is one final variable which is important for modifying the input deck,
\inlinecode{Deck\_State}. The input deck parser routine used to read the main
input deck, the initial conditions file and the extended IO file is all the
same routine, and it just uses the variable \inlinecode{Deck\_State} to
determine which type of file is being read. The possible values of
\inlinecode{Deck\_State} are

\begin{itemize}
\item DS\_DECK - The main input deck
\item DS\_IC - The initial conditions file
\item DS\_EIO - The extended IO file
\end{itemize}
These constants are defined in \inlinecode{shared\_data.F90} and if new files
need to be read, then new variables should be created in the same place with
similar names using the \inlinecode{DS\_} prefix.

The layout of \inlinecode{StartBlock} and \inlinecode{EndBlock} is very simple,
and simply tests \inlinecode{Deck\_State} to makes sure that the deck reader is
reading the right file, then uses \inlinecode{StrCmp} to test the block name,
and then if necessary calls the correct routine to deal with the start or
finish of a block.

The main routine which needs to be explained is \inlinecode{HandleBlock}, which
is the function which determines which subroutine to call to parse the elements
of a given block. The function is very simple and has the same basic sequence
as the \inlinecode{StartBlock} and \inlinecode{EndBlock} functions. First check
what file is being parsed by checking \inlinecode{Deck\_State}, then use
\inlinecode{StrCmp} to compare the \inlinecode{BlockName} parameter with the
list of known block names. What happens next is dependent on exactly what a
developer wants their block to do, but at the simplest level, the routine
simply calls another function which takes the ElementName and ElementValue as
parameters and returns an error code from Appendix A determining the success or
failure of reading the element. Some blocks have slightly more sophisticated
entries in \inlinecode{HandleDeck} such as the \inlinecode{Species} block in
the initial conditions file reader which strips the species number off the end
of the block name and passes it to the handler routine. The routines that deal
with constants and DEOs are implemented before any tests to
\inlinecode{Deck\_State} since it is valid to set constants and DEOs in any
type of file.

The final routine is \inlinecode{CheckCompulsoryBlocks} which is used to check
that all the needed elements of the input deck have been set. A single
parameter \inlinecode{errcode\_deck} is passed in. Once again, the routine
checks \inlinecode{Deck\_State} to make sure that it is testing the correct
type of input deck file. It then goes through and calls functions to check that
all the necessary parts of a block have been set. The subroutines are contained
in the same file as the routine which is called in \inlinecode{HandleBlock} to
handle elements of the block. The error handler functions should return an
error code from Appendix A, usually \inlinecode{ERR\_MISSING\_ELEMENTS}. The
return code from the error handle function should then be \inlinecode{IOR}ed
with \inlinecode{errcode\_deck} to allow error codes to be returned from
several different checks with errors occurring.

\subsubsection{The element handler routines for deck elements}
The exact form of the handler routines is up to the end user, the only {\it
requirements} are that the routine should return an error code detailing
whether or not there are any problems with reading the block and that the error
code should be \inlinecode{ERR\_NONE} if either the element name or element
value are the special constant \inlinecode{blank}. The typical implementation
of an element handler routine is shown in the routine
\inlinecode{src/deck/deck\_control\_block.f90}, and this general layout should
be copied for compatibility if this is possible.\\

Sometimes, it is useful to have each new block correspond to a new instance of
an object in the code. An example of this in \EPOCH is in
\inlinecode{src/deck/deck\_ic\_laser\_block.f90} where each new laser block in
the input deck corresponds to a new laser being attached to a boundary. This is
allowed by implementing the lasers as a linked list on each boundary, with a
new laser object being created when a laser block is started, the laser
information being set during the main reader routine, and then the laser being
attached to the linked list by a call to \inlinecode{Attach\_Laser} in
\inlinecode{src/laser.f90} when the block is ended. When a new laser block is
started the process simply repeats allowing the end user to have as many lasers
as desired.

\subsubsection{Naming new element handler files}
While the name of the function which deals with elements of a new block is up
to the end user, the file should try to follow the form of the existing
names. That is the name should have the following form, remembering that works
should be spaced out using \_ characters.
\begin{itemize}
\item Begin with \inlinecode{deck\_}
\item If the block isn't in the main input deck (input.deck) then there
  should be a code here which details which input deck file is begin read
  when this block is valid. For the existing input deck files this would be
  \subitem \inlinecode{IC\_} for the initial conditions file.
  \subitem \inlinecode{EIO\_} for the extended io file.
\item The next element should be the name of the block followed by \_.
  i.e. \inlinecode{control\_}
\item The final element should just be the work \inlinecode{block}
\end{itemize}

\subsubsection{Adding elements to existing blocks}
The existing blocks in the code are read in the following files
\begin{itemize}
\item \inlinecode{deck\_boundaries\_block.f90} - Input deck boundary block
\item \inlinecode{deck\_constant\_block.f90} - Sets constants in all deck files
\item \inlinecode{deck\_control\_block.f90} - Input deck control block
\item \inlinecode{deck\_deo\_block.f90} - Deferred Evaluation Objects in all
  deck files
\item \inlinecode{deck\_eio\_dist\_fn\_block.f90} - Extended IO deck dist\_fn
  blocks
\item \inlinecode{deck\_eio\_particle\_probe\_block.F90} - Extended IO deck
  probe blocks
\item \inlinecode{deck\_ic\_external\_block.f90} - Initial conditions deck for
  reading species\_external and field\_external blocks.
\item \inlinecode{deck\_ic\_fields\_block.f90} - Initial conditions deck field
  blocks
\item \inlinecode{deck\_ic\_laser\_block.f90} - Initial conditions deck laser
  blocks
\item \inlinecode{deck\_ic\_species\_block.f90} - Initial conditions deck
  species\{n\} blocks.
\item \inlinecode{deck\_io\_block.F90} - Input deck output blocks.
\item \inlinecode{deck\_species\_block.F90} - Input deck species blocks.
\item \inlinecode{deck\_window\_block.f90} - Input deck window block.
\end{itemize}

The existing structure of the blocks is simple enough in most cases that it
should be fairly easy to add new elements if needed. The most likely change
needed is to change the list of variables to dump in the \inlinecode{output}
block. How to do this is detailed in the section on \EPOCH IO.

\subsection{Permanently adding functions, constants to \EPOCH}
In much the same way that it is possible to permanently add new blocks to the
input deck, it is also possible to permanently add functions and constants to
EPOCH's maths parser, although adding new operators is possible, it is
sufficiently likely to cause problems with the operation of the maths parser
that it is formally not recommended by the author of the program, and hence is
not documented here.

\subsubsection{Adding the new tokenizer handle}
When adding a new function or constant to the maths parser using the temporary
routines, there are routines, \inlinecode{RegisterFunction} or
\inlinecode{RegisterConstant} which give a numerical handle which is the token
used to represent that function or constant after the text has been parser
(remember that EPOCH's maths parser tokenizes before evaluation!). When
permanently adding objects to the maths parser, the tokenizer handles have to
be set up manually. This takes place in \inlinecode{src/shared\_data.F90} in
the module \inlinecode{shared\_parser\_data}. There are several lines which
look like
\simpleboxverbatim
  INTEGER,PARAMETER :: CONST_IX=40, CONST_IY=41, CONST_IZ=42
  .
  .
  .
  INTEGER,PARAMETER :: FUNC_TEMPZ=21, FUNC_INTERPOLATE=22, FUNC_TANH=23
\end{Verbatim}
Constants beginning with \inlinecode{CONST\_} are tokenizer handles for
constants, and those beginning with \inlinecode{FUNC\_} are tokenizer handles
for functions. Each number has to be unique and has to be less than a number
which represents the lower bound of values reserved for temporary or deck
specified values. This means that any tokenizer handle for a function has to be
less than the value of the variable \inlinecode{FUNC\_CUSTOM\_LOWBOUND} and any
handle for a constant must be less than \inlinecode{CONST\_DECK\_LOWBOUND}. It
is acceptable to simply increase the value of
\inlinecode{FUNC\_CUSTOM\_LOWBOUND} and \inlinecode{CONST\_DECK\_LOWBOUND} to
allow the use of more values for internal constants and functions, although
care should be taken, since this means that you are at the point of having {\it
thousands} of constants or functions, and some simplification is probably
needed, since the maths parser is probably rather slow by this point. If
\inlinecode{CONST\_DECK\_LOWBOUND} is increased then the constant
\inlinecode{CONSTANT\_CUSTOM\_LOWBOUND} should be increased by the same amount
(The values between \inlinecode{CONST\_DECK\_LOWBOUND} and
\inlinecode{CONSTANT\_CUSTOM\_LOWBOUND-1} are used for constants specified
inside the input deck while values greater than or equal to
\inlinecode{CONSTANT\_CUSTOM\_LOWBOUND} are used for constants specified by
\inlinecode{RegisterConstant}.

Once the tokenizer handle is specified in \inlinecode{shared\_parser\_data}, it
is now possible to extend the main areas of the maths parser. Note that from
here on it, you MUST always use the constant named handle, NEVER the numerical
value that you specified for the value of the handle, otherwise combining
functions and constants from several sources becomes much harder.

\subsubsection{Adding the new function or constant to the tokenizer}
The next stage is to add the string representation of your constant or function
to the tokenizer routines in
\inlinecode{src/parser/tokenizer\_blocks.F90}. This is very simple to do, just
find either the function \inlinecode{AsConstant} or \inlinecode{AsFunction} and
look at the existing code. These functions are just long lists of
\inlinecode{StrCmp} commands followed by code to deal with custom
functions/constants. To add the new code, just add an additional line looking
like
\simpleboxverbatim
    IF (StrCmp(name,"my_const")) AsConstant=CONST_MY_CONST
    .
    .
    .
    IF (StrCmp(name,"my_func"))    AsFunction=FUNC_MY_FUNC
\end{Verbatim}
Note that neither routine returns immediately after recognising the name of the
function/constant. This allows users to override built in constants or
functions with custom versions using \inlinecode{RegisterConstant} and
\inlinecode{RegisterFunction}. This is not significant, since tokenizing should
never be used in a speed critical part of the code.

\subsubsection{Implementing the function or constant in the evaluator}
The evaluator is the part of the code that actually takes the streams of tokens
produced by the tokenizer and evaluates them into a number. The relevant parts
of the evaluator for adding new constants or functions are in
\inlinecode{src/parser/evaluator\_blocks.F90} and the functions which may need
changing are \inlinecode{DoConstant} and \inlinecode{DoFunctions} which are
both passed up to five parameters, these parameters being
\begin{itemize}
\item INTEGER :: OpCode - The operation code, this is the tokenizer handle
  which was defined in \inlinecode{shared\_parser\_data}
\item INTEGER :: ix, iy ,iz - The position of the current evaluation in the
  domain. If your function or constant behaves differently at different points
  in space then you should use these parameters to reference the correct point
  of an array.
\item INTEGER :: errcode - This should be set to an error code from Appendix A,
  usually \inlinecode{ERR\_BAD\_VALUE} if for some reason it is not possible to
  evaluate your constant or function.
\end{itemize}

The rest of the routine to set a constant is as simple as testing for the
tokenizer handle already set up in \inlinecode{shared\_parser\_data} and then
calling the subroutine \inlinecode{PushOnEval} which pushes the final constant
onto the evaluation stack which is used by the RPN parser. The basic sequence
for functions is similar except for the addition of the code to read the values
that the function takes, this is again the subroutine \inlinecode{GetValues}
which is also used in custom function. The calling sequence in
\inlinecode{DoFunction} looks like

\simpleboxverbatim
    IF (opcode .EQ. FUNC_GAUSS) THEN
       CALL GetValues(3,Values)
       CALL PushOnEval(EXP(-((Values(1)-Values(2))/Values(3))**2))
       RETURN
    ENDIF
\end{Verbatim}
Simple call the \inlinecode{GetValues} subroutine passing the number of
required parameters and an array of type \inlinecode{REAL(num)} which is at
least as long as the number of required parameters, and the array is populated
by the values passed into the function, constants and maths expressions are
already evaluated by the time that this section of code is reached, so there is
no need to deal with further parsing. Then simply call \inlinecode{PushOnEval}
to push the result of your function onto the evaluation stack.

\section{Developing an extension to \EPOCH}

Exactly how to extend \EPOCH depends heavily upon what you intend to add. The
simplest thing is to add a new diagnostic to the code, and this is detailed in
the section on \EPOCH IO. Other than simply adding new diagnostics to the code,
there are a few main places where changes to the code will probably be needed
to develop and extension to \EPOCH. These are
\begin{itemize}
\item The field solver - Changing the field solver to add new laser like
  boundaries, add spatial smoothing to remove noise, add high order field
  solvers etc.
\item The particle pusher - Change the basic physical model of \EPOCH by
  modifying the particle pusher
\item The boundary routines - Add new boundary conditions or modify existing
  boundary conditions
\item The laser boundary routines - Add new features to the laser boundaries in
  this routine
\item The main driver (\inlinecode{epoch\{n\}d.F90}) - This is the routine
  where the main calling sequence of \EPOCH is setup, and totally new
  extensions to \EPOCH should be placed in here.
\end{itemize}

Changing the field solver or the particle pusher or the l is fairly easily
accomplished by reading the section of this manual detailing the relevant part
of the code, reading through the code making sure that it all makes sense and
then make the necessary changes. The general sequence for writing an extension
would be
\begin{itemize}
\item Add any new global variables needed to \inlinecode{shared\_data.F90}
\item Add the meat of your change to the code
\item Test the change to your code. Make absolutely sure that you can turn your
  change to the code off.
\item Add controls for your extension to the input deck reader.
\end{itemize}

\subsection{The main driver routine}
When adding completely new routines to the code, they should be added to the
file \inlinecode{src/epoch\{n\}d.F90}. This routine simply calls other routines
which perform the actual execution of the code. The first section of the code
controls the setup of the basic parts of the code, MPI initialization and
setting up initial conditions. If you wish to add new startup conditions then
you should find out at which point of this routine sufficient parts of the
initial conditions are setup. The setup of the code is fairly complicated, but
there are a few key points at which the code significantly changes state.
\begin{itemize}
\item After the call to \inlinecode{Read\_Deck} the code has read the basic
  information from the input deck files and any tests or changes which have to
  be made to input deck values should be made immediately after this line. Note
  that although the variables from the deck have been set and have been stored
  to the correct variables, none of these values have been used, so allocatable
  variables haven't been allocated. The grid does not exist at this point.
\item After the call to \inlinecode{open\_files} the code has finished
  allocating all field variables, although particles may not yet have been set
  up. The grid now exists.
\item There are now a series of \inlinecode{IF} statements which test for
  things like \inlinecode{IF (IOR(ictype,IC\_AUTOLOAD) .NE. 0)}. These lines
  are the lines which test for all the possible states of the initial
  conditions. The last test is for the manual load routine
  (\inlinecode{IC\_MANUAL}). After this test all the particles have been loaded
  and are now on their correct processor. The load balancer has now been called
  at least once so the domains may no longer be identical.
\item The main loop is a simple do loop beginning with just a single command of
  \inlinecode{DO}. Inside this loop there are several calls the routines which
  actually advance the system. Most routines which can change currents should
  take place after the particle pusher but before the final update for the E
  and B routines. These routines are
  \subitem \inlinecode{set\_dt} - This routine sets the timestep.
  \subitem \inlinecode{update\_eb\_fields\_half} - Time centre the E and B
    fields
  \subitem \inlinecode{push\_particles} - The particle pusher
  \subitem \inlinecode{Reorder\_Particles\_to\_grid} - Groups particles into
    linked lists at each grid point. Used for the particle splitting routine,
    and would be the right place to add a collision operator. Any routine
    which needs to have nearby particles grouped together should take place
    after the call to this routine.
  \subitem \inlinecode{Split\_Particles} - The very early beta particle
    splitting operator. Doesn't really work yet, do not use!
  \subitem \inlinecode{Reattach\_Particles\_to\_mainlist} - Undoes the
    particle grouping and rebuilds the main list of particles used by the
    particle pusher. Any routine which needs to have nearby particles grouped
    together should take place before the call to this routine.
  \subitem \inlinecode{update\_eb\_fields\_final} - Updates the E and B
    fields to the full timestep.
\item After the call to \inlinecode{update\_eb\_fields\_final} the code is
  ready for another timestep. Any routines which do not change the time
  integrated properties of the code (like the moving window) should come after
  this call.
\end{itemize}

\subsection{The particle reordering routine}
If the code is compiled with the right flags during the main loop then the
particles are grouped into a linked list for each cell in the domain, with all
the particles which are in that cell linked into the list. The main list
\inlinecode{Species(iSpecies)\%AttachedList} is empty and cannot be used during
this period. The particles should now be accessed using the variable
\inlinecode{Species(iSpecies)\%SecondaryList(ix,iy,iz)} which is the array of
linked lists. This array is allocated on the call to
\inlinecode{Reorder\_Particles\_to\_grid} and deallocated on the call to
\inlinecode{Reattach\_Particles\_to\_mainlist}, and should not be used outside
the section of code between these two calls. The particles themselves remain
unchanged. No attempt is made to check that particles do not cross processor
boundaries in this section, so if a particle's position is changed, it is up to
the user to ensure that the particle is transferred to another processor if
required. However, if a particle is transferred to another processor, it is
acceptable to relink it to \inlinecode{Species(iSpecies)\%AttachedList} since
the other lists are simply appended to that list when the particles are
reattached to the main list.\\

You should not write an extension to the code which requires the use of the
particle reordering routines if it is not necessary since these routines on
their own take almost 1/20 of the particle pusher which can be quite
significant.

\pagebreak

\appendix
  \begin{center}
    {\bf APPENDICES}
  \end{center}
\section{Error Codes}
The input deck and maths parser in \EPOCH uses various named error codes to
report on errors which occur during the evaluation of the input deck. These
codes are
\begin{itemize}
\item ERR\_NONE - No error. Set an error code to ERR\_NONE to state that no
  error has occurred.
\item ERR\_UNKNOWN\_BLOCK - In the input deck a block has been found which is
  not known. This should be returned in \inlinecode{HandleCustomBlock} if it is
  passed any block but one with which it is familiar.
\item ERR\_UNKNOWN\_ELEMENT - In the input deck an element of a valid block has
  been found which is not known. This should be returned in
  \inlinecode{HandleCustomBlock} if an element is requested which is unknown.
\item ERR\_PRESET\_ELEMENT - An element of the input deck has already been set
  and is being set again. Usually this is an indication of a malformed input
  deck file, so \inlinecode{HandleCustomBlock} should try to identify
  situations where this happens and pass return this error message if the
  subsequent attempts to set the variable are being ignored.
\item ERR\_PRESET\_ELEMENT\_USE\_LATER - An element of the input deck has
  already been set and is being set again. Usually this is an indication of a
  malformed input deck file, so \inlinecode{HandleCustomBlock} should try to
  identify situations where this happens and pass return this error message if
  the subsequent attempts to set the variable are still successful.
\item {\bf ERR\_BAD\_VALUE} - An value which is being evaluated for the right
  hand side of an element assignment is in some way invalid. Internally to the
  code this usually means that an string which must be interpreted as an maths
  expression or a numerical constant is in some way malformed. It is also
  acceptable to return this error code when a value has been passed which is
  invalid for some other reason (the value is outside an acceptable range etc.)
\item {\bf ERR\_MISSING\_ELEMENTS} - This is an error code returned when the
  code is testing to make sure that all necessary elements of an input deck
  file have been specified. It should be returned when some required parameter
  is missing in the subroutine \inlinecode{CheckCustomBlocks}
\item ERR\_TERMINATE - This error code means that the code is in a state where
  execution is impossible and the code must terminate once the input deck has
  been read. Some other error codes automatically set ERR\_TERMINATE, but it
  can always be IOR'ed with any error code to force the code to exit. Note that
  just returning ERR\_TERMINATE will just cause the code to silently quit.
\item {\bf ERR\_REQUIRED\_ELEMENT\_NOT\_SET} - This means that the code cannot
  parse an input deck element since another element which must be known
  beforehand has not been set. This is intended for things like setting the
  species information where the number of species must be known in
  advance. This error code uses the extended error string to give user friendly
  feedback, if you return this error code then you should set
  Extended\_Error\_String to be equal to the name of the required element which
  has not been set. If multiple previous elements are required then the code
  should be set up so that it checks for the presence of the required elements
  in order and reports on missing elements so that the end user can fix them
  one by one.
\item ERR\_PP\_OPTIONS\_WRONG - If you've written a part of the code so that
  the part is controlled by preprocessor options then you should return this
  error message if someone attempts to set input deck elements which refer to
  that part when the correct preprocessor options are not used. This means that
  the user is aware of the fact that the requested feature will not be
  active. This error code also uses the extended error string to give user
  friendly feedback. If you return this error code, you should set the string
  Extended\_Error\_String to the define command ("-DPER\_PARTICLE\_WEIGHT")
  that would turn on the requested feature of the code.
\item {\bf ERR\_OTHER} - This error code is a catch all error which causes the
  code to quit with a sarcastic error message. It's mainly intended for
  debugging and is used before the final error code is implemented.
\end{itemize}

Those error codes with names in {\bf BOLD} are those which will cause the code
to terminate.

\end{document}
