\documentclass[12pt,a4paper]{article}
\newcommand{\version}{3.0}

\usepackage{pdfpages}
\usepackage{url,graphicx,tabularx,array,titleref,booktabs}
\usepackage[hmargin=.47in,vmargin=0.6in,nohead]{geometry}
\usepackage{color,verbatim,framed}
\usepackage{moreverb}
\usepackage{xr}
%\usepackage{upgreek}
\usepackage{fancyvrb}
%\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{appendix}
\usepackage{color}
\usepackage{tabularx}
\usepackage{graphicx}
%\usepackage{fullpage}
\usepackage{enumerate}
\usepackage{bold-extra}
%\usepackage{fix-cm}
\definecolor{txt}{rgb}{0,0,1}
\definecolor{cmd}{rgb}{0,1,0}
\newcommand{\txt}[1]{{\color{txt}{\tt #1}}}
\newcommand{\cmd}[1]{{\color{cmd}{\tt #1}}}
\definecolor{warwickdark}{cmyk}{1.0,0.6,0.0,0.06}
\definecolor{warwickmid}{cmyk}{0.69,0.34,0.0,0.0}
\definecolor{warwicklight}{cmyk}{1.0,0.0,0.0,0.0}
\definecolor{warwickred}{cmyk}{0.0,1.0,0.65,0.15}
\newcommand{\HRule}{\rule[0.3cm]{\linewidth}{0.5mm}}
\newcommand{\emphtext}{\color{warwickdark} \fontfamily{phv}\selectfont\large\bf}
\newcommand{\inlinecode}[1]{{\color{warwickred} \bf\texttt{#1}}}
\newcommand{\sectit}[1]{See the section titled ``{\bf\titleref{sec:#1}}''.}
\newcommand{\sect}[1]{Section~\ref{sec:#1}}
\newcommand{\code}[1]{{\texttt{#1}}}
%\newcommand{\qtt}[1]{``{\code{#1}}''}
\newcommand{\inlineemph}[1]{{\color{warwicklight} \bf{#1}}}
\newcommand{\inlineemtt}{\color{warwicklight} \fontfamily{phv}\selectfont\ttfamily\bfseries}
\newcommand{\cemph}[1]{{\inlineemph{#1}}}
\newcommand{\EPOCH}{{\color{warwickdark}\fontfamily{phv}\selectfont{EPOCH}}}
% Caption before Label to fix strange problem with not putting in subsection
% numbers. DO NOT CHANGE.
\newcommand{\captionedimage}[3]
  {{\begin{figure}[hbt!]\centering\includegraphics{#1}\caption{#3}\label{#2}
    \end{figure}}}
\newcommand{\scaledcapimage}[4]
  {{\begin{figure}[hbt!]\centering\includegraphics[scale=#4]{#1}\caption{#3}
    \label{#2} \end{figure}}}

\newcommand{\tony}[1]{{\color{warwickred} \bf{TONY'S COMMENT:} \bf{#1}}\\}

\definecolor{shadecolor}{cmyk}{0.1,0.05,0.0,0.0}
\setlength{\FrameRule}{0.6mm}

\newenvironment{lboxverbatim}[1]{
\setlength{\FrameSep}{0pt}
%\topsep=0ex\relax
\def\FrameCommand{\fboxsep=0pt \colorbox{shadecolor}}
\MakeFramed{\FrameRestore}
\vspace{-13.5pt}
\fvset{label=#1}
\boxverb
}{
\endboxverb
\vspace{-13.5pt}
\endMakeFramed
}
\newenvironment{boxverbatim}{\lboxverbatim{none}}{\endlboxverbatim}

\newenvironment{nbboxverbatim}[1]{
\noindent\minipage{\textwidth}
\setlength{\FrameSep}{0pt}
%\topsep=0ex\relax
\def\FrameCommand{\fboxsep=0pt \colorbox{shadecolor}}
\MakeFramed{\FrameRestore}
\fvset{label=#1}
\boxverb
}{
\endboxverb
\vspace{-13.5pt}
\endMakeFramed
\endminipage
\vspace{5pt}
}

\DefineVerbatimEnvironment{boxverb}{Verbatim}
  {frame=single,framerule=0.5mm,rulecolor=\color{warwickmid},
   formatcom=\color{black}}

\DefineVerbatimEnvironment{codedef}{Verbatim}
  {formatcom=\color{warwickred},fontsize=\Large,commandchars=\\\{\}}
%\newcommand{\txt}[1]{{\color{blue}{\tt #1}}}
%\newcommand{\cmd}[1]{{\color{green}{\tt #1}}}
\newcommand{\qtt}[1]{``{\tt #1}"}
\newcommand{\qm}[1]{{\em ``#1"}}

\begin{document}%
\includepdf{images/title_page_user}
{
  \fontfamily{phv}\selectfont\input{epoch_user_title}
}
\fontfamily{garamond}\selectfont%
\tableofcontents%
\newpage%
\DefineShortVerb{\#}
\fvset{formatcom=\color{warwickred}}

\section{FAQs}

\subsection{What is {\EPOCH}?}

{\EPOCH} is a plasma physics simulation code which uses the Particle in Cell
(PIC) method. In this method, collections of physical particles are represented
using a smaller number of pseudoparticles, and the fields generated by the
motion of these pseudoparticles are calculated using a finite difference time
domain technique on an underlying grid of fixed spatial resolution. The forces
on the pseudoparticles due to the calculated fields are then used to update the
pseudoparticle velocities, and these velocities are then used to update the
pseudoparticle positions. This leads to a scheme which can reproduce the full
range of classical micro-scale behaviour of a collection of charged
particles.\\

\subsubsection{Features of {\EPOCH}}
\begin{itemize}
  \item MPI parallelised explicit 2nd order relativistic PIC code.
  \item Dynamic MPI load balancing option.
  \item MPI-IO based output, allowing restart on arbitrary number of processors.
  \item Data analysis and visualisation options include ITT IDL, LLNL VisIt
    and Mathworks MatLab.
  \item Control of setup and runs of {\EPOCH} through a customisable input deck.
\end{itemize}

\subsection{The origins of the code}
The {\EPOCH} family of PIC codes is based on the older code PSC by Hartmut Ruhl,
and retains almost the same core algorithm for the field updates and particle
advance routines. {\EPOCH} was written to add more modern features, and to
structure the code in such a way that future expansion of the code is made as
easy as possible.

\subsection{What normalisations are used in {\EPOCH}?}
Since the idea from the start was that {\EPOCH} would be used by a large number
of different users, and that it should be as easy as possible to ``plug in''
different modules from different people into a given copy of the code, it was
decided to write {\EPOCH} in SI units. There are a few places in the code where
some quantities are given in other units for convenience (for example charges
are specified in multiples of the electron charge), but the entire of the core
code is written in SI units.

\subsection{What are those \code{\_num} things doing everywhere?}
Historically using the compiler auto-promotion of \code{REAL} to
\code{DOUBLE PRECISION} was unreliable, so {\EPOCH} uses kind tags to specify
the precision of the code. The \code{\_num} suffixes and the associated
definition of \code{REAL}s as \code{REAL(num)} are these kind tags in
operation. The \code{\_num} tags force numerical constants to match the
precision of the code preventing errors due to precision conversion. The
important thing is that all numerical constants should be tagged with an
\code{\_num} tag, and all \code{REAL}s should be defined as \code{REAL(num)}.

\subsection{What is an input deck?}
An input deck is text file which can be used to set simulation parameters
for {\EPOCH} without needing to edit or recompile the source code.
It consists of a list of blocks which start as \inlineemph{begin:blockname}
and end with \inlineemph{end:blockname}. Within the body of each block is
a list of key/value pairs, one per line, with key and value separated by
an equals sign. Most aspects of a simulation can be controlled using an
input deck, such as the number of grid points in the simulation domain,
the initial distribution of particles and initial electromagnetic field
configuration. It is designed to be relatively easy to read and edit. For
most simulations it should be possible to set up a simulation without
editing the source code at all.

\subsection{I just want to use the code as a black box, or I'm just
  starting. How do I do that?}
\sectit{gettingstarted} There's quite a lot to learn to get started so you
should plan to read through all of this section. Then look at the code and have
a play with some test problems. After that re-read this section. This should be
enough for testing simple problems.

\subsection{I've been through the getting started guides but want more detail
  on using the code. How do I do that?}
\sectit{endusers}. Once again expect to have to read this all the way through.
Do some example problems with the code and then re-read the section.

\subsection{What is the autoloader?}
Throughout this document we will often refer to the ``autoloader'' when
setting up the initial particle distribution. In the input deck it is
possible to specify a functional form for the density and temperature 
of a particle species. {\EPOCH} will then place the particles to match
the density function and set the velocities of the particles so that they
match the Maxwellian thermal distribution for the temperature.
The code which performs this particle set up is called the ``autoloader''.

At present, there is no way to specify a non-Maxwellian particle distribution
from within the input deck. In such cases, it is necessary to edit and
recompile the {\EPOCH} source code. The recommended method for setting
the initial particle properties is to use the ``\code{manual\_load}'' function
as described in \sect{manualload}.

\subsection{What is a maths parser?}
As previously mentioned, the behaviour of {\EPOCH} is controlled using an
input deck which contains a list of key/value pairs. The value part of the
pair is not restricted to simple constants but can be a complex mathematical
expression. It is evaluated at run time using a section of code called the
"maths parser". There is no need for the end user to know anything about this
code. It is just there to enable the use of mathematical expressions in the
input deck.
Further information about this facility can be found in
\sect{maths_parser}.

\subsection{I am an advanced user, but I want to set up the code so that less
  experienced users can use it. How do I do that?}
\sectit{customising}

\subsection{I want to develop an addition to {\EPOCH}. How do I do that?}
Basically read the entire of this manual. The second part of the manual details
the internals of the code but it expects you to already be familiar with all
the material in the first part of the manual.

\subsection{I want to have a full understanding of how {\EPOCH} works. How do I
  do that?}
If you really want to understand {\EPOCH}
in full, the only way is to read all of
this manual and then read through the code. Most of it is commented.
\pagebreak

\section{Getting Started Guides}
\label{sec:gettingstarted}

\subsection{History of these guides}
These guides are based on material which was used as handouts at an {\EPOCH}
introductory workshop held in February 2010 at the University of Warwick. The
purpose of these guides is to quickly get a new user to the point of being able
to use {\EPOCH} without getting bogged down in the details of how the code
works. Some of the material covered in these getting started guides will also
appear in the body of the manual starting from \sect{endusers}.

\subsection{Running {\EPOCH} and basic control of EPOCH1D}
When the code is run, the output is
\begin{lboxverbatim}{Command line output}

     @@@@@@@@  @@@@@@      @@@@    @@@@@@@@  @@    @@    @@@@@@    @@@@@@       
     @@@@@@@@  @@@@@@      @@@@    @@@@@@@@  @@    @@    @@@@@@    @@@@@@       
     @@        @@    @@  @@    @@  @@        @@    @@      @@@@    @@  @@       
     @@        @@    @@  @@    @@  @@        @@    @@      @@@@    @@  @@       
     @@        @@    @@  @@    @@  @@        @@    @@      @@@@    @@    @@     
     @@        @@    @@  @@    @@  @@        @@    @@      @@@@    @@    @@     
     @@@@@@@@  @@@@@@    @@    @@  @@        @@@@@@@@      @@@@    @@    @@     
     @@@@@@@@  @@@@@@    @@    @@  @@        @@@@@@@@      @@@@    @@    @@     
     @@        @@        @@    @@  @@        @@    @@      @@@@    @@    @@     
     @@        @@        @@    @@  @@        @@    @@      @@@@    @@    @@     
     @@        @@        @@    @@  @@        @@    @@      @@@@    @@  @@       
     @@        @@        @@    @@  @@        @@    @@      @@@@    @@  @@       
     @@@@@@@@  @@          @@@@    @@@@@@@@  @@    @@    @@@@@@@@  @@@@@@       
     @@@@@@@@  @@          @@@@    @@@@@@@@  @@    @@    @@@@@@@@  @@@@@@       
                                                                                
                                                                                
                                                                                
                                                                                
 
 Welcome to EPOCH1D Version 3.0             
 
 The code was compiled with the following compile time options
 *************************************************************
 Per particle weighting -DPER_PARTICLE_WEIGHT
 Tracer particle support -DTRACER_PARTICLES
 Particle probe support -DPARTICLE_PROBES
 *************************************************************
 
 Code is running on 1 processing elements
 
 
 Specify output directory
\end{lboxverbatim}

At which point the end user should simply type in the name of the directory
where the code output is to be placed. This directory must also include the
file \qtt{input.deck} which controls the code setup, specifies how to set the
initial conditions and controls the I/O. Writing an input deck for {\EPOCH} is
fairly time consuming and so the code is supplied with an example input deck
which includes all the necessary sections for the code to run. This section of
the manual describes how to set up the basic code and a few simple problems in
EPOCH1D.

\subsection{\code{input.deck}}
Most of the control of {\EPOCH} is through a text file called \code{input.deck}.
The input deck file must be in the output directory and contains all the basic
information which is needed to set up the code, including the size and
subdivision of the domain, the boundary conditions, the species of particles to
simulate and the output settings for the code. For most users this will be
capable of specifying all the initial conditions and output options they need.
More complicated initial conditions will be handled in the next section.

The input deck is split into blocks of related variables. The blocks can appear
in any order. Blocks can also use variables defined in other blocks. Thus in
the examples below you must understand the roles of all blocks to understand
the full \code{input.deck}.

\subsubsection{\cemph{control} block}
The \cemph{control} block sets up the basic code properties for the
domain, the end time of the code, the load balancer and the types of initial
conditions to use.

\begin{lboxverbatim}{control block}
begin:control
   nx = 2000 # in x
   npart = 200*200*40

   nsteps = -1

   t_end = 0.3e-12

   x_min = -5e-6
   x_max = 5e-6

   # dt_multiplier = 0.95
   dlb_threshold = 1.0

   # restart_snapshot = 98

   # field_order = 2
   # stdout_frequency = 10
end:control
\end{lboxverbatim}

As illustrated in the above code block, the ``{\texttt{\#}}'' symbol is treated
as a comment character and the code ignores everything on a line following this
character.\\

{\emphtext nx} - Number of grid points in the x direction. This parameter
is mandatory. There must be sufficient gridpoints so that
(x\_max-x\_min)/nx $< \lambda_d$, where $\lambda_d$ is the Debye length.\\

{\emphtext npart} - The global number of pseudoparticles in the
simulation. This parameter does not need to be given if a specific number
of particles is supplied for each particle species. Specifying both will just
use the number of particles supplied for each species.\\

{\emphtext nsteps} - The number of iterations of the core solver before the
code terminates. Negative numbers instruct the code to only terminate at
\inlineemph{t\_end}. If \inlineemph{nsteps} is not specified then
\inlineemph{t\_end} must be given.\\

{\emphtext t\_end} - The final simulation time in simulation seconds before the
code terminates. If \inlineemph{t\_end} is not specified the
\inlineemph{nsteps} must be given. If they are both specified then
the first time restriction to be satisfied takes precedence.\\

{\emphtext x\_min} - The position of the left hand edge of the domain in
metres. Can be negative. ``x\_start'' is accepted as a synonym. This parameter
is mandatory.\\

{\emphtext x\_max} - The position of the right hand edge of the domain in
metres. Must be greater than \inlineemph{x\_min}.
``x\_end'' is accepted as a synonym. This parameter is mandatory.\\

{\emphtext dt\_multiplier} - Factor by which the timestep is multiplied before
it is applied in the code, i.e. a multiplying factor applied to the CFL
condition on the timestep. Must be less than one. If no value is given then
the default of 0.95 is used.\\

{\emphtext dlb\_threshold} - The minimum ratio of the
load on the least loaded processor to that on the most loaded processor allowed
before the code load balances. Set to 1 means
always balance, set to 0 means never balance. If this parameter is not
specified then the code will only be load balanced at initialisation time.\\

{\emphtext restart\_snapshot} - The number of a previously written restart
dump from which to restart the code. If not restarting from a previous run
this variable does not need to be set.\\

{\emphtext field\_order} - Order of the finite difference scheme used for
solving Maxwell's equations. Can be 2, 4 or 6. If not specified, the default
is to use a second order scheme.\\

{\emphtext stdout\_frequency} - If specified then the code will print a one
line status message to stdout after every given number or timesteps. The
default (\code{stdout\_frequency = 0}) is to print nothing to screen.

\subsubsection{\inlineemph{boundaries} block}
The {\emphtext boundaries} block sets the boundary conditions of each boundary
of the domain. Some types of boundaries allow EM wave sources (lasers) to be
attached to a boundary. Lasers are attached at the initial conditions
stage.

\begin{lboxverbatim}{boundaries block}
begin:boundaries
   bc_x_min = simple_laser
   bc_x_max_field = simple_outflow
   bc_x_max_particle = simple_outflow
end:boundaries
\end{lboxverbatim}

{\emphtext bc\_x\_min} - The condition for the left boundary for both fields
and particles. ``xbc\_left'' is accepted as a synonym.\\

{\emphtext bc\_x\_min\_\{field,particle\}} - The condition for the left
boundary for \{fields,particles\}.\linebreak ``xbc\_left\_\{field,particle\}''
is accepted as a synonym.\\

{\emphtext bc\_x\_max} - The condition for the right boundary for both fields
and particles. ``xbc\_right'' is accepted as a synonym.\\

{\emphtext bc\_x\_max\_\{field,particle\}} - The condition for the right
boundary for \{fields,particles\}.\linebreak ``xbc\_right\_\{field,particle\}''
is accepted as a synonym.\\

There are six boundary types in {\EPOCH} and each boundary of the domain can
have one and only one of these boundaries attached to it. These boundary types
are:\\

{\emphtext periodic} - A simple periodic boundary condition. Fields and/or
particles reaching one edge of the domain are wrapped round to the opposite
boundary.\\

{\emphtext other} - A generic boundary condition which in the default {\EPOCH}
version is perfectly reflecting for both particles and EM waves.\\

{\emphtext simple\_laser} - A characteristic based boundary condition to which
one or more EM wave sources can be attached. Since the wave sources require the
domain to be completely set up before they can be calculated the wave sources
are attached when the initial conditions are set.  EM waves impinging on a
\inlineemph{simple\_laser} boundary are transmitted with as little reflection
as possible. Particles are fully transmitted. The field boundary condition
works by allowing outflowing characteristics to propagate through the boundary
while using the attached lasers to specify the inflowing characteristics. The
particles are simply removed from the simulation when they reach the
boundary.\\

{\emphtext simple\_outflow} - A simplified version of \inlineemph{simple\_laser}
which has the same properties of transmitting incident waves and
particles, but which cannot have EM wave sources attached to it. These
boundaries are about 5\% more computationally efficient than
\inlineemph{simple\_laser boundaries} with no attached sources. This boundary
condition again allows outflowing characteristics to flow unchanged, but this
time the inflowing characteristics are set to zero. The particles are again
simply removed from the simulation when they reach the boundary.\\

{\emphtext reflect} - A perfectly reflecting boundary condition.\\

{\emphtext open} - When applied to fields, EM waves outflowing characteristics
propagate through the boundary. Particles are transmitted through the boundary
and removed from the system.\\

{\emphtext NOTE: If simple\_laser, simple\_outflow or open are specified on
one or more boundaries then the code will no longer necessarily conserve mass.}

Note also that it is possible for the user to specify contradictory,
unphysical boundary conditions. It is the users responsibility that these
flags are set correctly.

\subsubsection{\inlineemph{species} block}

\begin{lboxverbatim}{species block}
begin:species
   # electrons
   name = Electron
   charge = -1.0
   mass = 1.0
   frac = 0.5
   # npart = 2000*100
   dump = T
   # tracer = F
   number_density = 1.e4
   temp = 1e6

   temp_x = 0.0
   temp_y = temp_x(Electron)
   number_density_min = 0.1 * den_max
   number_density = if(abs(x) lt thick,den_max,0.0)
   number_density = if((x gt -thick) and (abs(y) gt 2e-6),0.0,number_density(Carbon))
end:species

begin:species
   # carbon4+
   name = Carbon
   charge = 4.0
   mass = 1836.0*12
   frac = 0.5
   # npart = 2000*100
   dump = T

   number_density = 0.25*number_density(Electron)
   temp_x = temp_x(Electron)
   temp_y = temp_x(Electron)
end:species
\end{lboxverbatim}

{\emphtext name} - This specifies the name of the particle species defined
in the current block. This name can include any alphanumeric characters in
the basic ASCII set. The name is used to identify the species in any
consequent input block. It is a mandatory parameter.\\

{\emphtext NOTE: IT IS IMPOSSIBLE TO SET TWO SPECIES WITH THE SAME NAME!} \\

{\emphtext charge} - This sets the charge of the species in
multiples of the electron charge. Negative numbers are used for negatively
charged particles. This is a mandatory parameter.\\

{\emphtext mass} - This sets the mass of the species in multiples
of the electron mass. Negative numbers are not trapped and effectively swap the
charge of the species. This is not recommended since it breaks the
mass\_density diagnostic. This is a mandatory parameter.\\

{\emphtext npart} - This specifies the number of pseudoparticles
which should be loaded into the simulation domain for the species. This is the
most convenient way of loading particles for simulations containing multiple
species with different number densities. If these are specified then
\inlineemph{npart} (the global number of particles specified in the control
block) is ignored for this species. It should not be specified at the same time
as frac for a given species.\\

{\emphtext frac} - This specifies what fraction of npart (the
global number of particles specified in the control block) should be assigned
to the species.\\

{\emphtext NOTE: frac should not be specified at the same time as npart for a
given species.}\\

{\emphtext dump} - Logical flag detailing whether or not to dump
information about the species. If set to ``F'', then the species information
is not dumped when writing ANY species specific diagnostics, although it is
included in global diagnostics (i.e in the example if ``dump = F'' were
specified then there would be no ``Mass\_Density\_Electron'', but the mass of
the electron would be considered when calculating ``mass\_density'') and
restart dumps. ``dump = F'' is the default value.\\

{\emphtext tracer} - Logical flag switching the particle species
into tracer particles. Tracer particles are enabled with the correct
precompiler option, and when set for a given species make that species move
correctly for its charge and mass, but contribute no current. This means that
these particles are passive tracers in the plasma. ``tracer = F'' is the
default value.\\

The species blocks are also used for specifying initial conditions for
the particle species. The initial conditions in {\EPOCH} can be specified in
various ways, but the easiest way is to specify the initial conditions in the
input deck file. This allows any initial condition which can be specified
everywhere in space by a number density and a drifting Maxwellian distribution
function.
These are built up using the normal maths
expressions, by setting the density and temperature for each species which is
then used by the autoloader to actually position the particles. \\
The elements of the species block used for setting
initial conditions are:\\

{\emphtext number\_density} - Particle number density in $m^{-3}$.
As soon as a number\_density= line has been read, the values are
calculated for the whole domain and are available for reuse on the right hand
side of an expression. This is seen in the above example in the first two lines
for the carbon species, where the density is first set and then corrected.\\
This parameter is mandatory.\\

{\emphtext number\_density\_min} - Minimum particle number density in $m^{-3}$.
When the number density in a cell falls below number\_density\_min the
autoloader does not load any pseudoparticles into that cell to minimise the
number of low weight, unimportant particles. If set to 0 then all cells are
loaded with particles. This is the default.\\

{\emphtext number\_density\_max} - Maximum particle number density in $m^{-3}$.
When the number density in a cell rises above number\_density\_max the
autoloader clips the density to number\_density\_max allowing easy
implementation of exponential rises to plateaus. If it is a negative value
then no clipping is performed. This is the default.\\

{\emphtext temp\_\{x,y,z\}} - The temperature in each direction for a thermal
distribution in K. To specify a temperature in ev, simply use the deck
parser. So for example temp\_x = 4*kev/kb gives a 4kev temperature.\\

{\emphtext temp} - Sets an isotropic temperature distribution in K. Does not
give thermal distribution in ignorable directions. If both temp and a specific
temp\_x, temp\_y, temp\_z parameter is specified then the last to appear in the
deck has precedence. If neither are given then the species will have a default
temperature of zero Kelvin.\\

{\emphtext temp\_\{x,y,z\}\_ev, temp\_ev} - These are the same as the
temperature parameters described above except the units are given in
electronvolts rather than Kelvin.\\

{\emphtext drift\_\{x,y,z\}} - Specifies a momentum space offset in
$kg\ ms^{-1}$ to the distribution function for this species. By default,
the drift is zero.\\

It is also possible to set initial conditions for a particle species
using an external file.  Instead of specifying the
initial conditions mathematically in the input deck, you specify in quotation
marks the filename of a simple binary file containing the information required.

\begin{lboxverbatim}{external initial conditions}
begin:species
   name = Electron
   number_density = 'Data/ic.dat'
   offset = 80000
   temp_x = 'Data/ic.dat'
end:species
\end{lboxverbatim}


An additional element is also introduced, the offset element. This
is the offset in bytes from the start of the file to where the data should
be read from. As a given line in the block executes, the file is opened, the
file handle is moved to the point specified by the offset parameter, the data
is read and the file is then closed. Therefore, unless the offset value is
changed between data reading lines the same data will be read into all the
variables. The data is read in as soon as a line is executed, and so it is
perfectly possible to load data from a file and then modify the data using
a mathematical expression.\\

The file should be a simple binary file consisting of floating point numbers of
the same precision as \inlinecode{\_num} in the core {\EPOCH} code.\\

{\emphtext NOTE: The files that are expected by this block are SIMPLE BINARY
files, NOT Fortran unformatted files. It is possible to read Fortran
unformatted files using the offset element, but care must be taken!}\\


\subsubsection{\inlineemph{output} block}
\label{sec:output block}
Output in {\EPOCH} is handled using the custom designed SDF file format
(\inlineemph{Self Describing Format}) which is documented in \sect{sdf}
of the developers manual.
It comes with readers for ITT IDL and LLNL VisIt, and Mathworks MatLab.
The IDL reader is also compatible with the open source GDL tool.
What the code should output and when it should output it is
specified in the ``output'' block of the input deck. \\

There are three types of output dump in {\EPOCH} which are used for different
purposes. These types are:\\

{\emphtext normal} - The most frequent type of output dump in {\EPOCH} is a
normal dump.\\

{\emphtext full} - A full dump is usually written every 10 or so normal
dumps. A full dump contains all the data that a normal dump contains and should
also contain any information which is needed only infrequently, whether this is
the full particle information or a large distribution function. It is possible
to turn off full dumps completely.\\

{\emphtext restart} - A restart dump is a dump where the code guarantees to
write enough data to allow the code to restart from the output. Output dumps
are guaranteed to contain all the information in a normal dump and, if they
coincide with the timing for a full dump, will also contain the full dump
information.\\

Information will never be written into a file twice, even if two conditions for
it being written are satisfied (i.e even if px should be dumped both because it
is a full dump and a restart dump, px will only be written once).\\

When specifying which type of output dump to write a variable to there are four
options which are specified for each variable and can be combined by
addition. Some combinations make no sense but are formally
valid. These are:\\

{\emphtext never} - If the variable is not a required restart variable then it
will never be written. If it is a required restart variable then it will be
written only at restart dumps.\\

{\emphtext always} - This variable will be written at full, normal and restart
dumps.\\

{\emphtext full} - This variable will be written at full dumps only.\\

{\emphtext restart} - This variable will be written at restart dumps only.\\

There is also a fifth parameter which can be specified for some variables.\\

{\emphtext species} - The output for this variable should be broken down on a
species by species basis. This only applies to certain kinds of derived field
variable, such as mass\_density. It is combined with a restart frequency code
by addition as in: \inlinecode{px = always + species}.\\

When applied to a variable, these codes are referred to as a
\inlineemph{dumpmask}.

\begin{lboxverbatim}{output block}
begin:output
   # If use_offset_grid is true then the code dumps a grid which
   # displays positions relative to the left hand edge of the window
   use_offset_grid = F
   # number of timesteps between output dumps
   dt_snapshot = 1.0e-14
   # Number of dt_snapshot between full dumps
   full_dump_every = 10
   restart_dump_every = -1
   force_final_to_be_restartable = T

   # Properties at particle positions
   particles = never
   px = never
   py = never
   pz = never
   vx = never
   vy = never
   vz = never
   charge = never
   mass = never
   particle_weight = never
   species_id = never

   # Properties on grid
   grid = always
   ex = always
   ey = always
   ez = always
   bx = always
   by = always
   bz = always
   jx = always
   jy = always
   jz = never
   ekbar = always + species
   mass_density = never + species
   charge_density = always
   number_density = always + species
   temperature = always + species

   distribution_functions = always
   particle_probes = never
end:output
\end{lboxverbatim}

{\emphtext use\_offset\_grid} - When using moving windows some visualisation
programs (notably VisIt) show the motion of the window by moving the
visualisation window rather than by changing the x-axis. Setting this option to
``T'' causes the code to write another grid which always gives the offset
relative to the left hand edge of the window rather than the true origin.
Performs no function when not using the moving window. The default value
is ``F''.\\

{\emphtext dt\_snapshot} - Sets the interval between normal output dumps in
simulation seconds. Setting zero or negative means that the code will output
every step of the core solver. The code does NOT guarantee that outputs will be
exactly \inlineemph{dt\_snapshot} apart, what is guaranteed is that the next
output will be after the first iteration which takes the simulation to a time
$\ge$ \inlineemph{dt\_snapshot} from the last output. The default value is
larger than the length of the simulation that will never trigger an output.\\

{\emphtext nstep\_snapshot} - Sets the number of timesteps between normal
output dumps. Setting zero or negative means that the code will output
every step of the core solver. If \inlineemph{dt\_snapshot} is also specified
then both conditions are considered. The default value is a huge integer
which will never trigger an output.\\

{\emphtext full\_dump\_every} - The number of normal output dumps between full
output dumps. Setting to zero makes every dump a full dump. Setting to a
negative number stops the code from producing any full dumps. This is the
default.\\

{\emphtext restart\_dump\_every} - The number of normal output dumps between
restart dumps. Setting to zero makes every dump a restart dump. Setting to a
negative number stops the code from producing any restart dumps. This is the
default.\\

{\emphtext force\_final\_to\_be\_restartable} - Force the code to override
other output settings and make the last output dump it writes be a restart
dump. Any internal condition which causes the code to terminate will make the
code write a restart dump, but code crashes or scheduler terminations will not
cause the code to write a restart dump. The default value is ``T''.\\

{\emphtext dump\_source\_code} - {\EPOCH} has the ability to write its own
source code into restart dumps. This is generated at compile time and embedded
into the binary and so is guaranteed to match that corresponding to the running
code. {\EPOCH} comes with a script called
\inlineemph{unpack\_source\_from\_restart} which can be used to unpack the
source code from a restart dump. If this logical flag is set to false then 
the feature will be disabled. The default value is ``T''.\\

{\emphtext dump\_input\_decks} - If this logical flag is set to true then
a copy of the input decks for the currently running simulation is written
into the restart dumps. The default value is ``T''.\\

{\emphtext particles} - The dumpmask for the particle positions. Restart
variable. No particle variables can be plotted in VisIt unless this is
dumped.\\

{\emphtext p\{x,y,z\}} - The dumpmasks for the particle momenta. Restart
variable.\\

{\emphtext v\{x,y,z\}} - The dumpmasks for the particle velocities.\\

{\emphtext charge} - The dumpmask for the charge of a given particle. This
has no effect if the code is not compiled with the option for per particle
charge. See details on the \code{Makefile} later.\\

{\emphtext mass} - The dumpmask for the mass of a given particles. This
has no effect if the code is not compiled with the option for per
particle mass.\\

{\emphtext particle\_weight} - The dumpmask for the weighting function which
describes how many real particles each pseudoparticle represents. Restart
variable.\\

{\emphtext species\_id} - The dump mask for the number representing which
particle species a given particle is. This is the same as the number assigned
to that particle species in the species block. Restart variable.\\

{\emphtext grid} - The dumpmask for the Cartesian grid which defines the
locations of the grid variables. No grid variables can be plotted in VisIt
unless this variable is output.\\

{\emphtext e\{x,y,z\}} - The electric field vectors pointing in all three
directions. Restart variables.\\

{\emphtext b\{x,y,z\}} - The magnetic field vectors pointing in all three
directions. Restart variables. In 1D bx is a trivial variable because of the
Solenoidal condition. It is included simply for symmetry with higher dimension
codes.\\

{\emphtext j\{x,y,z\}} - The currents pointing in all three directions. Restart
variables.\\

{\emphtext ekbar} - Mean kinetic energy on grid. Can have species dumpmask.\\

{\emphtext mass\_density} - Mass density on grid. Can have species dumpmask.\\

{\emphtext charge\_density} - Charge density on grid. Can have species
dumpmask.\\

{\emphtext number\_density} - Number density on grid. Can have species
dumpmask.\\

{\emphtext temperature} - Temperature on grid. Can have species dumpmask. The
exact way that temperature is calculated in the code is likely to vary in the
near future.\\

{\emphtext distribution\_functions} - Dumpmask for outputting distribution
functions specified in the input deck. Each individual distribution function
can have its own dumpmask, but this one takes precedence.\\

{\emphtext particle\_probes} - Dumpmask for outputting particle probes
specified in the input deck. Each individual particle probe
can have its own dumpmask, but this one takes precedence.\\

% fix: ejected_particles

\subsection{\inlineemph{constant} blocks}

The \inlineemph{constant} block type helps to make the input deck more flexible
and maintainable. It allows you to define constants and maths parser
expressions which can be used by name later in the deck.\\

Constants are simply maths parser expressions which are assigned to a name as
shown above. When the name is used on the right hand side of a deck expression
it is replaced by the expression it was assigned with. This expression may
be a simple numerical constant, a mathematical expression or a function.
Constants may contain spatially varying information without having to
pre-calculate them at every location in the domain.
To those familiar with old Fortran codes, constants are essentially just
statement functions.\\

If a constant name is reused in a constant block then the old constant is
deleted and replaced with the new one. This happens without warning.\\

\begin{lboxverbatim}{constant block}
begin:constant
   lambda = 1.0e-6 # 1 micron wavelength
   omega = 2.0*pi*c/lambda
   den_crit = critical(omega)
   scale = 3.5e-6 # microns
   den_max = 5.0*den_crit
   thick = 300e-9
   pplength = 6000e-9
   widscale = 5.0e-6

   t_wid = (10.0e-6)/c
   amax = 1.0
   wy = 1e-6
   y = 0.0

   slope = exp(-2.0*(y/wy)^2)
   blob = gauss(sqrt(x^2+y^2),0.0,1.0e-6)
end:constant
\end{lboxverbatim}

Using constants can be very helpful when dealing with long,
complicated expressions since they allow the expression to be broken down into
much simpler parts. They can also be used to get around the Fortran string
length limitation built into many compilers which prevents deck lines being
longer then 512 characters long. As a general rule, it is a good idea to break
down complicated expressions using constants or by other means, in order to
make the deck look more readable.\\

Constants are persistent for the entire runtime of the code,
allowing them to be used when specifying time profiles for lasers, and also
allowing developers to use maths parser expressions for other internal parts of
the code where needed.\\

In the above example, several pre-defined constants have been used
(\inlineemph{pi} and \inlineemph{c}) and also several functions
(\inlineemph{critical}, \inlineemph{exp}, \inlineemph{gauss} and
\inlineemph{sqrt}). These are described in \sect{constants} and
\sect{functions}.

\subsubsection{\inlineemph{laser} blocks}
\label{sec:lasers}
Laser blocks attach an EM wave source to a boundary which is set as
\inlineemph{simple\_laser}.

\begin{lboxverbatim}{laser block}
begin:laser
   boundary = x_min
   id = 1
   irradiance_w_cm2 = 1.0e15
   lambda = 1.06 * microns
   pol_angle = 0.0
   phase = 0.0
   t_profile = gauss(time,40.0e-15,40.0e-15)
   t_start = 0.0
   t_end = 80.0e-15
end:laser
\end{lboxverbatim}

As already mentioned in the discussion of laser boundaries in the boundaries
block, lasers are attached to compatible boundaries here in the initial
conditions deck. In 1D, laser blocks are slightly simpler than their 2D and 3D
equivalents, but most of the important features will be mentioned here. The
only significant difference is that there is also a spatial profile for
multidimensional lasers. This is covered in detail in
\sect{multilaser}.\\

{\emphtext boundary} - The boundary on which to attach the laser.
In 1D, the directions can be either x\_min or x\_max.  ``left'' and ``right''
are accepted as a synonyms for ``x\_min'' and ``x\_max''.\\

{\emphtext amp} - The amplitude of the $E$ field of the laser in $V/m$.\\

{\emphtext irradiance} - The irradiance (intensity) of the laser in $W/m^2$.
There is no need to specify both irradiance and amp and the last specified
in the block is the value used. It is mandatory to specify at least one.\\

{\emphtext irradiance\_w\_cm2} - This is identical to the 
\inlineemph{irradiance} parameter described above, except that the units
are specified in $W/cm^2$.\\

{\emphtext id} - An id code for the laser. Used if you specify the laser time
profile in the {\EPOCH} source rather than in the input deck. Does not have to
be unique, but all lasers with the same id will have the same time profile.
This parameter is optional and is not used under normal conditions.\\

{\emphtext omega} - Angular frequency (rad/s not Hz) for the laser.\\

{\emphtext lambda} - Wavelength in a vacuum for the laser specified in $m$.
If you want to specify in $\mu m$ then you can multiply by the constant
``microns''. One of \inlineemph{lambda} or \inlineemph{omega} is a
required parameter.\\

{\emphtext pol\_angle} - Polarisation angle for the laser in radians.
This parameter is optional and has a value of zero by default.
The angle is measured with respect to the right-hand triad of propagation
direction, electric and magnetic fields. Although the 1D code has no $y$
or $z$ spatial axis, the fields still have $y$ and $z$ components.
If the laser is on \inlineemph{x\_min} then the default $E$ field is in
the $y$-direction and the $B$ field is the $z$-direction. The polarisation
angle is measured clockwise about the $x$-axis with zero along the $E_y$
direction. If the laser is on \inlineemph{x\_max} then the angle is
anti-clockwise.\\

{\emphtext pol} - This is identical to \inlineemph{pol\_angle} with the angle
specified in degrees rather than radians. If both are specified then the
last one is used.\\

{\emphtext phase} - Phase shift for the laser in radians. 
There is zero phase shift applied by default.\\

{\emphtext profile} - This parameter is a little redundant in 1D and is
only included for consistency with 2D and 3D versions of the code.
The laser field is multiplied by this parameter to give its final amplitude
so the intention is to use a value between zero and one. By default it is a
unit constant and therefore has no affect on the laser amplitude.\\

{\emphtext t\_profile} - Used to specify the time profile for the laser
amplitude. Like \inlineemph{profile} the laser field is multiplied by
this parameter but it is a function of time rather than space. In a similar
manner, it is best to use a value between zero and one.
Setting values greater than one is possible but will cause the maximum laser
intensity to grow beyond \inlineemph{amp}. The default is to leave the
laser unchanged over time.\\

{\emphtext t\_start} - Start time for the laser in seconds. Can be set to the
string ``start'' to start at the beginning of the simulation. This is the
default value. When using this parameter, the laser start is hard. To get a
soft start use the \inlineemph{t\_profile} parameter to ramp the laser up to
full strength.\\

{\emphtext t\_end} - End time for the laser in seconds, can be set to the
string ``end'' to end at the end of the simulation. This is the default value.
When using this parameter, the laser end is clipped straight to zero at
t$>$\inlineemph{t\_end}. To get a soft end use the \inlineemph{t\_profile}
parameter to ramp the laser down to zero.\\

In theory, any laser time profile required is possible, but the core FDTD
solver for the EM fields in {\EPOCH} produces spurious results if sudden
changes in the field intensity occur. This is shown in Figures~\ref{badpulse}
and \ref{smoothpulse}. The pulse shown in Figure~\ref{badpulse} used a constant
\inlineemph{t\_profile} and used \inlineemph{t\_end} to stop the laser after
8fs. Since the stopping time was not an exact multiple of the period, the
result was to introduce spurious oscillations behind the pulse. If the laser
had a finite phase shift so that the amplitude did not start at zero, a
similar effect would be observed on the front of the pulse.

\captionedimage{./images/pulse2}{badpulse}{A laser pulse with a sharp
  cutoff shows numerical artifacts behind the pulse.}
\captionedimage{./images/pulse1}{smoothpulse}{A laser pulse with a smooth
  temporal profile shows no artifacts.}

Figure~\ref{smoothpulse} instead used a Gaussian window function with a
characteristic width of 8fs as well as using \inlineemph{t\_end} to introduce
a hard cutoff. It can clearly be seen that there are no spurious oscillations
and the wave packet propagates correctly, showing only some dispersive
features.

There is no hard and fast rule as to how rapid the rise or fall for a laser can
be, and the best advice is to simply test the problem and see whether any
problems occur. If they do then there are various solutions. Essentially, the
timestep must be reduced to the point where the sharp change in amplitude can
be accommodated. The best solution for this is to increase the spatial
resolution (with a comparable increase in the number of pseudoparticles), thus
causing the timestep to drop via the CFL condition.

This is computationally expensive, and so a cheaper option is simply to
decrease the input.deck option \inlineemph{dt\_multiplier}. This artificially
decreases the timestep below the timestep calculated from the internal
stability criteria and allows the resolution of sharp temporal gradients. This
is an inferior solution since the FDTD scheme has increased error as the
timestep is reduced from that for EM waves. The latest version of {\EPOCH}
includes a high order field solver to attempt to reduce this.

\subsubsection{\inlineemph{fields} block}
\begin{lboxverbatim}{fields block}
begin:fields
   ex = sin(pi*x/length_x)
   ey = cos(pi*x/length_x)
   ez = 0
   bx = 1.0
   by = -1.0
   bz = 0
end:fields
\end{lboxverbatim}

Note this example uses $\pi$ and length\_x. These will be explained later in
detail. The constant $\pi$, along with other constants is always available
within the input deck. The domain size length\_x, along with other useful
quantities, is calculated by the code (from x\_max and x\_min)
when it reads the input deck.

The final type of block in the {\EPOCH} input deck is the fields block. This
allows you to specify the electric and magnetic fields at any point in the
domain. Once again, this is a very simple block needing only limited
explanation. All field variables are accessible by name and can be read back
using the appropriate commands from the maths parser. \\

Any valid maths parser expression can be used to set up the fields, and no
check is made to ensure that the $\nabla.B = 0$ is satisfied. \\

\subsection{Moving to EPOCH2D and EPOCH3D}
EPOCH1D is the simplest version of {\EPOCH} and, although feature complete,
lacks many of the elements which are required for multidimensional operation.
These elements are mainly small modifications to the concepts already
introduced in EPOCH1D but are significant enough to need at least some
discussion.\\

The higher dimension versions of the code go by the uninspired names of EPOCH2D
and EPOCH3D. Most of the input decks are equivalent to those already covered in
EPOCH1D, with a few added elements for setting the number of grid points in the
additional dimensions, setting the start and end points for the axes in the new
dimensions, and setting boundary conditions on the new boundaries. These will
be covered in more detail over the next few pages.\\

The laser blocks become slightly more complicated by the addition of spatial
profiles for the laser front, and the addition of the ability to have spatially
dependent phase profiles across the laser front. This will be covered later in
this document.\\

The data loading routines are identical to those for EPOCH1D, although
obviously new routines are required to actually visualise 2D and 3D data. 2D
and 3D data is much larger than 1D, and a much larger number of particles are
required to adequately resolve the physics in multidimensional simulations. As
a consequence, the data files generated by higher dimensionality versions of
{\EPOCH} will be much larger, making the more advanced I/O routines available
in {\EPOCH} more useful. These will be covered in the following sections.\\

\subsubsection{Changes to the \inlineemph{control} block}

\begin{lboxverbatim}{Changed control block}
begin:control
   .
   .
   ny = 200
   nz = 200
   .
   y_min = -10e-6
   y_max = 10e-6
   z_min = -10e-6
   z_max = 10e-6
   .
   .
end:control
\end{lboxverbatim}

The modified control block in EPOCH2D and 3D is very similar to the control
block already introduced for EPOCH1D. All that is added are new elements
describing the number of gridpoints in y and z (\inlineemph{ny \& nz}), and
new start and end lines for the length of the domain in the new directions
(\inlineemph{y\_min $\rightarrow$ y\_max} \&
\inlineemph{z\_min $\rightarrow$ z\_max}). These operate in exactly the same
way as those already introduced with EPOCH1D.  However, care must be taken to
increase the number of particles, ensuring that the number of particles per
cell remains high enough to accurately resolve the distribution function.\\

Also note that the amount of memory required for multidimensional simulations
will generally be hundreds of times larger than that required for 1D
simulations.\\

\subsubsection{Changes to the \inlineemph{boundaries} block}

\begin{lboxverbatim}{Changed boundaries block}
begin:boundaries
   .
   .
   bc_y_min = periodic
   bc_y_max = periodic
   bc_z_min = simple_laser
   bc_z_max = simple_outflow
end:boundaries
\end{lboxverbatim}

The modified boundary block includes new boundary conditions for the additional
boundaries that are introduced in higher dimensions. These available boundaries
are exactly the same as in 1D, with the additional boundaries being:\\

\begin{tabular}{rcl}
{\inlineemtt bc\_y\_min} &-& bottom of domain. ``ybc\_down'' is also accepted.\\
{\inlineemtt bc\_y\_max} &-& top of domain. ``ybc\_up'' is also accepted.\\
{\inlineemtt bc\_z\_min} &-& back of domain. ``zbc\_back'' is also accepted.\\
{\inlineemtt bc\_z\_max} &-& front of domain. ``zbc\_front'' is also accepted.\\
\end{tabular} \\

These are equivalent to the existing 1D simulations except that the moving
window always moves parallel to the x-axis when activated.\\
This concludes all
the modifications to input.deck that are required to use {\EPOCH} in multiple
dimensions. There are some changes that are required to allow
multidimensional initial conditions, but a surprising number of initial
conditions are in fact 1D even when running in multi-dimensional versions of
{\EPOCH}. The next few pages cover the modifications to the initial conditions
file which are needed for true multidimensional initial conditions with
examples.

\subsubsection{Multidimensional initial conditions}

The basic modification to the {\EPOCH} initial conditions deck is the addition
of the new variables describing positions and length in the new directions. The
names of these variables are given in the full manual and will be used without
introduction here.

\scaledcapimage{./images/gaussic}{gaussblob}{A Gaussian density blob at the
  centre of the domain.}{0.4}

A very simple problem to set up using EPOCH2D is a Gaussian blob which is
shown in Figure~\ref{gaussblob}, in the form both of the ic.deck needed to
create it and the output from VisIt that is produced from running this deck.

\scaledcapimage{./images/invgaussic}{inversegaussblob}{A Gaussian density
  deficit at the centre of the domain.}{0.4}

In Figure~\ref{inversegaussblob}, a very small modification to this initial
conditions deck is shown which creates the a case with a Gaussian density
minimum at the centre. This makes it clear that multidimensional initial
conditions are only a little more complex than 1D initial conditions, but at
present these are not very interesting initial conditions.

The next example extends this to a more useful initial condition.\\

\begin{nbboxverbatim}{species block to set up Gaussian density blob}
begin:constant
   width = 2.5e-6 # 2.5 microns
   r = sqrt(x^2+y^2)
end:constant

begin:species
   name = Electron
   number_density = 1.0e19 * gauss(r,0.0,width)
end:species
\end{nbboxverbatim}
%
%\begin{minipage}{\textwidth}
\begin{nbboxverbatim}{species block to set up Gaussian density blob}
begin:constant
   width = 2.5e-6 # 2.5 microns
   r = sqrt(x^2+y^2)
end:constant

begin:species
   name = Electron
   number_density = 1.0e19 * (1.0-gauss(r,0.0,width))
end:species
\end{nbboxverbatim}
%\end{minipage}

\subsubsection{\inlineemph{laser} blocks in multiple dimensions.}
\label{sec:multilaser}

The laser blocks already introduced in EPOCH1D are still present in
2D and 3D, but some of the parameters now accept spatial information.\\

\scaledcapimage{./images/profile_flat}{flatlaser}{Constant laser profile}{0.4}

{\emphtext profile} - The spatial profile for the laser. This is
essentially an array defined along the edge (or surface) that the laser is
attached to. It is clear that the spatial profile is only meaningful
perpendicular to the laser's direction of travel and so it is just a single
constant in 1D. The laser profile is evaluated as an initial condition
and so cannot include any temporal information which must be
encoded in \inlineemph{t\_profile}.  The spatial profile is evaluated at the
boundary where the laser is attached and so only spatial information in the
plane of the boundary is significant. This is most clearly explained through a
couple of examples. In these examples the spatial profile of the laser is set
to vary between a flat uniform profile (\inlineemph{profile = 1}) and a
Gaussian profile in y (\inlineemph{profile = gauss(y,0,2.5e-6)}). The
difference between these profiles is obvious but the important point is that a
laser travelling parallel to the x-direction has a profile in the y
direction. Similarly a laser propagating in the y-direction has a profile in
the x direction. In 3D this is extended so that a laser propagating in a
specified direction has a profile in both orthogonal directions. So a laser
travelling parallel to the x axis in 3D would have a profile in y and z. Since
3D lasers are very similar to 2D lasers, they will not be considered here in
greater detail, but in 3D, it is possible to freely specify the laser profile
across the entire face where a laser is attached.\\

\scaledcapimage{./images/profile_gauss}{gausslaser}{Gaussian laser profile}{0.4}

{\emphtext phase} - Phase shift for the laser in radians. This is a spatial
variable which is also defined across the whole of the boundary on which the
laser is attached. This allows a user to add a laser travelling at an angle
to a boundary as shown in Figure~\ref{angle}.
\scaledcapimage{./images/wave}{wave}{Laser at an angle}{0.4}
The setup for this is not entirely straightforward and requires a little
bit of explanation. Figure~\ref{wave} illustrates a laser being driven at
an angle on the x\_min boundary. Different wave fronts cross the $y$-axis
at different places and this forms a sinusoidal profile along $y$ that
represents the phase. The wavelength of this profile is
given by $\lambda_\phi = \lambda / \sin\theta$, where $\lambda$ is the
wavelength of the laser and $\theta$ is the angle of the propagation
direction with respect to the $x$-axis. The actual phase to use will
be $\phi(y) = -k_\phi y = -2\pi y / \lambda_\phi$. It is negative because
the phase of the wave is propagating in the positive $y$ direction.
It is also necessary to alter the wavelength of the driver since this
is given in the direction perpendicular to the boundary. The new
wavelength to use will be $\lambda\cos\theta$. Figure~\ref{angle} shows
the resulting $E_y$ field for a laser driven at an angle of $\pi / 8$. Note
that since the boundary conditions in the code are derived for propagation
perpendicular to the boundary, there will be artifacts on the scale of the
grid for lasers driven at an angle.

Using this technique it is also possible to focus a laser. This is done by
using the same technique as above but making the angle of propagation,
$\theta$, a function of $y$ such that the laser is focused to a point along
the $x$-axis.\\

\scaledcapimage{./images/profile_angle}{angle}{Angled laser profile}{0.4}

% laser from corner?

{\emphtext pol\_angle} - Polarisation angle for the electric field of the
laser in radians. This parameter is optional and has a value of zero by default.
The angle is measured with respect to the right-hand triad of propagation
direction, electric and magnetic fields. If the laser is on
\inlineemph{x\_min} then the default $E$ field is in the $y$-direction and
the $B$ field is the $z$-direction. The polarisation angle is measured
clockwise about the $x$-axis with zero along the $y$-axis.\\
Similarly, for propagation directions:\\
\inlineemph{y\_min} - angle about $y$-axis, zero along $z$-axis\\
\inlineemph{z\_min} - angle about $z$-axis, zero along $x$-axis\\
\inlineemph{x\_max} - angle anti-clockwise about $x$-axis, zero along $y$-axis\\
\inlineemph{y\_max} - angle anti-clockwise about $y$-axis, zero along $z$-axis\\
\inlineemph{z\_max} - angle anti-clockwise about $z$-axis, zero along $x$-axis\\

\subsubsection{Distribution functions}
%
\begin{nbboxverbatim}{dist\_fn block}
begin:dist_fn
   name = x_px
   ndims = 2
   dumpmask = always

   direction1 = dir_x
   direction2 = dir_px

   # range is ignored for spatial coordinates
   range1 = (1,1)
   range2 = (-50.0e-20,50.0e-20)

   # resolution is ignored for spatial coordinates
   resolution1 = 1
   resolution2 = 5000

   include_species:Electron
   include_species:Carbon
end:dist_fn
\end{nbboxverbatim}

One way of considering the PIC methodology is based on the idea of using the
simulation pseudoparticles as Monte-Carlo sampling points of the phase space
of Vlasov's equation. While direct simulation of Vlasov's equation leads to
much lower noise than using this Monte-Carlo approach it is much more
computationally expensive and is currently only just possible in 2D and
completely impossible in 3D. However, sometimes it is useful to be able to
reconstruct at least some of the phase space for one or more particle species,
and this option is provided through a \inlineemph{dist\_fn} block. The
distribution function is integrated over all dimensions which are not axes of
the distribution function.\\

This block allows the user to specify information about
setting up additional diagnostics including phase space reconstructions. It is
possible to set up as many 2D and 3D distribution functions as required by
simply specifying multiple \inlineemph{dist\_fn} blocks. The layout of these
blocks is as follows:\\

{\emphtext name} - The name of the distribution function when it is
output. This name is appended with the name of each species for which the data
is output and so, for example, when applied to a species named
carbon the output is called \inlineemph{x\_px\_Carbon}. The Cartesian grid
which describes the axes of the distribution function would then be called
\inlineemph{grid\_x\_px\_Carbon}.\\

{\emphtext ndims} - The number of dimensions in this phase space
reconstruction. Due to difficulties in visualising data in more than three
dimensions, this is restricted to being either 2 or 3.\\

{\emphtext dumpmask} - Determines which output dumps will include this
distribution function. The dumpmask has the same semantics as those used
by variables in the ``output'' block, described in \sect{output block}.
If the ``distribution\_functions'' dumpmask is specified in the ``output''
block then that will take precedence.\\

{\emphtext direction\inlinecode{n}} - This is the direction
which is calculated to run along axis \inlinecode{n}. This can be any one of:
dir\_x, dir\_y, dir\_z, dir\_px, dir\_py, dir\_pz, dir\_en, dir\_gamma\_m1
with spatial codes only being available in dimensionalities of the code which
have that direction. Therefore dir\_z does not exist in EPOCH1D or EPOCH2D.\\

{\emphtext range\inlinecode{n}} - The range between which this axis should
run. This is in the form of (minimum, maximum). The rangen parameter is ignored
when applied to a spatial direction since all spatial directions run over
the whole domain. For momentum directions this parameter is specified in
$kg\ ms^{-1}$. If the range of a momentum direction is set so that the maximum
and the minimum are both zero then the code will automatically set the range to
exactly span the range of particle momenta at the point of writing the dump.\\

{\emphtext NOTE: Currently the range parameters have to be simple floating
point numbers and NOT maths parser expressions.}\\

{\emphtext resolution\inlinecode{n}} - The number of gridpoints in a given
direction. Once again this is ignored for spatial dimensions where the
resolution is always the same as the resolution of the underlying simulation.\\

{\emphtext include\_species} - Specifies a species which should be included
in the output. This is useful since it is rare that momentum limits are
appropriate for both electrons and ions, so usually for a given dist\_fn block
only electrons or ions are considered. It is possible to have two dist\_fn
blocks with the same name but different momentum ranges and different
include\_species settings produce the effect of a single diagnostic for
all species in the output file.\\


There are a few additional commands which are less commonly used but can be
useful in some circumstances. These commands allow a user to restrict which
particles should be included in the distribution function.
It allows the user to specify minimum and
maximum values for each spatial and momentum direction and use particles which
fall within this range when calculating the distribution function. The
restrictions are specified in the same (minimum,maximum) form as ranges. These
commands are:\\

{\emphtext restrict\_\{x,y,z\}} - Restricts over spatial dimensions. Only
spatial dimensions which exist in the code being run are available. Therefore,
attempting to set restrict\_z in EPOCH1D will produce a warning.\\

{\emphtext restrict\_p\{x,y,z\}} - Restricts over momentum directions. All
momentum directions exist in all versions of the code, so it is possible to set
restrictions in any momentum dimension in any dimensionality of the code.\\

{\emphtext NOTE: It is possible to restrict in dimensions which are included in
the distribution function and these restrictions are honoured. This means that
there will be empty sections of the distribution function plot.}

\subsection{Basic examples of using {\EPOCH}}

\subsubsection{Electron two stream instability}

An obvious simple test problem to do with {\EPOCH} is the electron two stream
instability. An example of a nice dramatic two stream instability can be
obtained using EPOCH1D by setting the code with the following input deck
files.
\begin{lboxverbatim}{input.deck}
begin:control
   # global number of gridpoints
   nx = 400 # in x
   npart = 3200

   # maximum number of iterations
   # set to -1 to run until finished
   nsteps = -1

   # final time of simulation
   t_end = 1.5e-1

   # size of domain
   x_min = 0
   x_max = 5.0e5
end:control

begin:boundaries
   bc_x_min = periodic
   bc_x_max = periodic
end:boundaries

begin:species
   # Rightwards travelling electrons
   name = Right
   charge = -1
   mass = 1.0
   frac = 0.5
   dump = T
end:species

begin:species
   # Leftwards travelling electrons
   name = Left
   charge = -1
   mass = 1.0
   frac = 0.5
   dump = T
end:species

begin:output
   # If use_offset_grid is true then the code dumps a
   # grid which displays positions relative to the
   # Left hand edge of the window
   use_offset_grid = F
   # number of timesteps between output dumps
   dt_snapshot = 1.5e-3
   # Number of dt_snapshot between full dumps
   full_dump_every = 1
   restart_dump_every = -1
   force_final_to_be_restartable = T

   # Properties at particle positions
   particles = always
   px = always
   py = never
   pz = never
   vx = never
   vy = never
   vz = never
   charge = never
   mass = never
   particle_weight = never
   species_id = always

   # Properties on grid
   grid = always
   ex = always
   ey = always
   ez = always
   bx = always
   by = always
   bz = always
   jx = always
   jy = never
   jz = never
   ekbar = always
   mass_density = never + species
   charge_density = never
   number_density = always + species
   temperature = never
end:output

include:ic.deck
\end{lboxverbatim}

\begin{lboxverbatim}{ic.deck}
begin:constant
   drift_p = 2.5e-24
   temp = 273
   dens = 10
end:constant

begin:species
   name = Right
   temp_x = temp
   drift_x = drift_p
   number_density = dens
end:species

begin:species
   name = Left
   temp_x = temp
   drift_x = -drift_p
   number_density = dens
end:species
\end{lboxverbatim}

\scaledcapimage{./images/late}{tsilate}{The final state of the electron
  phase space for the two stream instability example.}{0.4}

While the \inlineemph{input.deck} file is rather long, most of it is the basic
standard input deck that is supplied with {\EPOCH}, with only the length of the
domain, the final time and the time between snapshots specific to this
problem. \inlineemph{ic.deck}, the initial conditions file, is very simple
indeed. The first block sets up constants for the momentum space drift, the
temperature and the electron number density. The second and third blocks set up
the two drifting Maxwellian distributions and the constant density profile.
Note that we have written this example as two separate files simply
to demonstrate how this is done. The
same result would be obtained by appending the contents of ``ic.deck'' to
the end of ``input.deck'' and removing the ``include'' line.
The final output from this simulation is shown in Figure~\ref{tsilate}.

\subsubsection{Structured density profile in EPOCH2D}

\scaledcapimage{./images/shapetest}{densitycomplex}{Complex 2D density
  structure}{0.4}

A simple but useful example for EPOCH2D is to have a highly structured initial
condition to show that this is still easy to implement in {\EPOCH}. A good
example initial condition would be:
\begin{lboxverbatim}{ic.deck}
begin:constant
  den_peak = 1.0e19
end:constant

begin:species
  name = Electron
  number_density = den_peak*(sin(4.0*pi*x/length_x+pi/4))*(sin(8.0*pi*y/length_y)+1)
  number_density_min = 0.1*den_peak
end:species

begin:species
  name = Proton
  number_density = number_density(Electron)
end:species
\end{lboxverbatim}

Although not included here, the input deck associated with these initial
conditions sets the properties for the Electron and Proton species.
The species block for \inlineemph{Electron} is specified
first, setting up the electron density to be a structured 2D sinusoidal
profile. The species block for \inlineemph{Proton} is then set to
match the density of \inlineemph{Electron}, enforcing charge neutrality. On
its own this initial condition does nothing and so only needs to run for 0
timesteps (\inlineemph{nsteps = 0} in input.deck). The resulting electron number
density should look like Figure~\ref{densitycomplex}

\subsubsection{A hollow cone in 3D}
A more useful example of an initial condition is to create a hollow cone. This
is easy to do in both 2D and 3D, but is presented here in 3D form.
\begin{lboxverbatim}{ic.deck}
begin:constants
   den_cone = 1.0e22
   ri = abs(x-5.0e-6)
   ro = ri+1.0e-6
   r = sqrt(y^2+z^2)
end:constants

begin:species
   name = Proton
   number_density = if((r gt ri) and (r lt ro), den_cone, 0.0)
   number_density = if(x gt 3.0e-6, den_cone, number_density(Proton))
   number_density = if(x lt 4.0e-6, den_cone, number_density(Proton))
   number_density = if(r lt ri, den_cone, number_density(Proton))
   number_density = if(x gt 4e-6, 0.0, number_density(Proton))
end:species

begin:species
   name = Electron
   number_density = number_density(Proton) * 22.0
end:species
\end{lboxverbatim}

To convert this to 2D, simply replace the line
\inlinecode{r = sqrt(y\^{}2+z\^{}2)} with the line \inlinecode{r = abs(y)}. The
actual work in these initial conditions is done by the three lines inside the
block for the \inlineemph{Proton} species. Each of these lines performs a very
specific function:

\begin{enumerate}
\item Creates the outer cone. Simply tests whether \inlinecode{r} is within
  the range of radii which corresponds to the thickness of the cone and if so
  fills it with the given density. Since the inner radius is x dependent this
  produces a cone rather than a cylinder. On its own, this line produces a
  pair of cones joined at the tip.
\item Creates the solid tip of the cone. This line just tests whether the
  point in space is within the outer radius of the cone and within a given
  range in x, and fills it with the given density if true.
\item Cuts off all of the cone beyond the solid tip. Simply tests if x is
  greater than the end of the cone tip and sets the density to zero if so.
\end{enumerate}

\scaledcapimage{./images/3dcone}{3dcone}{Cone initial conditions in 3D}{0.4}
\scaledcapimage{./images/2dcone}{2dcone}{Cone initial conditions in 2D}{0.4}

This deck produces and initial condition which looks like Figure~\ref{3dcone}
and Figure~\ref{2dcone} in 3D and 2D respectively.

The details presented above are a first rough guide to using {\EPOCH}. To
clearly understand {\EPOCH} it is best to now try some simple examples. To
view the results you will have to jump forward to the section
Visualising {\EPOCH} output data (section 3.15). After these tests re-read
this section before proceeding to the more detailed descriptions that follow.


\clearpage

\section{{\EPOCH} for end users}
This section is a more detailed version of the Getting Started Guide above. As
a result there is some repetition. More complex examples and options are
introduced.
\label{sec:endusers}

\subsection{Structure of the {\EPOCH} codes}
When obtained, the {\EPOCH} codes all have a similar structure. Inside the
epoch{n}d directory, there are 4 subdirectories:

\begin{itemize}
\item src - The {\EPOCH} source code.
\item IDL - The IDL routines needed to open the SDF files which the code
  outputs.
\item example\_decks - A sample data directory containing example input deck
  files.
\item Data - This is an empty directory to use for running simulations.
\end{itemize}

there are also 4 files:

\begin{itemize}
\item Changelog.txt - A brief overview of the change history for each
  released version of {\EPOCH}.
\item Makefile - A standard makefile.
\item Start.pro - An IDL script which starts the IDL visualisation
  routines. Execute it using ``idl Start''.
\item unpack\_source\_from\_restart - Restart dumps can be written to contain
  a copy of the input decks and source code used to generate them. This script
  can be used to unpack that information from a given restart dump. It is run
  from the command line and must be passed the name of the restart dump file.
\end{itemize}

There are also two directories in the parent directory of epoch{1,2,3}d:

\begin{itemize}
\item Matlab - The files for creating a plug-in for the Mathworks MatLab
  visualisation tool for reading SDF files generated by an {\EPOCH} run.
\item VisIt - The files for creating a plug-in for the LLNL VisIt parallel
  visualisation tool for reading SDF files generated by an {\EPOCH} run.
\end{itemize}

\subsection{Libraries and requirements}
The {\EPOCH} codes are written using MPI for parallelism, but have no other
libraries or dependencies. Currently, the codes are written to only require
MPI1.2 compatible libraries, although this may change to require full MPI2
compliance in the future. Current versions of both MPICH and OpenMPI implement
the MPI2 standard and are known to work with this code. The SCALI MPI
implementation is only compliant with the MPI1.2 specification and may loose
support soon.
There are no plans to write a version of {\EPOCH} which does not require
the MPI libraries.

The code is supplied with a standard GNU make makefile, which is also
compatible with most other forms of the {\bf make} utility. In theory it is
possible to compile the code without a {\bf make} utility, but it is much
easier to compile the code using the supplied makefile.

\subsection{Compiling and running {\EPOCH}}

To compile {\EPOCH} in the supplied state, just type\\
\indent\inlinecode{make}\\
and the code will compile. There are certain options within the code which are
controlled by compiler preprocessors which are described in the next
section. When the code is compiled, it creates a new directory called ``bin''
containing the compiled binary which will be called \inlinecode{epoch1d},
\inlinecode{epoch2d} or \inlinecode{epoch3d}. To run the code, just execute the
binary file by typing:\\
\indent\inlinecode{./bin/epoch2d}\\
or whatever the correct binary is for the dimensionality of the code that you
have. You should be given a screen which begins with the {\EPOCH} logo, and then
reads:
\begin{boxverbatim}
 Welcome to EPOCH2D Version 3.0

 The code was compiled with the following compile time options
 *************************************************************
 Per particle weighting -DPER_PARTICLE_WEIGHT
 Tracer particle support -DTRACER_PARTICLES
 Particle probe support -DPARTICLE_PROBES
 *************************************************************

 Code is running on 1 processing elements


 Specify output directory
\end{boxverbatim}

At this point, the user simply types in the name of the (already existing)
output directory and the code will read the input deck files inside the
specified directory and start running. To run the code in parallel, just use
the normal mpirun or mpiexec scripts supplied by your MPI implementation. If
you want the code to run unattended, then you will need to specify the output
directory by piping the directory name in from a file. An example of such a
file is supplied as ``deck.file'' with the standard distribution of {\EPOCH}. To
use it, just run the code as\\
\indent\inlinecode{mpirun -np 2 ./bin/epoch2d < deck.file}\\
and the code will run without user input. Some cluster queueing systems do not
allow the use of input pipes to mpirun. In this case, there is usually a
``-stdin'' command line option to specify an input file, see your cluster
documentation for more details.

\subsection{Compiler flags and preprocessor defines}
As already stated, some features of the code are controlled by compiler
preprocessor directives. The flags for these preprocessor directives are
specified in ``Makefile'' and are placed on the line which reads:
\begin{boxverbatim}
DEFINES = -DPER_PARTICLE_WEIGHT
\end{boxverbatim}
To turn on the effect given by a given preprocessor directive, just add the
command \inlinecode{-D\{directive\}} to the \inlinecode{DEFINES} line. The
options currently controlled by the preprocessor are:\\
\begin{itemize}
\item PER\_PARTICLE\_WEIGHT - Instead of running the code where each
  pseudoparticle represents the same number of real particles, each
  pseudoparticle can represent a different number of real particles. Many of
  the codes more advanced features require this and it is turned on by
  default. It can be turned off to save on memory, but this is recommended
  only for advanced users.
\item PER\_PARTICLE\_CHARGE\_MASS - By default, the particle charge and
  mass are specified on a per-species basis. With this flag enabled, charge
  and mass become a per-particle property.
\item SPLIT\_PARTICLES\_AFTER\_PUSH - After the code has updated the particle
  positions, it splits the particles into separate lists for each grid
  cell. Some features of the code (like collision operators) require this
  feature to be on, but it is off by default.
\item PARTICLE\_DEBUG - Each particle is additionally tagged with information
  about which processor it is currently on, and which processor it starts
  on. This is a debug mode for code development.
\item FIELD\_DEBUG - The code also outputs information about where the
  processor boundaries are in space. This is a debug mode for code development.
\item PARSER\_DEBUG - The code outputs more detailed information whilst
  parsing the input deck. This is a debug mode for code development.
\item PARTICLE\_IONISE - Activate the particle ionisation code (BETA).
\item PARTICLE\_COUNT\_UPDATE - Makes the code keep global particle counts for
  each species on each processor. This information isn't needed by the core
  algorithm, but can be useful for developing some types of additional physics
  packages. It does require one additional MPI\_ALL\_REDUCE per species per
  timestep, so it is not activated by default.
\item TRACER\_PARTICLES - Gives the option to specify one or more species as
  tracer particles. Tracer particles are specified like normal particles, and
  move about as would a normal particle with the same charge and mass, but
  tracer particles do not generate any current and are therefore passive
  elements in the simulation. Any attempt to add particle collision effects
  should remember that tracer species should not interact through collisions.
  The implementation of tracer particles requires an additional ``IF'' clause
  in the particle push, so it is not activated by default.
\item PARTICLE\_PROBES - For laser plasma interaction studies it can sometimes
  be useful to be able to record information about particles which cross a
  plane in the simulation. Since this requires the code to check whether each
  particles has crossed the plane in the particles pusher and also to store
  copies of particles until the next output dump, it is a heavyweight
  diagnostic. Therefore, this diagnostic is only enabled when the code is
  compiled with this directive.
\item PARTICLE\_SHAPE\_TOPHAT - By default, the code uses a first order
  b-spline (triangle) shape function to represent particles giving
  third order particle weighting.
  Using this flag changes the particle representation to that of a top-hat
  function (0th order b-spline yielding a second order weighting).
\item PARTICLE\_SHAPE\_BSPLINE3 - This flag changes the particle representation
  to that of a 3rd order b-spline shape function (5th order weighting).
\end{itemize}

So to turn on per particle weighting and particle debugging, the line would
look like:
\begin{boxverbatim}
DEFINES = -DPER_PARTICLE_WEIGHT -DPARTICLE_DEBUG
\end{boxverbatim}

If a user requests an option which the code has not been compiled to support
then the code will give an error message as follows:
\begin{boxverbatim}
 *** WARNING ***
 The element "particle_probes" of block "output" cannot be set
 because the code has not been compiled with the correct preprocessor options.
 Code will continue, but to use selected features, please recompile with the
 -DPARTICLE_PROBES option
\end{boxverbatim}

It is also possible to pass other flags to the compiler. In ``Makefile'' there
is a line which reads\\
\indent\inlinecode{FFLAGS = -O3 -fast}\\
the two commands to the right are compiler flags and are passed unaltered to
the Fortran compiler. Change this line to add any additional flags required by
your compiler.

By default, {\EPOCH} will write a copy of the source code and input decks
into each restart dump. This can be very useful since a restart dump contains
an exact copy of the code which was used to generate it, ensuring that you
can always regenerate the data or continue running from a restart.
The output can be prevented by using ``dump\_source\_code = F'' and
``dump\_input\_deck = F'' in the output block.
However, the functionality is difficult to build on some platforms so
the Makefile contains a line for bypassing this section of the build
process. Just below all the DEFINE flags there is the following line:
\begin{boxverbatim}
# ENCODED_SOURCE = dummy_encoded_source.o
\end{boxverbatim}
Just uncomment this line and source code in restart dumps will be permanently
disabled.


\subsection{The {\EPOCH} input deck}
The input deck files describe the setup of the code and
include almost all the controllable parameters for the code. The input deck is
contained in a file called ``input.deck'' which must be present in the output
directory that is given to the code at runtime. It is a structured
file which is split into separate blocks, with each block containing several
``parameter'' = ``value'' pairs. The pairs can be present in any order, and not
all possible pairs must be present in any given input deck. If a required pair
is missing the code will exit with an error message. The input deck is case
sensitive, so true is always ``T'', false is always ``F'' and the names of
the parameters are always lower case.\\

There are three {\it input deck directive} commands, which are:
\begin{itemize}
\item begin:{\it block} - Begin the block named {\it block}.
\item end:{\it block} - Ends the block named {\it block}.
\item include:{\it filename} - Includes another file (called {\it filename})
  into the input deck at the point where the directive is encountered. The
  input deck parser reads the included file exactly as if the contents of the
  included file were pasted directly at the position of the include directive.
\end{itemize}
Each block must be surrounded by valid {\it begin:} and {\it end:} directives
or the input deck will fail. There are currently eleven valid blocks hard
coded into the input deck reader, but it is possible for end users to extend
the input deck. The eleven built in blocks are:
\begin{itemize}
\item control - Contains information about the general code setup.
\item boundaries - Contains information about the boundary conditions for this
  run.
\item species - Contains information about the species of particles which are
  used in the code. Also details of how these are initialised.
\item output - Contains information about when and how to dump output files.
\item window - Contains information about the moving window if the code is
  used in that fashion.
\item constant - Contains information about user defined constants and
  expressions. These are designed to simplify the initial condition setup.
\item fields - Contains information about the EM fields specified at the
  start of the simulation.
\item laser - Contains information about laser boundary sources.
\item dist\_fn - Contains information about distribution functions that should
  be calculated for output.
\item probe - Contains information about particle probes used for output.
\end{itemize}

\subsubsection{The control block}
The control block of a valid input deck for EPOCH2D reads as follows:
\begin{boxverbatim}
begin:control
   # global number of gridpoints
   nx = 512 # in x
   ny = 512 # in y
   # global number of particles
   npart = 1000000

   # final time of simulation
   t_end = 1.0e-12

   # size of domain
   x_min = -0.1e-6
   x_max = 400.0e-6
   y_min = -400.0e-6
   y_max = 400.0e-6

   dlb_threshold = 0.5
end:control
\end{boxverbatim}

The allowed entries are as follows:\\

{\emphtext nx, ny, nz} - Number of grid points in the x,y,z direction. There
must be sufficient gridpoints so that (x\_max-x\_min)/nx $< \lambda_d$, where
$\lambda_d$ is the Debye length. (Similarly for the y and z directions.).
These are required parameters.\\

{\emphtext npart} - The global number of pseudoparticles in the
simulation. This parameter does not need to be given if a specific number
of particles is supplied for each particle species. Specifying both will just
use the number of particles supplied for each species.\\

{\emphtext nsteps} - The number of iterations of the core solver before the
code terminates. Negative numbers instruct the code to only terminate at
\inlineemph{t\_end}.\\

{\emphtext t\_end} - The final simulation time in simulation seconds before the
code terminates.\\

{\emphtext NOTE: The code will terminate if EITHER of the above conditions on
nsteps or t\_end is satisfied.}\\

{\emphtext \{x,y,z\}\_min} - Minimum grid position of the domain in
metres. These are required parameters. Can be negative. ``\{x,y,z\}\_start'' is accepted as a synonym.\\

{\emphtext \{x,y,z\}\_max} - Maximum grid position of the domain in
metres. These are required parameters. Must be greater than
\inlineemph{\{x,y,z\}\_min}.  ``\{x,y,z\}\_end'' is accepted as a synonym.\\

{\emphtext dt\_multiplier} - Factor by which the timestep is multiplied before
it is applied in the code. Must be less than one. The default value is 0.95.\\

{\emphtext dlb\_threshold} - Number indicating the minimum ratio between the
load on the least loaded processor to the most loaded processor. Set to 1 means
always balance, set to 0 means never balance. If this parameter is not
specified then the code will only be load balanced at initialisation time.\\

{\emphtext restart\_snapshot} - The number of a previously written restart
dump to restart the code from. If not specified then the initial conditions
from the input.deck are used.\\

{\emphtext field\_order} - Order of the finite difference scheme used for
solving Maxwell's equations. Can be 2, 4 or 6. If not specified, the default
is to use a second order scheme.\\

{\emphtext stdout\_frequency} - If specified then the code will print a one
line status message to stdout after every given number or timesteps. The
default is to print nothing to screen.\\


Most of the control block is self explanatory, but there are two parts which
need further description. \\
``dlb'' stands for Dynamic Load Balancing and, when turned on, it allows the
code to rearrange the internal domain boundaries to try and balance the
workload on each processor. This rearrangement is an expensive operation, so
it is only performed when the maximum load imbalance reaches a given critical
point. This critical point is given by the parameter ``dlb\_threshold'' which
is the ratio of the workload on the least loaded processor to the most loaded
processor. When the calculated load imbalance is less than ``dlb\_threshold''
the code performs a re-balancing sweep, so if ``dlb\_threshold = 1.0'' is set
then the code will keep trying to re-balance the workload at almost every
timestep. At present the workload on each processor is simply calculated from
the number of particles on each processor, but this will probably change in
future. If the ``dlb\_threshold'' parameter is not specified then the code
will only be load balanced at initialisation time.\\

\subsubsection{The boundaries block}
The next section of the input deck describes the boundary conditions. The
boundaries block for EPOCH3D is as follows:
\begin{boxverbatim}
begin:boundaries
   bc_x_min = other
   bc_x_max = other
   bc_y_min = periodic
   bc_y_max = periodic
   bc_z_min = other
   bc_z_max = other
end:boundaries
\end{boxverbatim}

This block is fairly self explanatory and describes the boundary conditions
applied to each of the 6 faces of the cuboid which represents the extents of
the simulation. In 1D only xbc\_ appears and in 2D only xbc\_ and ybc\_
appear. The possible boundary conditions are:\\
\begin{itemize}
\item periodic - Particles and fields crossing this boundary wrap back round
  to the opposite boundary. If either boundary condition is set to periodic
  then the boundary condition on the matching boundary at the other side of
  the box is also assumed periodic.
\item other - Particles are perfectly reflected from this boundary
  type. Electric and magnetic fields are clamped to zero at the boundary.
\item simple\_laser - Particles and outwardly propagating EM waves travel
  through the boundary. One or more inwardly propagating EM wave sources may
  be specified either in the input deck or in the initial conditions section.
\item simple\_outflow - Particles and outwardly propagating EM waves travel.
  through the boundary. It is not possible to attach a wave source to this
  type of boundary, which makes it simpler and faster than simple\_laser.
\end{itemize}
Other boundary types will appear as the code matures, probably including laser
driven boundaries and absorbing boundaries.\\

\subsubsection{The species block}
The next section of the input deck describes the particle species used in the
code. An example species block for any {\EPOCH} code is given below.
\begin{boxverbatim}
begin:species
   # H+ ions
   name = Proton
   charge = 1.0
   mass = 1800.0
   frac = 0.5
   dump = T
end:species
\end{boxverbatim}

The species block is slightly more complex than preceding blocks in that the
number of species described in a block must be specified in advance. While
for most input deck blocks the structure is completely free-form, the first
thing specified in the species block must be ``n\_species'' which tells the
code how many species of particle are present in the code. After that, the
block is once again free-form, although it makes sense to keep the information
for each species together. Each species has the following data which must be
specified in the input deck:\\
\begin{itemize}
\item charge - The charge on the particle in units of the electron charge.
  Required parameter.
\item mass - The mass of the particle in units of the electron mass.
  Required parameter.
\item frac - The fraction of the total number of particles in the simulation
  which are of this species. Not used if ``\inlinecode{npart}'' is given in
  the species block.
\item name - The name of this particle species (as written to the output
  dumps). Required parameter.
\item dump - Whether or not to dump this particle species in normal outputs
  (this is ignored for restart dumps when enough information is dumped to
  restart the code). Default is ``\inlinecode{F}''
\item npart - This can be used instead of \inlinecode{frac} to explicitly set
  the number of particles for a species. If this element is set then the code
  effectively ignores the values of \inlinecode{npart} set in the control
  block.
\item tracer - If the code is compiled with tracer particle support then
  setting this logical element to ``\inlinecode{T}'' makes the code treat this
  species as a tracer species. Tracer species have the correct charge and mass
  but do not contribute any current. Default is ``\inlinecode{F}''
\end{itemize}

The particle species which a given property refers to is simply set by a
number after the property name, starting with 1 for the first species and
ending at n\_species for the final species. A final note: if the values of
frac for all species don't add up to one then there will be some particles
requested which are never assigned a species. These particles are destroyed
before the code runs to save memory and compute time, but it means that the
number of particles in the simulation will be lower than expected.\\

\subsubsection{The output block}
The next section of the input deck is the output section. It describes the
data that the user wants dumped from the code and an example block from any
version of {\EPOCH} is given below.
\begin{boxverbatim}
begin:output
   # If use_offset_grid is true then the code dumps a
   # grid which displays positions relative to the
   # Left hand edge of the window
   use_offset_grid = T

   # number of timesteps between output dumps
   dt_snapshot = 1.0e-14
   # Number of dt_snapshot between full dumps
   full_dump_every = 1
   restart_dump_every = 1
   force_final_to_be_restartable = T

   # Properties at particle positions
   particles = full
   px = never
   py = never
   pz = never
   vx = full
   vy = full
   vz = never
   charge = full
   mass = full
   particle_weight = always
   species_id = always

   # Properties on grid
   grid = always
   ex = always
   ey = always
   ez = always
   bx = always
   by = always
   bz = always
   jx = always
   jy = always
   jz = always
   temperatures = always
   mass_density = always
   charge_density = always
end:output
\end{boxverbatim}

The first set of options control the type and frequency of output dumps. They
are used as follows\\
\begin{itemize}
\item use\_offset\_grid - Causes the code to output a special grid which moves
  with a moving window if one is specified. This is needed to allow
  visualisation packages like LLNL VisIt, which cannot cope with moving axes, to
  work properly. If you are not using a moving window then setting this option
  to true merely wastes space as both the normal and the special grid are the
  same. Default value is ``F''.
\item dt\_snapshot - Time (in internal seconds) between performing a basic
  output dump. Default value is larger than the simulation time.
\item full\_dump\_every - Number of basic output dumps between full output
  dumps. Set to -1 or lower to not produce full dumps. Default value is -1.
\item restart\_dump\_every - Number of basic output dumps between restart
  dumps. Set to -1 or lower to not produce restart dumps. Default value is -1.
\item force\_final\_to\_be\_restartable - Whether or not the code should force
  the last output dump to be a restart dump. This ensures that it is possible
  to restart the code from the last output dump. Default is ``F''.
\end{itemize}

The remaining items control what data should be dumped at which type of
output. There are three possible values\\
\begin{itemize}
\item never - This variable will never be dumped unless it is a required restart
  variable in which case it will be dumped at a restart dump.
\item full - Dump only at a full output dump.
\item always - Dump at a basic output dump.
\item species - When applied to a grid variable which can meaningfully be
  calculated on a per species level, this causes the code to dump per species
  information about that variable. This is simply added to the frequency code,
  i.e. ``mass\_density = always + species'' will cause the mass density to be
  output at every dump for each species and also globally.
\end{itemize}

The options are fairly self explanatory, but they are given in more detail
below. The first set are per particle properties which must be plotted at the
individual particle positions to make sense. All entries have a default
dumpmask of ``never''.\\
\begin{itemize}
\item particles - Dump particle position data.
\item px, py, pz - Dump particle momentum in x, y, z direction.
\item vx, vy, vz - Dump particle velocity in x, y, z direction.
\item charge - Dump particle charge.
\item mass - Dump particle mass.
\item particle\_weight - Dump the weight value for each particle. (The weight
  is the number of real particles represented by a given pseudoparticle).
\item species\_id - Dump the species number for each particle.
\end{itemize}

There are also variables which are defined on the underlying grid. All entries
have a default dumpmask of ``never''.\\
\begin{itemize}
\item grid - Dump the grid underlying the simulation.
\item ex, ey, ez - Dump the electric field in x, y, z.
\item bx, by, bz - Dump the magnetic field in x, y, z.
\item jx, jy, jz - Dump the current in x, y, z.
\item temperature - Dump the mean particle kinetic energy at each gridpoint
  for each species.
\item mass\_density - Dump the mass density.
\item charge\_density - Dump the charge density.
\end{itemize}

\subsubsection{The window block}
{\EPOCH} can include an optional block which causes the simulation domain to
operate as a moving window. At present, it is only possible to have the window
moving at a constant speed parallel to the x direction, although the window
does not have to start moving at t = 0. When the window moves, the code removes
particles from the left hand edge of the domain and introduces new particles
at the right hand edge. The code does not only reintroduce the same number of
particles at the right hand edge as are removed at the left hand edge, but
introduces new particles so that for each species the new particles have a
given number density, temperature and number of pseudoparticles per cell. It
is not currently possible to turn off the reintroduction of particles to allow
a pulse to travel into a vacuum region, although this is being developed. The
block looks like:
\begin{boxverbatim}
begin:window
   move_window = T
   window_v_x = 3.0e8
   window_start_time = 7.0e-13
   bc_x_min_after_move = simple_outflow
   bc_x_max_after_move = simple_outflow
end:window
\end{boxverbatim}

\begin{itemize}
\item move\_window - Logical flag determining whether or not to move the
  window. If the window block is absent then this is the same as setting
  move\_window to ``F''.
\item window\_v\_x - The speed in m/s of the window.
\item window\_start\_time - The time in seconds at which the window should
  start moving.
\item bc\_x\_min\_after\_move - The boundary condition which should apply to
  the left boundary after the window has started moving. This is to allow the
  swapping of a laser boundary to a simple outflow boundary. Boundary codes
  are the same as when just specifying normal boundaries. If a boundary value
  isn't specified then it is assumed that the boundary isn't changed when the
  window starts moving. ``xbc\_left\_after\_move'' is accepted as a synonym.
\item bc\_x\_max\_after\_move - The boundary condition which should apply to
  the right boundary after the window has started moving.
  ``xbc\_right\_after\_move'' is accepted as a synonym.
\end{itemize}

The basic input deck has now been considered fully but it
 is possible for an end user to add new blocks to the input deck As a result
a version of the code which you have obtained from a source other than
CCPForge may include other input deck blocks. These should be described in
additional documentation provided with the version of the code that you have.

\subsection{The maths parser}
\label{sec:maths_parser}
A discussion of the input deck for {\EPOCH} would not be complete without
consideration of the maths parser. The maths parser is the code which reads
the input decks.
The parser makes it possible that any parameter taking a
numerical value (integer or real) can be input as a mathematical expression
rather than as a numerical constant. The maths parser is fairly extensive and
includes a range of mathematical functions, physical and simulation constants
and appropriately prioritised mathematical operators.


\subsubsection{Constants}
\label{sec:constants}
The maths parser in {\EPOCH}  has the following constants
\begin{itemize}
\item pi - The ratio of the circumference of a circle to its diameter.
\item kb - Boltzmann's constant.
\item me - Mass of an electron.
\item qe - Charge of an electron.
\item c - Speed of light.
\item epsilon0 - Permeability of free space.
\item mu0 - Permittivity of free space.
\item ev - Electronvolt.
\item kev - Kilo-Electronvolt.
\item mev - Mega-Electronvolt.
\item microns - A convenience symbol for specifying wavelength in microns
rather than metres.
\item W\_cm2 - A convenience symbol for specifying irradiance in $W/cm^2$
rather than $W/m^2$.
\item time - Initial simulation time.
\item length\_\{x,y,z\} - The length of the simulation box in the x,y,z
  direction.
\item dx,dy,dz - Grid spacing in the x,y,z direction.
\item \{x,y,z\}\_min - Grid coordinate of the minimum x,y,z boundary.
\item \{x,y,z\}\_max - Grid coordinate of the maximum x,y,z boundary.
\item nx,ny,nz - Number of grid points in the x,y,z direction.
\item x,y,z - Grid coordinates in the x,y,z direction.
\item ix,iy,iz - Grid index in the x,y,z direction.
\end{itemize}

It is also possible for an end user to specify custom constants both within
the code and from the input deck. These topics are covered later in this
subsection. An example of using a constant would be:\\
\indent\inlinecode{length\_x = pi}\\

\subsubsection{Functions}
\label{sec:functions}
The maths parser in {\EPOCH} has the following functions
\begin{itemize}
\item sqrt(a) - Square root.
\item sin(a) - Sine.
\item cos(a) - Cosine.
\item tan(a) - Tangent.
\item exp(a) - Exponential.
\item asin(a) - Arcsine.
\item acos(a) - Arccosine.
\item atan(a) - Arctangent.
\item if(a,b,c) - Conditional function. If a != 0 the function returns b,
  otherwise the function returns c.
\item floor(a) - Convert real to integer rounding down.
\item ceil(a) - Convert real to integer rounding up.
\item nint(a) - Convert real to integer rounding to nearest integer.
\item tanh(a) - Hyperbolic tangent.
\item sinh(a) - Hyperbolic sine.
\item cosh(a) - Hyperbolic cosine.
\item abs(a) - Absolute value.
\item loge(a) - Natural logarithm.
\item log10(a) - Base-10 logarithm.
\item log\_base(a,b) - Base-b logarithm.
\item number\_density(a) - Returns the density for species a.
\item temp\_\{x,y,z\}(a) - Returns temperature in the x, y or z direction for species a.
\item temp(a) - Returns the isotropic temperature for species a.
\item e\{x,y,z\}(x,y,z) - Returns the x, y or z component of the electric
    field at the specified location.
\item b\{x,y,z\}(x,y,z) - Returns the x, y or z component of the magnetic
    field at the specified location.
\item critical($\omega$) - Returns the critical density for the given
    frequency $\omega$. ie. $n_{crit}(\omega) = \omega^2 m_0 \epsilon_0 / e^2$
\item gauss($x,x_0,w$) - Calculate a Gaussian profile in variable
    {\it x} centred on {\it $x_0$} with a characteristic width {\it w}.
    $f(x) = \exp{(-((x-x_0)/w)^2)}$. In this expression the
    full width at half maximum is given by $fwhm = 2 w \sqrt{\ln{2}}$
\item semigauss($t,A,A_0,w$) - Calculate a semi Gaussian profile in variable
    $t$ with maximum amplitude $A$, amplitude at $t=0$ $A_0$ and width $w$.
    The parameter $A_0$ is used to calculate $t_0$, the point at which the
    Gaussian reaches its maximum value. For $t$ less than $t_0$ the profile
    is Gaussian and for $t$ greater than $t_0$ it is the constant $A$.
\[
t_0 = w\sqrt{-\ln{(A_0/A)}}
\]\[
f(t) =
\begin{cases}
A \exp{(-((t-t_0)/w)^2)}, & t < t_0 \\
A, & \mbox{otherwise}
\end{cases}
\]
\item interpolate(interp\_var,....,n\_pairs) - Linear interpolation function,
  explained later.
\end{itemize}

It is also possible for an end user to specify custom functions within the
code. An example of using a function would be:\\
\indent\inlinecode{length\_x = exp(pi)}\\

\subsubsection{Operators}
The maths parser in {\EPOCH} allows the following operators
\begin{itemize}
\item a + b - Addition operator.
\item a - b - Subtraction operator or unary negation operator (auto-detected).
\item a * b - Multiplication operator.
\item a / b - Division operator.
\item a\^{}b - Power raise operator.
\item a e b - Power of ten operator (1.0e3 = 1000).
\item a lt b - Less than operator. Returns 1 if a $<$ b, otherwise returns
  0. Intended for use with if.
\item a gt b - Greater than operator. Returns 1 if a $>$ b, otherwise returns 0.
\item a eq b - Equality operator. Returns 1 if a == b, otherwise returns 0.
\item a and b - Logical and operator. Returns 1 if a != 0 and b != 0,
  otherwise returns 0.
\item a or b - Logical or operator. Returns 1 if a != 0 or b != 0, otherwise
  returns 0.
\end{itemize}

It is not possible at this time to specify custom operators without major
changes to the code. An example of using an operator would be:\\
\indent\inlinecode{length\_x = 10.0 + 12.0}\\

\subsection{Creating custom constants within the input deck}
Setting up the custom extensions to the input deck are discussed in the
section {\bf Customising {\EPOCH}} later in the manual, but it is simple to set
up custom constants from within the input deck. There is a special input deck
block called {\it constant} which simply contains the constants which you want
to set up. Suppose, for example, that you have a problem in 1D where the Debye
length is known and you want the box to be a fixed number of Debye lengths,
and the grid spacing to always be at least 0.5 Debye lengths, you would set
that up as follows:
\begin{boxverbatim}
begin:constant
  l_debye = 1.0e-6 # Debye length is 1 micrometer
  n_debye_in_box = 100 # number of debye lengths in simulation
  n_gridpoints = 100 # number of grid points requested
  l_metres = l_debye * n_debye_in_box # length of simulation box in metres
  n_gp_per_debye = n_gridpoints/n_debye_in_box # number of gridpoints per debye length
end:constant

begin:control
  # if the number of gridpoints per debye length is greater than 2
  # use the requested number of gridpoints, otherwise use enough
  # that there are two gridpoints per debye length
  nx = if(n_gp_per_debye gt 2, n_gridpoints, n_debye_in_box * 2)
  length_x = l_metres
end:control
\end{boxverbatim}

Note that in this case, it is still up to the user to ensure that the Debye
length is actually the value given in \inlinecode{l\_debye} by setting the
initial conditions. The named constants are created the first time they are
specified, and can be reset at will. It is possible to have several instances
of the constant block, either creating new constants or resetting existing
ones. It is possible to end other blocks, define constants, and then
restart the block, so this is valid:
\begin{boxverbatim}
begin:control
   # some of control block
end:control

begin:constant
   # set constants
end:constant

begin:control
   # rest of control block
end:control
\end{boxverbatim}

\subsection{Specifying initial conditions for particles using the input deck}

If the initial conditions for the plasma you wish to model can be described
by a number density and temperature profile on the underlying grid then
{\EPOCH} can create an appropriate particle distribution for you. The
set of routines which accomplish this task are known as the autoloader.
For many users, this functionality is sufficient to make use of the
code and there is no need to deal with the internal representation of
particles in {\EPOCH}.

The autoloader randomly loads particles in space to reproduce the number
density profile that was requested. It then sets the momentum components
of the particles to approximate a Maxwell-Boltzmann distribution
corresponding to the temperature profile. Sometimes this is not the
desired behaviour, for example you may wish to model a bump-on-tail
velocity distribution. It is currently not possible to specify these
initial conditions from the input deck and the particles must be setup
programmatically.

There are two stages to the particle setup in {\EPOCH} 

\begin{itemize}
\item auto\_load - This routine is called after reading and parsing the
  input deck. It takes care of allocating particles and setting up their
  initial positions and momenta using the initial conditions supplied in
  deck file.
  It is not necessary to recompile the code, or even have
  access to the source to change the initial conditions using this method.
\item manual\_load - Once particles have been allocated they can have their
  properties altered in this routine. By default it is an empty routine
  which does nothing.
\end{itemize}

\subsubsection{Setting autoloader properties from the input deck}
There are several blocks which allow the user to specify initial conditions
from the input deck. These blocks have the same maths capabilities as other
input deck blocks, but with some additional constants and functions which
only make sense when specifying initial conditions.\\

\begin{nbboxverbatim}{none}
begin:constant
   partdens = 1.0e25
   wpe = sqrt(partdens * qe^2/(me * epsilon0))
end:constant

begin:species
   name = s1
   number_density = interpolate(x,-(6.0e-6),0.2,(10.0e-6),0.2,(11.0e-6),
            1.0,(150.0e-6),1.0,(150.5e-6),0.2,(420.0e-6),0.2,6)
   number_density = number_density(s1)*partdens
   temp_x = 300.0
   temp_y = temp_x(s1)
   number_density_min = 0.3*partdens
end:species

begin:species
   name = s2
   number_density = number_density(s1)
   temp_x = temp_x(s1)
   temp_y = temp_x(s1)
   number_density_min = 0.3*partdens
end:species
\end{nbboxverbatim}

In the above example we have made use of the ``species'' block for specifying
initial conditions. There is one block for each species
and each species is identified by the ``name'' entry.
The ``species'' block has the following possible elements.
\begin{itemize}
\item number\_density - Particle number density in $m^{-3}$. 
  As soon as a number\_density= line has been parsed, the values are
  calculated for the whole domain and are available for reuse on the right hand
  side of an expression.
\item temp\_\{x,y,z\} - The temperature in each direction for a thermal
  distribution in K. To specify a temperature in ev, simply use the deck
  parser. So for example temp\_x = 4*kev/kb gives a 4kev temperature.
\item temp - Sets an isotropic temperature distribution in K. Does not give
  thermal distribution in ignorable directions. If both temp and a specific
  temp\_x, temp\_y, temp\_z parameter is specified then the last to appear in
  the deck has precedence.
\item number\_density\_min - Minimum particle number density in $m^{-3}$.
  When the number density in a cell falls below number\_density\_min the
  autoloader does not load any
  pseudoparticles into that cell to minimise the number of low weight,
  unimportant particles. If set to 0 then all cells are loaded with particles.
\item number\_density\_max - Maximum particle number density in $m^{-3}$. When
  the number density in a cell rises above number\_density\_max the autoloader
  clips the density to number\_density\_max allowing easy implementation of
  exponential rises to plateaus.
\item drift\_\{x,y,z\} - Specifies a momentum space offset in $kg\ ms^{-1}$ to
  the distribution function for this species. At present the drift\_\{x,y,z\}
  parameter CANNOT vary in space and is just a single constant.
\end{itemize}

In this block, the maths parser has the following constants available
which are generated based on the values given in the ``control'' block:
\begin{itemize}
\item x - X coordinate in metres.
\item y - Y coordinate in metres (2D and 3D only).
\item z - Z coordinate in metres (3D only).
\item dx - Grid spacing in the x direction.
\item dy - Grid spacing in the y direction (2D and 3D only).
\item dz - Grid spacing in the z direction (3D only).
\item \{x,y,z\}\_start - \{x,y,z\}\_start specified in the input deck.
\item \{x,y,z\}\_end - \{x,y,z\}\_end specified in the input deck.
\item ix - X coordinate in grid points.
\item iy - Y coordinate in grid points (2D and 3D only).
\item iz - Z coordinate in grid points (3D only).
\item time - Returns current simulation time (used in the laser boundaries).
\end{itemize}

The use of most of these functions and constants is fairly simple, but
``interpolate'' requires some additional explanation. This function allows a
user to specify a set of position,value pairs and have the code linearly
interpolate the values between these control points. This function is mainly
intended for ease of converting initial conditions from other existing PIC
codes, and the same effect can usually be obtained more elegantly using the
``if'' command. The structure of the ``interpolate'' command is as follows:
The first parameter is the variable which is to be used as the axis over which
to interpolate the values. This can in general be any valid expression, but
will normally just be a coordinate axis. The next 2n entries are the
position,value pairs and the final parameter is the number of position,value
pairs. The slightly clunky syntax of this command is unfortunately necessary to
allow it to work with some fairly fundamental features of the maths parser
used in {\EPOCH}.\\
All that is required now is to give an example.
A good example is to reproduce
the previous example of an isolated plasma block in 2D. This would look like:
\begin{boxverbatim}
begin:species
   name = s1
   # first set density in the range 0->1
   # cut down density in x direction
   number_density = if ((x gt -1) and (x lt 1),1.0,0.2)
   # cut down density in y direction
   number_density = if ((y gt -1) and (y lt 1),number_density(s1),0.2)

   # multiply density by real particle density
   number_density = number_density(s1)*100.0

   # Set the temperature to be zero
   temp_x = 0.0
   temp_y = temp_x(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*100.0
end:species

begin:species
   # Just copy the density for species s1
   number_density = number_density(s1)

   # Just copy the temperature from species s1
   temp_x = temp_x(s1)
   temp_y = temp_y(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*100.0
end:species
\end{boxverbatim}

An important point to notice is that the two parts of the logical expressions
in the input deck are enclosed within their own brackets. This helps to remove
some ambiguities in the functioning of the input deck parser. It is hoped that
this will soon be fixed, but at present ALWAYS enclose logical expressions in
brackets.

\subsubsection{Setting autoloader properties from an external binary file}
It is possible to load external data files into variables used by the
autoloader. In the input deck this is done as follows:
\begin{boxverbatim}
begin:species
   name = s1
   number_density = 'Data/data.file'
   offset = 80000
   temp_x = 'Data/data.file'
   temp_y = 'Data/data.file'
end:species_external1
\end{boxverbatim}

This method of specifying initial conditions is very similar to using the
maths parser, except that
where you would normally specify a functional form for a variable, you now
specify a filename.  It is possible to specify
multiple variables in a single file using the {\bf offset} element. When the
offset is set, the next data read from a file is read with an offset of {\bf
offset} bytes from the start of the file. {\bf offset} is reset to zero at the
start of a new {\it species} block, but is not reset within a given
{\it species} block. Therefore, in the example above, {\bf temp\_x}
and {\bf temp\_y} are assigned the same values. The data is immediately loaded
into the requested variable, so it is valid to do the following:
\begin{boxverbatim}
begin:species
   name = s1
   number_density = 'Data/data.file'
   number_density = number_density(s1)*partdens
   offset = 80000
   temp_x = 'Data/data.file'
   temp_y = temp_x(s1)
end:species
\end{boxverbatim}


\subsection{Manually overriding particle parameters set by the autoloader}
\label{sec:manualload}

Since not all problems in plasma physics can be described in terms of an
initial distribution of thermal plasma, it is also possible to manually
control properties of each individual pseudoparticle for an initial
condition. This takes place in the subroutine \inlinecode{manual\_load} in the
file user\_interaction/ic\_module.f90. Manual loading takes place after
all the autoloader phase, to allow manual tweaking of autoloader specified
initial conditions.

\subsubsection{{\EPOCH} internal representation of particles}
\label{sec:partrep}
Before we can go about manipulating particle properties in
\inlinecode{manual\_load}, we first need an overview of how the particles
are defined in {\EPOCH}.
Inside the code, particles are represented by a Fortran90 TYPE called
``particle''. The current definition of this type (in 2D) is:
\begin{boxverbatim}
  TYPE particle
    REAL(num), DIMENSION(3) :: part_p
    REAL(num), DIMENSION(c_ndims) :: part_pos
#ifdef PER_PARTICLE_WEIGHT
    REAL(num) :: weight
#endif
#ifdef PER_PARTICLE_CHARGE_MASS
    REAL(num) :: charge
    REAL(num) :: mass
#endif
    TYPE(particle), POINTER :: next, prev
#ifdef PARTICLE_DEBUG
    INTEGER :: processor
    INTEGER :: processor_at_t0
#endif
  END TYPE particle
\end{boxverbatim}
Note the presence of the preprocessor directives, meaning that charge and mass
only exist if the \inlinecode{-DPER\_PARTICLE\_CHARGEMASS} define was put in
the makefile. If you want to access a property that does not seem to be
present, check the preprocessor defines.

The ``particle'' properties can be explained as follows:
\begin{itemize}
\item part\_p - The momentum in 3 dimensions for the particle. This is always
  of size 3.
\item part\_pos - The position of the particle in space. This is of the same
  size as the dimensionality of the code.
\item weight - The weight of this particle. The number of real particles
  represented by this pseudoparticle.
\item charge - The particle charge. If the code was compiled without per
  particle charge, then the code uses the charge property from
  TYPE(particle\_species).
\item mass - The particle rest mass. If the code was compiled without per
  particle mass, then the code uses the mass property from
  TYPE(particle\_species).
\item next, prev - The next and previous particle in the linked list which
  represents the particles in the current species. This will be explained in
  more detail later.
\item processor - The rank of the processor which currently holds the
  particle.
\item processor\_at\_t0 - The rank of the processor on which the particle
  started.
\end{itemize}

Collections of particles are represented by another Fortran TYPE, called
\inlinecode{particle\_list}. This type represents all the properties of a
collection of particles and is used behind the scenes to deal with
inter-processor communication of particles. The definition of the type is:
\begin{boxverbatim}
  TYPE particle_list
    TYPE(particle), POINTER :: head
    TYPE(particle), POINTER :: tail
    INTEGER(KIND=8) :: count
    ! Pointer is safe if the particles in it are all unambiguously linked
    LOGICAL :: safe

    TYPE(particle_list), POINTER :: next, prev
  END TYPE particle_list
\end{boxverbatim}
\begin{itemize}
\item head - The first particle in the linked list.
\item tail - The last particle in the linked list.
\item count - The number of particles in the list. Note that this is NOT MPI
  aware, so reading count only gives you the number of particles on the local
  processor.
\item safe - Any particle\_list which a user should come across will be a safe
  particle\_list. Don't change this property.
\item next, prev - For future expansion it is possible to attach particle\_lists
  together in another linked list. This is not currently used anywhere in the
  code.
\end{itemize}

An entire species of particles is represented by another Fortran TYPE, this
time called\linebreak \inlinecode{particle\_species}. This represents all the
properties which are common to all particles in a species. There are lots
of entries which are only compiled in when compile-time flags are specified.
The definition without any such flags is:
\begin{boxverbatim}
  TYPE particle_species
    ! Core properties
    CHARACTER(string_length) :: name
    TYPE(particle_family), POINTER :: next, prev
    INTEGER :: id
    LOGICAL :: dump

    REAL(num) :: charge
    REAL(num) :: mass
    INTEGER(KIND=8) :: count
    TYPE(particle_list) :: attached_list

    ! Injection of particles
    INTEGER(KIND=8) :: npart_per_cell
    REAL(num), DIMENSION(:), POINTER :: density
    REAL(num), DIMENSION(:,:), POINTER :: temperature

  END TYPE particle_species
\end{boxverbatim}

This definition is for the 2D version of the code. The only difference for
the other two versions is the number of dimensions in the density and
temperature arrays.

\begin{itemize}
\item name - The name of the particle species, used in the output dumps etc.
\item next, prev - Particle species are also linked together in a linked
  list. This is used internally by the output dump routines, but should not be
  used by end users.
\item id - The species number for this species. This is the same number as is
  used in the input deck to designate the species.
\item dump - Flag to determine wether or to include this species in output
  dumps. Note that the flag is ignored for restart dumps.
\item charge - The charge in Coulombs. Even if PER\_PARTICLE\_CHARGEMASS is
  specified, this is still populated from the input deck, and now refers to
  the reference charge for the species.
\item mass - The mass in kg.
\item count - The global number of particles of this species (NOTE may not
  be accurate). This will only ever be the number of particles on this
  processor when running on a single processor. While this property will be
  accurate when setting up initial conditions, it is only guaranteed to be
  accurate for the rest of the code if the code is compiled with the correct
  preprocessor options.
\item attached\_list - The list of particles which belong to this species.
\end{itemize}

The last three entries are only used by the particle injection model.

\subsubsection{Setting the particle properties}
The details of exactly what a linked list means in {\EPOCH} is described
in the developers manual. For now, all we really need to know is that each
species has a list of particles. A pointer to the first particle in the list
is contained in #species_list(ispecies)%attached_list%head#. Once you have
a pointer to a particle (eg. #current#), you advance to the next pointer in
the list with #current => current%next#.

After all the descriptions of the types, actually setting the properties of
the particles is fairly simple. The following is an example which positions
the particles correctly in 1D space, but doesn't set any momentum.
\begin{boxverbatim}
SUBROUTINE manual_load

  TYPE(particle), POINTER :: current
  INTEGER :: ispecies
  REAL(num) :: rpos, dx

  DO ispecies = 1, n_species
    current => species_list(ispecies)%attached_list%head
    dx = length_x / species_list(ispecies)%attached_list%count
    rpos = x_min
    DO WHILE(ASSOCIATED(current))
      current%part_pos = rpos
      current%weight = 1.0_num
      rpos = rpos + dx
      current => current%next
    ENDDO
  ENDDO

END SUBROUTINE manual_load
\end{boxverbatim}

This will take the particles which have been placed at random positions
by the autoloader and repositions them in a uniform manner. In order to
adjust the particle positions, you need to know about the grid used in
{\EPOCH}. In this example we only required the length of the domain,
``length\_x'' and the minimum value of x, ``x\_min''. A more exaustive
list is given in the following section. Note that
I completely ignored the question of domain decomposition when setting up the
particles. The code automatically moves the particles onto the correct
processor without user interaction.

In the above example, note that particle momentum was not specified and
particle weight was set to be a simple constant. Setting particle weight can
be very simple if you can get the pseudoparticle distribution to match the
real particle distribution, or quite tricky if this isn't possible. Remember
that the weight of each pseudoparticle is the number which locally transforms
the pseudoparticle number density into the real particle number density. If
the pseudoparticle distribution matches the real particle distribution then
this is simply a constant, i.e the ratio of the number of pseudoparticles in
the domain to the number of real particles in the domain. In more complicated
cases, it is probably better to use the autoloader than to manually set up the
number density distribution.

\subsubsection{Grid coordinates used in {\EPOCH}.}

When setting up initial conditions within the {\EPOCH} source (rather than
using the input deck)
there are several constants that you may need to use. These constants are:
\begin{itemize}
\item nx - Number of gridpoints on the local processor in the x direction.
\item ny - Number of gridpoints on the local processor in the y direction (2D
  and 3D).
\item nz - Number of gridpoints on the local processor in the z direction (3D).
\item length\_\{x,y,z\} - Length of domain in the x, y, z directions.
\item \{x,y,z\}\_min - Minimum value of x, y, z for the whole domain.
\item \{x,y,z\}\_max - Maximum value of x, y, z for the whole domain.
\item n\_species - The number of species in the code.
\end{itemize}

There are also up to three arrays which are available for use.
\begin{itemize}
\item x(-2:nx+3) - Position of a given gridpoint in real units in the x
  direction.
\item y(-2:ny+3) - Position of a given gridpoint in real units in the y
  direction (2D and 3D).
\item z(-2:nz+3) - Position of a given gridpoint in read units in the z
  direction (3D).
\end{itemize}

\subsubsection{Loading a non-thermal particle distribution.}

While the autoloader is capable of dealing with most required initial thermal
distributions, you may want to set up non-thermal initial conditions. The code
includes a helper function to select a point from an arbitrary distribution
function which can be used to deal with most non-thermal distributions. To use
the helper function, you need to define two 1D arrays which are the x and
y axes for the distribution function. An example of using the helper function
is given below.
\begin{boxverbatim}
SUBROUTINE manual_load

  TYPE(particle), POINTER :: current
  INTEGER, PARAMETER :: nx_local = 100
  INTEGER :: ispecies, ix
  REAL(num) :: rpos, dx_local
  REAL(num) :: min_p, max_p, var, temperature
  REAL(num), DIMENSION(nx_local) :: x_axis, y_axis

  min_p = -3.0e-20
  max_p = 3.0e-20

  dx_local = (max_p - min_p) / REAL(nx_local-1, num) + min_p
  DO ix = 1, nx_local
    x_axis(ix) = min_p + (ix - 1) * dx_local
  ENDDO

  temperature1 = 1e4_num * kb
  temperature2 = 1e4_num
  DO ispecies = 1, n_species
    var1 = 2.0_num * kb * temperature1 * species_list(ispecies)%mass
    var2 = 2.0_num * kb * temperature2 * species_list(ispecies)%mass
    DO ix = 1, nx_local
      x2 = x_axis(ix)**2
      y_axis(ix) = EXP(-x2 / var1) + EXP(-x2 / var2)
    ENDDO
    current=>species_list(ispecies)%attached_list%head
    DO WHILE(ASSOCIATED(current))
      current%part_p(1) = sample_dist_function(x_axis, y_axis, seed)
      current=>current%next
    ENDDO
  ENDDO

END SUBROUTINE manual_load
\end{boxverbatim}

This example will set the particles to have a bump-on-tail velocity
distribution, a setup which is not possible to do using only the
input deck. It is not necessary to normalise
the distribution function, as this is done automatically by the
{\bf sample\_dist\_function} function.


\subsection{Lasers}
In the latest version of {\EPOCH}, the ability to add EM wave sources such as
lasers at boundaries has been added. To use lasers, set the boundary that you
wish to have a laser on to be of type \inlinecode{simple\_laser} and then
specify one or more lasers attached to that boundary. Lasers may be specified
anywhere initial conditions are specified.

\subsubsection{Lasers in the input deck}

To introduce a laser into the code from the input deck, you simply add a
``laser'' block for every laser that you want. It is perfectly valid to add as
many lasers as required to a boundary. A laser block looks like:
\begin{boxverbatim}
begin:laser
   boundary = x_min
   amp = 3.88191e13
   profile = exp(-(y^2))
   omega = 1.78e15
   pol_angle = 0.0
   phase = 0.0
   t_profile = 1.0
   t_start = 0.0
   t_end = end
   id = 1
end:laser
\end{boxverbatim}

\begin{itemize}
\item boundary - The boundary on which to attach the laser. Options are x\_min,
  x\_max, y\_min, y\_max, z\_min and z\_max. This must be the first element of
  the block. ``left'', ``right'', ``down'', ``up'', ``back'' and ``front'' are
  accepted as synonyms.
\item amp - The amplitude of the laser.
\item profile - The spatial profile of the laser. This should be a spatial
  function not including any values in the direction normal to the boundary
  on which the laser is attached, and the expression will be evaluated at the
  boundary. This is calculated at t = 0, so no time dependant part may be used.
\item omega - The frequency of the laser.
\item pol\_angle - The polarisation angle of the magnetic field of the laser
  from the ignorable direction. If pol\_angle = 0.0 then the magnetic field
  perturbation is only in bz.
\item pol\_angle - Polarisation angle for the electric field of the laser in
  radians. This parameter is optional and has a value of zero by default.
  The angle is measured with respect to the right-hand triad of propagation
  direction, electric and magnetic fields. If the laser is on
  \inlineemph{x\_min} then the default $E$ field is in the $y$-direction and
  the $B$ field is the $z$-direction. The polarisation angle is measured
  clockwise about the $x$-axis with zero along the $y$-axis.\\
  Similarly, for propagation directions:\\
\inlineemph{y\_min} - angle about $y$-axis, zero along $z$-axis\\
\inlineemph{z\_min} - angle about $z$-axis, zero along $x$-axis\\
\inlineemph{x\_max} - angle anti-clockwise about $x$-axis, zero along $y$-axis\\
\inlineemph{y\_max} - angle anti-clockwise about $y$-axis, zero along $z$-axis\\
\inlineemph{z\_max} - angle anti-clockwise about $z$-axis, zero along $x$-axis
\item phase - The phase profile of the laser wavefront. Once again this is
  calculated at t = 0, so no time dependant part may be used.
\item t\_profile - The temporal profile of the laser. This is calculated at
  each timestep, but you cannot specify spatial information. If this is not
  specified then the code will attempt to get a temporal profile using the
  \inlinecode{custom\_laser\_time\_profile} subroutine inside the code.
\item t\_start - The time at which to start applying the laser. Can be
  ``start'' to just start at the beginning of the simulation.
\item t\_end - The time at which to stop applying the laser. Can be ``end'' to
  just end when the simulation finishes.
\item id - A user supplied id which identifies a laser. This does not have to
  be unique, and is only used when specifying temporal profiles inside the
  code.
\end{itemize}

If you add multiple laser blocks to the initial conditions file then the
multiple lasers will be additively combined on the boundary.

\subsubsection{Lasers in the internal initial conditions}
You can add lasers at any point in the internal initial conditions routines,
using the internal representation of a laser in the code, which is a Fortran
TYPE called \inlinecode{laser\_block}.
\begin{boxverbatim}
  TYPE laser_block
    ! Boundary to which laser is attached
    INTEGER :: boundary
    ! A unique id number for the laser (not used directly by EPOCH)
    ! Only used if hard coding time profiles
    INTEGER :: id
    REAL(num), DIMENSION(:), POINTER :: profile
    REAL(num), DIMENSION(:), POINTER :: phase

    LOGICAL :: use_time_function
    TYPE(primitive_stack) :: time_function

    REAL(num) :: amp, omega, pol_angle, angle, t_start, t_end

    TYPE(laser_block), POINTER :: next
  END TYPE laser_block
\end{boxverbatim}
Most of these items are the same as their equivalents in the input deck and
are set in the same way. The detailed description is
\begin{itemize}
\item direction - The boundary on which the laser is attached. This is
  automatically set when the laser is attached to a boundary.
\item id - Exactly the same as the id property from the input deck.
\item profile - The spatial profile for the laser. The array is allocated by
  the initial call to \inlinecode{init\_laser} and must be populated between
  (1:nx) for a boundary on the top or bottom, or (1:ny) for a boundary on the
  left or right.
\item phase - The phase of the wavefront for the laser. See profile.
\item use\_time\_function - A logical variable which tests whether to use an
  input deck specified time profile or a hard coded profile. If you're setting
  up a laser inside the code, this should be false.
\item time\_function - The Parser Stack which represents the temporal profile of
  the laser if specified in the input deck. Don't set it to anything if
  specifying an internal initial condition.
\item amp, omega, pol\_angle etc. - The same as in the input deck.
\end{itemize}

To actually set up a laser is fairly simple, as shown below. The following
code creates a laser and attaches it to the left hand boundary and would
be placed in the ``manual\_load'' routine.
\begin{boxverbatim}
  TYPE(laser_block), POINTER :: new_laser

  ALLOCATE(new_laser)
  CALL init_laser(new_laser, c_bd_x_min)
  new_laser%amp = 3.88191e13_num
  new_laser%omega = 1.78e15_num
  new_laser%id = 1
  new_laser%phase = 0.0_num
  DO iy = 1, ny
    new_laser%profile(iy) = exp(-y(iy)**2)
  ENDDO

  CALL attach_laser(new_laser)
\end{boxverbatim}
After the call to \inlinecode{attach\_laser} the laser is attached to the
correct boundary. Since new\_laser is a pointer, it is valid to then reallocate
the same variable again to create and attach further lasers. It is valid to
delete a laser without attaching it, although obviously the laser is lost. It
is not valid to call \inlinecode{laser\_init} on an already initialised laser.

\subsubsection{Internal laser time profiles}
If you specify a laser's time profile in the input deck then you need take no
further action. However, if you specify a laser within the code or wish to
have more control, you can specify the laser time profile internally. In this
case, the relevant function is in
\inlinecode{user\_interaction/custom\_laser.f90}.
\begin{boxverbatim}
FUNCTION custom_laser_time_profile(laser)

  TYPE(laser_block), INTENT(IN) :: laser
  REAL(num) :: custom_laser_time_profile

  IF (laser%id .EQ. 1) THEN
    custom_laser_time_profile = 1.0
  ELSE
    custom_laser_time_profile = EXP(-((time-1.0e-12_num)/1.0-e13_num)**2)
  ENDIF

END FUNCTION custom_laser_time_profile
\end{boxverbatim}
The function returns just the time profile part of the laser and the
amplitude specified when the laser is set up is still applied, so normally you
would want custom\_laser\_time\_profile to run between 0 and 1.

\subsection{Distribution functions}
PIC codes effectively represent a Lagrangian Monte-Carlo sampling of the phase
space of Vlasov's equation. Sometimes it is useful to reconstruct part of the
full phase space. This is controlled by the distribution function option.
Distribution function output can be specified in any of the initial conditions
sections of the main code.

\subsubsection{Distribution function units}
Calculating distribution functions requires some degree of integration of data
leading to various possible ways of normalising the resulting distribution
function. In {\EPOCH}, distribution functions are normalised so that the value
at every point of the distribution function is the number of particles within
that cell of the distribution function, ignoring all phase space directions
which are not considered as an axis of the distribution function. Summing the
distribution function should give the total number of real particles
(as opposed to computational pseudo-particles) in the
simulation.

\subsubsection{Distribution function limitations}
At present, the code to calculate the distribution functions has one
limitation: it ignores particle shape functions when calculating properties
on the spatial axis, meaning that the result is less smooth than normal
properties from the code. This will be improved in a future release.

\subsubsection{Distribution functions in the input deck}
\begin{boxverbatim}
begin:dist_fn
   name = x_px
   ndims = 2
   dumpmask = always

   direction1 = dir_x
   direction2 = dir_px

   # range is ignored for spatial coordinates
   range1 = (1,1)
   range2 = (-3.0e-20,3.0e-20)

   restrict_py = (-3.0e-20,3.0e-20)

   # resolution is ignored for spatial coordinates
   resolution1 = 1
   resolution2 = 100

   include_species:s1
   include_species:s2
end:dist_fn
\end{boxverbatim}
\begin{itemize}
\item name - The name that the distribution function should have in output
  dumps.
\item ndims - The number of dimensions that the distribution function should
  have. Currently only 2 or 3 are valid numbers.
\item direction\{n\} - For each dimension specified in {\bf ndims} it is
  necessary to specify the direction of the full phase space which corresponds
  to the axis. Valid directions are: dir\_x, \{dir\_y\}, \{dir\_z\}, dir\_px,
  dir\_py, dir\_pz. Spatial directions are only valid in high enough dimension
  codes, i.e. EPOCH1D only has a valid dir\_x.
\item range\{n\} - The range of this dimension, specified as ({\it lower},{\it
    upper}). This is ignored for spatial dimensions. Any particle which exceeds
  the range is ignored.
\item resolution\{n\} - The number of gridpoints in each dimension. This
  number is ignored for any specified spatial dimension, due to the
  requirements of the parallelism scheme of {\EPOCH}.
\item restrict\_\{x,y,z,p\_x,p\_y,p\_z\} - Restrictions are specified in the
  same way as ranges, but have a subtly different behaviour. Ranges specify
  the range of a visible axis on the resulting distribution function, whereas
  restrictions allow you to specify a valid window of particle properties even
  for properties which are not being used as axes. It is possible to set a
  restriction that is more restrictive than the range applied. This is not
  trapped as an error and such parts of the distribution function are
  guaranteed to be empty.
\item include\_species - Whether to calculate the distribution function
  for this species.
\end{itemize}

\subsection{Particle Probes}
Sometimes it is useful to consider all the properties of particle which pass
through a point/line/plane (depending on dimension) in the simulation. To
allow this, it is possible to specify one or more {\it Particle Probe} blocks
in the input deck. These record copies of all particles which cross a
point/line/plane in a given direction which meet minimum and maximum kinetic
energy criteria and output the particle properties into the normal output
files. Particle probes record the positions, momenta and weight of all
particles passing through the plane. To use particle probes, the code must be
compiled with the \inlinecode{-DPARTICLE\_PROBES} compiler option. This is
a fairly heavyweight diagnostic since each particle position must be tested
from within the particle push. The code will run faster if it is not compiled
in.\\

The probe is specified in terms of a point in the plane and the normal
vector to the plane which is to be monitored. In 2D these are both 2D
vectors and in 1D they are just constants. Particles are only recorded
if they cross the plane in the direction given by the normal vector.
If you want to record particles travelling in both directions then use two
particle probes, one with an opposite signed normal vector to the other.

\subsubsection{Particle probes in the input deck}
\begin{boxverbatim}
begin:probe
   name = electron_back_probe

   point = (50.0e-6, -50.0e-6)
   normal = (1.0, 0.0)

   probe_species:s1
   ek_min = 0.0
   ek_max = -1.0

   dump = always
end:probe
\end{boxverbatim}
\begin{itemize}
\item name - The name that the probe should have in output dumps. Output
  variables are then named this as a prefix. For example, the block shown above
  will result in the name\linebreak \inlinecode{electron\_back\_probe\_px} for
  the x momentum. The particle positions would just be called\linebreak
  \inlinecode{electron\_back\_probe}.
\item point - An arbitrary point in the plane of the probe.
\item normal - A vector normal to the plane of the probe, in the direction
  of crossings you wish to monitor.
\item probe\_species - The species to which this probe should be
  applied. To probe several species, use several probe blocks in the input
  deck.
\item ek\_min - The minimum kinetic energy of particles to store information
  about. Set to 0 for no minimum kinetic energy.
\item ek\_max - The maximum kinetic energy of particles to store information
  about. Set to -1 for no maximum kinetic energy.
\item dump - The dump code for this particle probe. This is the same as that
  for the main output controls in \inlinecode{input.deck}. Note that the code
  has to store copies of particles which pass through the probe until a dump
  occurs. This means that the code's memory requirements can increase
  drastically if this code only dumps probe information infrequently. If this
  is set to \inlinecode{never} then the code effectively never uses the probe.
\end{itemize}

\subsection{Restarting {\EPOCH} from previous output dumps}
Another possible way of setting up initial conditions in {\EPOCH} is to load in
a previous output dump and use it to specify initial conditions for the
code. The effect of this is to restart the code from the state that it was in
when the dump was made. To do this, you just
set the field ``restart\_snapshot'' to
the number of the output dump from which you want the code to restart. Because
of the way in which the code is written you cannot guarantee that the code will
successfully restart from any output dump. To restart properly, the
following {\it must} have been dumped
\begin{itemize}
\item Particle positions.
\item Particle momenta.
\item Particle species.
\item Particle weights.
\item Relevant parts of the electric field (If for example it is known that
  ez == 0 then it is not needed).
\item Relevant parts of the magnetic field.
\end{itemize}
Since the autoloader completely changes the position of particles etc. it is
not possible to combine restart dumps with {\it any} of the autoloader
routines. It is possible to use the manual particle control part of the
initial conditions to make changes to a restarted initial condition after the
restart dump is loaded. The output files don't include all of the information
needed to restart the code fully, but a restart dump will contain a full copy
of the relevant input deck files which can be unpacked before running the
code. In future the code may well be changed to allow full restart from
output files.\\

If specific ``restart'' dumps are specified in the input deck, or the
``force\_final\_to\_be\_restartable'' flag is set then in some cases the
output is forced to contain enough information to output all the data. These
restart dumps can be very large, and also override the ``dump'' parameter
specified for a species and output the data for that species anyway.

\newpage

\subsection{Parameterising input decks}
\label{sec:customising}
The simplest way to allow someone to use {\EPOCH} as a black box is to give them
the input.deck files that control the setup and initial conditions
of the code. The input deck is simple enough that a quick read through of the
relevant section of the manual should make it fairly easy for a new user to
control those features of the code, but the initial conditions can be complex
enough to be require significant work on the part of an unfamiliar user to
understand. In this case, it can be helpful to use the ability to specify
constants in an input deck to parameterise the file. So, to go back to a slight
variation on an earlier example:
\begin{boxverbatim}
begin:species
   name = s1

   # first set density in the range 0->1
   # cut down density in x direction
   number_density = if ((x gt -1) and (x lt 1),1.0,0.2)
   # cut down density in y direction
   number_density = if ((y gt -1) and (y lt 1),number_density(s1),0.2)

   # multiply density by real particle density
   number_density = number_density(s1)*100.0

   # Set the temperature to be zero
   temp_x = 0.0
   temp_y = temp_x(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*100.0
end:species

begin:species
   name = s2

   # Just copy the density for species s1
   number_density = number_density(s1)

   # Just copy the temperature from species s1
   temp_x = temp_x(s1)
   temp_y = temp_y(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*100.0
end:species
\end{boxverbatim}

The particle density (100.0) is hard coded into the deck file in several
places. It would be easier if this was given to a new user as:
\begin{boxverbatim}
begin:constant
   particle_density = 100.0 # Particle number density
end:constant

begin:species
   name = s1

   # first set density in the range 0->1
   # cut down density in x direction
   number_density = if ((x gt -1) and (x lt 1),1.0,0.2)
   # cut down density in y direction
   number_density = if ((y gt -1) and (y lt 1),number_density(s1),0.2)

   # multiply density by real particle density
   number_density = number_density(s1)*particle_density

   # Set the temperature to be zero
   temp_x = 0.0
   temp_y = temp_x(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species

begin:species
   name = s2

   # Just copy the density for species s1
   number_density = number_density(s1)

   # Just copy the temperature from species s1
   temp_x = temp_x(s1)
   temp_y = temp_y(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species
\end{boxverbatim}

It is also possible to parameterise other elements of initial conditions in a
similar fashion. This is generally a good idea, since it makes the
initial conditions easier to read an maintain.

\subsection{Using spatially varying constants to further parameterise
  initial conditions}

Again, this is just a readability change to the normal input.deck file, but it
also makes changing and understanding the initial conditions rather
simpler. In this case, entire parts of the initial conditions are moved into a
spatially varying constant in order to make changing them at a later date
easier. For example:
\begin{boxverbatim}
begin:constant
   particle_density = 100.0 # Particle number density
   profile_x = if((x gt -1) and (x lt 1),1.0,0.2)
   profile_y = if((y gt -1) and (y lt 1),1.0,0.2)
end:constant

begin:species
   name = s1

   # multiply density by real particle density
   number_density = particle_density * profile_x * profile_y

   # Set the temperature to be zero
   temp_x = 0.0
   temp_y = temp_x(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species

begin:species
   name = s2

   # Just copy the density for species s1
   number_density = number_density(s1)

   # Just copy the temperature from species s1
   temp_x = temp_x(s1)
   temp_y = temp_y(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species
\end{boxverbatim}

This creates the same output as before. It is now trivial to modify the
profiles later. For example:
\begin{boxverbatim}
begin:constant
   particle_density = 100.0 # Particle number density
   profile_x = gauss(x,0.0,1.0)
   profile_y = gauss(y,0.0,1.0)
end:constant

begin:species
   name = s1

   # multiply density by real particle density
   number_density = particle_density * profile_x * profile_y

   # Set the temperature to be zero
   temp_x = 0.0
   temp_y = temp_x(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species

begin:species
   name = s2

   # Just copy the density for species s1
   number_density = number_density(s1)

   # Just copy the temperature from species s1
   temp_x = temp_x(s1)
   temp_y = temp_y(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species
\end{boxverbatim}

This changes the code to run with a Gaussian density profile rather then a step
function. Again, this can be extended as far as required.

\include{idl_visit}

%\includepdf{images/title_page_dev}
{
  \fontfamily{phv}\selectfont\input{epoch_dev_title}
}
\fontfamily{garamond}\selectfont%
\newpage%

\section{{\EPOCH} developers manual}

This section of the manual is aimed at people who intend to edit the {\EPOCH}
source code to extend or modify existing features, add new diagnostics or
develop new physics packages. It is expected that anyone reading this part of
the manual will be familiar with the material covered in the main manual,
particularly the notices about the layout of particle, particle\_list and
particle\_species structures in \sect{partrep} of the user manual.

A quick note: Some files have the normal Fortran file extension .f90, while
some have the slightly unusual .F90. The difference is that files with the
.F90 extension are passed through the preprocessor before they are compiled
allowing the use of precompiler directives (the \#ifdef commands).

\scaledcapimage{./images/coreblock}{coreblock}{Block diagram of the core
  routines in {\EPOCH}}{0.5}

\section{General layout of the {\EPOCH} code}

The names of the source files in {\EPOCH} are fairly self explanatory but, for
clarity, they are explained here.

\subsection{Directories}
All source files are contained in the \inlinecode{src} directory and its
subdirectories. There is a stylistic reason for the layout of the files, which
is explained here

\begin{itemize}
\item \inlinecode{src} - Files in this directory are the core files for the
  basic {\EPOCH} code, such as the field solvers, the particle pusher, the
  boundary conditions and the lasers.
\item \inlinecode{src/deck} - Files in this directory are responsible for
  dealing with the permanent input deck parser and include the core parts of
  the deck handler, and also the routines which deal with the blocks in the
  input deck files.
\item \inlinecode{src/housekeeping} - Files in this directory deal with those
  parts of the code operation which are not physics; including the load
  balancer, the MPI setup routines and the moving window.
\item \inlinecode{src/include} - This directory contains the shape function
  code fragments which are inserted into the particle push at compile time.
\item \inlinecode{src/io} - The files involved in all I/O activities, including
  the distribution functions and the particle probes.
\item \inlinecode{src/parser} - The files for the maths expression parser are
  in this directory, including both the core implementation of the shunting yard
  algorithm and the routines for implementing the permanent functions,
  constants and operators for the input deck.
\item \inlinecode{src/physics\_packages} - Contains routines which implement
  additional physics for the code.
\item \inlinecode{src/user\_interaction} - Contains any Fortran routines which
  a user has to modify to use the code with internal initial conditions, or to
  temporarily extend the maths parser or the input deck.
\end{itemize}


\subsection{The files in \inlinecode{src}}
\begin{itemize}
\item boundary.f90 - Includes all boundary conditions except laser and
  transmissive boundaries; including field and particle MPI boundaries, and
  field and particle domain boundaries.
\item epoch\{n\}d.F90 - Main driver for the code. Reading this routine gives
  the basic layout of the code flow.
\item fields.f90 - The Maxwell field solver.
\item laser.f90 - Includes laser and transmissive boundary conditions for each
  boundary and also the housekeeping routines for the laser objects.
\item particles.F90 - The particle pusher.
\item shared\_data.F90 - This file includes all the global variable and type
  definitions. Usually new variables should be defined in this file.
\item gen\_commit\_string - This is a script used to generate an ID string
  when compiling the code.
\item gen\_src\_module - This is a script which is used at build time to
  generate a Fortran module containing the source code. This is used for
  embedding the {\EPOCH} source code into restart dumps.
\end{itemize}

\subsection{The files in \inlinecode{src/deck}}
\begin{itemize}
\item deck.F90 - The main input deck routines. Deals with opening files,
  reading data and MPI distribution of the data to all processes. Also
  includes the routines which deal with calling the right reader routines to
  deal with a given block.
\item deck\_boundaries\_block.f90 - Reader routine for the ``boundaries'' block
  of the input deck.
\item deck\_constant\_block.f90 - Reader routine for ``constants'' blocks in the
  input deck.
\item deck\_control\_block.f90 - Reader routine for ``control'' block in the
  input deck.
\item deck\_eio\_dist\_fn\_block.f90 - Reader routine for ``dist\_fn'' blocks in
  the input deck.
\item deck\_eio\_particle\_probe\_block.f90 - Reader routine for
  ``particle\_probe'' blocks in the input deck.
\item deck\_ic\_fields\_block.f90 - Reader routine for ``fields'' blocks in the
  input deck.
\item deck\_ic\_laser\_block.f90 - Reader routine for ``laser'' blocks in the
  input deck.
\item deck\_ic\_species\_block.f90 - Reader routine for ``species'' blocks in
  the input deck.
\item deck\_io\_block.F90 - Reader routine for the ``io'' block in the input
  deck.
\item deck\_species\_block.F90 - Reader routine for the ``species'' block in the
  input deck.
\item deck\_window\_block.f90 - Reader routine for the ``window'' block in the
  input deck.
\item strings.F90 - Basic string handling routines such as ``str\_cmp'' and
  routines for converting strings to numbers WITHOUT using the maths parser
  are covered in this routine.
\item strings\_advanced.F90 - The routines which pass maths along to the maths
  parser routines are here.
\end{itemize}

\subsection{The files in \inlinecode{src/housekeeping}}
\begin{itemize}
\item balance.F90 - Contains the routines for the load balancer and related
  routines.
\item current\_smooth.F90 - Contains the current smoothing routines.
\item dummy\_encoded\_source.f90 - A dummy module used when the code is
  being built without the ability to write the source code into restart dumps.
\item mpi\_routines.F90 - Contains the routines dealing with the setup of the
  MPI layer and the creation of the communicator. Also allocates all arrays
  for the first time before load balancing.
\item mpi\_subtype\_control.F90 - Contains the routines that setup the mpi
  types required by the I/O subsystem.
\item particle\_pointer\_advance.F90 - Contains subroutines which walk through
  the lists of particles and species for I/O purposes.
\item partlist.F90 - Contains the routines which deal with the particle lists
  which are used for inter-processor communication of particles.
\item setup.F90 - Deals with the setup of the grids and domains and restarting
  from previous output dumps.
\item shape\_functions.F90 - Contain the particle shape functions used for
  calculating the particle weighting.
\item split\_particles.F90 - Is the implementation of a demonstration of
  particle splitting routines.
\item utilities.f90 - Contains growable arrays used by the species block parser.
\item version\_data.F90 - Contains version information for the current {\EPOCH}
  code.
\item welcome.F90 - The routine which prints the banner message and compiler
  options info.
\item window.F90 - The routines which deal with the moving window.
\end{itemize}

\subsection{The files in \inlinecode{src/io}}
\begin{itemize}
\item calc\_df.F90 - Despite the slightly confusing name, this subroutine
  deals with derived functions like number density, charge density and mass
  density.
\item diagnostics.F90 - Contains the routines which actually dump the data,
  decide what to dump and also the routine to calculate the timestep.
\item dist\_fn.F90 - Contains the routines to calculate the distribution
  functions, and also the routines handling the requests for distribution
  functions.
\item iterators.f90 - Contains the iterator functions used to write particle
  data into SDF files.
\item probes.F90 - Contains the routines which write the data from the
  particle probes. Also includes the routines which deal with user requests to
  add new particle probes.
\item sdf\_common.f90 - Core part of the SDF file format. Contains constants and
  definitions needed by the SDF format. If attempting to implement a SDF
  reader then look here for values of named constants.
\item sdf\_control.f90 - Core part of the SDF file format. Contains the routines
  needed to open and close files etc.
\item sdf.f90 - Module interface for the SDF file format. This file specifies
  the application interface to the SDF library.
\item sdf\_input.f90 - Core part of the SDF file format. Contains the general
  routines needed for reading data from SDF files.
\item sdf\_input\_cartesian.f90 - Core part of the SDF file format. Contains the
  routines needed to read Cartesian meshes and variables from SDF files.
\item sdf\_input\_functions.f90 - Core part of the SDF file format. Contains the
  routines needed to traverse the block structure of a SDF file without
  reading any block specific metadata.
\item sdf\_input\_point.f90 - Core part of the SDF file format. Contains the
  routines needed to read particles meshes and variables from SDF files.
\item sdf\_input\_util.f90 - Core part of the SDF file format. Contains
  general routines for reading the block structure of SDF files.
\item sdf\_job\_info.f90 - Contains routines for generating a unique job-id for
  each simulation run.
\item sdf\_output.f90 - Core part of the SDF file format. Contains the basic
  routines needed to write data to a SDF file.
\item sdf\_output\_cartesian.f90 - Core part of the SDF file format. Contains
  the routines needed to write Cartesian meshes and variables.
\item sdf\_output\_point.f90 - Core part of the SDF file format. Contains the
  routines needed to write particles meshes and variables.
\item sdf\_output\_util.f90 - Core part of the SDF file format. Contains
  general routines for writing the block structure of SDF files.
\item simple\_io.F90 - Contains routines for performing the simple binary I/O
  required by species\_external and fields\_external blocks.
\end{itemize}

\subsection{The files in \inlinecode{src/parser}}
\begin{itemize}
\item evaluate.f90 - Contains the routines which actually evaluate a tokenized
  expression. The core of this is a simple implementation of an RPN
  calculator.
\item evaluator\_blocks.f90 - Contains the routines which evaluate a given
  token into a numerical values. Actually implements the functions, constants
  and operators in {\EPOCH}'s maths parser.
\item shunt.F90 - {\EPOCH}'s implementation of the ``shunting yard'' algorithm
  used to simultaneously tokenize the input and convert it from infix notation
  to RPN.
\item stack.f90 - Deals with routines for pushing onto and popping off
  stacks.
\item tokenizer\_blocks.f90 - Deal with converting strings found in a string
  being tokenized into tokens. Essentially a large collection of ``str\_cmp''
  commands testing a string against a known name.
\end{itemize}

\subsection{The files in \inlinecode{src/physics\_packages}}
\begin{itemize}
\item ionise.F90 - This is a demonstration of how to implement a physics
  package. It implements a field ionisation routine using a 1 level Saha
  equation. It is more intended of a demonstration of how a physics package
  could be implemented that a ``research ready'' ionisation routine.
\end{itemize}

\subsection{The files in \inlinecode{src/user\_interaction}}
\begin{itemize}
\item custom\_deck.f90 - This file is where and end user can temporarily
  extend the input deck. Described in the ``\titleref{sec:customising}''
  section.
\item custom\_laser.f90 - The file where an end user specifies laser time
  profiles without using the input deck.
\item custom\_parser.f90 - The file where an end user can temporarily add new
  functions and constants to the input deck. It is described in the
  ``\titleref{sec:customising}'' section of this manual.
\item helper.F90 - This file contains all the internal workings of the
  autoloader. This is in user\_interaction for historical reasons, since early
  versions of the code required the end user to modify some parts of the
  functions contained in this file. As the autoloader has increased in
  complexity, this has ceased to be the case, so it is likely that soon this
  file will be move to ``housekeeping''.
\item ic\_module.f90 - This file is where the internal and manual initial
  conditions are set.
\item particle\_temperature.f90 - Contains the routines for thermally loading
  a particle species.
\end{itemize}

\section{{\EPOCH} makefile}

The makefile supplied with {\EPOCH} is a standard GNU make makefile, which must
be user modified to allow a developer to add new files to the code. {\EPOCH}'s
makefile is quite large, so an explanation of how to add new files and new
directories is given below.

\subsection{Adding a new file to be compiled with {\EPOCH}}
There are three things that must be done to cause {\EPOCH} to compile a new
file and link it into the final code. Assume that you're adding a file called
``newfile.F90''. First, find the line which sets the environment variable
\inlinecode{SRCFILES} and add a new parameter which reads\\
\\
newfile.F90\\
\\ This tells the makefile to compile the final code using your new file, the
next thing to do is to add a line which tells the code about the dependencies
for your file. Lower down in the makefile, you'll find a section with lines
which look like:
\begin{boxverbatim}
balance.o: balance.F90 boundary.o mpi_subtype_control.o partlist.o
\end{boxverbatim}
Add a new line for describing all the FILES (NOT modules) which are used by
your new file. If you USE shared\_data, mpi\_subtype\_control and stack in
your file then the line would look like:
\begin{boxverbatim}
newfile.o: newfile.F90 shared_data.o mpi_subtype_control.o stack.o
\end{boxverbatim}
Note the structure of the line with ONLY the source file for the new file
specified, all other used files specify the intermediate .o files. The
remaining element of the makefile which needs to be modified is to add your
new file as a dependency to all the files which USE modules contained in your
new file. This is achieved very simply by adding ``newfile.o'' to the dependency
list for those files which USE your modules. For example if you've written new
boundary conditions and USE your modules in boundary.F90, you'd just change
the line for boundary.F90 from:
\begin{boxverbatim}
boundary.o: boundary.f90 deck_io_block.o particle_temperature.o partlist.o
\end{boxverbatim}
to
\begin{boxverbatim}
boundary.o: boundary.f90 deck_io_block.o particle_temperature.o partlist.o \
  newfile.o
\end{boxverbatim}

Note that the backslash characters are line continuation marks in makefiles.

\subsection{Adding new directories to {\EPOCH}'s makefile}
If you want to add an entire new directory to the {\EPOCH} compile path then
you need to add it to the definition of the variable \inlinecode{VPATH}.
Remember to use the variable \inlinecode{\$(SRCDIR)} rather than hard-coding
\inlinecode{src} into the path.

\section{{\EPOCH} core programming}

{\EPOCH} is designed so that it can fairly easily be extended while still being
written in (more or less) standard Fortran90 and MPI1.2. This section details
in increasing complexity what a programmer needs to know to extend {\EPOCH} with
new diagnostics, new physics or even new core solvers. The first few entries
in this section range between style points and explanations of fairly trivial
parts of the {\EPOCH} code, but the end of this section gives an overview of how
one would perform major changes to the complete {\EPOCH} core solver.

\subsection{Physical constants}
In order to ensure that different parts of the code run at the same precision
common physical constants are defined in \inlinecode{shared\_data.F90} and any
new physical constants required by extensions to the code should be placed in
the same location. The constants available in the code are
\begin{itemize}
\item q0 - Charge on electron.
\item m0 - Rest mass of electron.
\item c - Speed of light in vacuum.
\item kb - Boltzmann's constant.
\item epsilon0 - Permittivity of free space.
\item mu0 - Permeability of free space.
\item h\_planck - Plank's constant.
\item ev - The value of an electron volt.
\end{itemize}

Any new constants required should be specified in the same place in
\inlinecode{shared\_data.F90}.

\subsection{Important variables, arrays and array length}
As well as the physical constants, there are some important variables which
you will have to use to do any development with {\EPOCH}. As a general note,
since {\EPOCH} is written with separate 1D, 2D and 3D versions, definitions will
be given for the 3D version of the code and irrelevant dimensions should just
be left out.

\subsubsection{Shape and size variables}
\begin{itemize}
\item INTEGER :: nx. ny, nz - The number of gridpoints on the current
  processor in each direction. This may change when the load balancer
  activates, so always use these variables rather than local copies.
\item INTEGER :: nx\_global, ny\_global, nz\_global - The number of gridpoints
  in each direction of the whole domain. These numbers will never change and
  will be the numbers read in from the input deck.
\item INTEGER(KIND=8) :: npart\_global - The global number of particles
  specified in the input deck. This is not updated as particles leave the
  domain through boundaries etc. so it is not guaranteed to be accurate.
\item INTEGER :: n\_species - The number of species of particles specified.
\item INTEGER :: nsteps - The maximum number of steps that the core solver
  should take.
\item INTEGER, DIMENSION(1:nproc\_{\it \{x,y,z\}}), ALLOCATABLE :: cell\_{\it
    \{x,y,z\}}\_start, cell\_{\it \{x,y,z\}}\_end.
\item INTEGER :: data\_dir\_max\_length - The maximum number of characters in
  the name of the output directory.
\item INTEGER :: n\_zeros - The number of leading zeros in the output filenames
  from {\EPOCH}.
\end{itemize}
The variables \inlinecode{cell\_{\it \{x,y,z\}}\_start} and
\inlinecode{cell\_{\it \{x,y,z\}}\_end} represent the part of a global array
which is held by the current processor. Since {\EPOCH} is an MPI code, there
doesn't exist a single copy of any of the global arrays anywhere, but if there
did then each processor would be responsible for the slice which runs\\
(cell\_x\_min(rank):cell\_x\_max(rank),
cell\_y\_min(rank):cell\_y\_max(rank),
cell\_z\_min(rank):cell\_z\_max(rank))\\
These variables are used internally in the load balancer, where it is updated,
but is also used when calculating distribution functions. Here it is used to
define the extents of the MPI type which is used to write the distribution
function to disk.

\subsubsection{Input deck variables}
\begin{itemize}
\item CHARACTER(LEN=entry\_length) :: blank - A special string which the input
  deck parser uses to indicate that it's passing a blank string rather than a
  string read from the deck which just happens to be blank.
\item INTEGER :: deck\_state - An integer determining which type of input deck
  is being read by the deck parser.
\item INTEGER, PARAMETER :: num\_vars\_to\_dump - A variable describing the
  number of variables which should be selectable in the input deck as possible
  variables to dump.
\item CHARACTER(LEN=entry\_length) :: extended\_error\_string - String used by
  some error codes in the deck parser to give more user friendly error
  messages.
\item CHARACTER(LEN=entry\_length) :: project\_name - String read from the
  input deck and written into the output files to allow the project to be
  recognised by a reader.
\end{itemize}

\subsubsection{Initial conditions (autoloader) variables}
Initial conditions for the autoloader for a given species are described in
{\EPOCH} by the Fortran TYPE \inlinecode{initial\_conditions\_block}. The
definition (in 3D) is:
\begin{boxverbatim}
TYPE initial_condition_block
  REAL(num), DIMENSION(:,:,:), POINTER :: den
  REAL(num), DIMENSION(:,:,:,:), POINTER :: temp
  REAL(num), DIMENSION(:,:,:,:), POINTER :: drift

  REAL(num) :: number_density_min
  REAL(num) :: number_density_max
END TYPE initial_condition_block
\end{boxverbatim}

In 2D, the arrays have one fewer index, and in 1D they have two fewer.

\begin{itemize}
\item REAL(num) :: den - Number density for the particles in the species. When
  defined runs (-2:nx+3,-2:ny+3,-2:nz+3).
\item REAL(num) :: temp - Temperature in Kelvin of the species in space. When
  defined runs (-2:nx+3,-2:ny+3,-2:nz+3,1:3). The final index of the array
  is a direction index, used to give anisotropic thermal distributions.
\item REAL(num) :: drift - Velocity drift in $m/s$ of the species in space. When
  defined runs (-2:nx+3,-2:ny+3,-2:nz+3,1:3). The final index of the array
  is the velocity direction component.
\item number\_density\_min - The minimum density below which the autoloader
  should not load particles.
\item number\_density\_max - The maximum density above which the autoloader
  should clip the density function.
\end{itemize}

The initial conditions themselves are in the variable
\begin{boxverbatim}
TYPE(initial_condition_block), DIMENSION(:), ALLOCATABLE :: initial_conditions
\end{boxverbatim}
which is allocated to an array of size \inlinecode{1:n\_species}.

\subsubsection{Linked Lists}
Linked lists are a standard computer programming technique which is still
slightly unusual in Fortran, and may well be unfamiliar to many Fortran
programmers. They effectively allow you to have an array of arbitrary length,
although this comes with various trade-offs about memory locality and speed of
accessing elements. The general concept is that of a chain where each link in
the chain only knows about the previous link in the chain and the next link in
the chain. Although there are schemes for doing this in languages which don't
have pointers, the normal method of implementing linked lists is to use
pointers to point to previous and next elements in the list, and this is how
they are implemented in {\EPOCH}. Since both linked lists and Fortran pointers
are slightly esoteric concepts, while being key to the operation of {\EPOCH} a
brief overview of them is presented here.\\

The simplest possible form of a linked list element would be a TYPE which
looks like:
\begin{boxverbatim}
TYPE linked_list
  TYPE(linked_list), POINTER :: next
  TYPE(linked_list), POINTER :: prev
END TYPE linked_list
\end{boxverbatim}

You also have to have a pointer to the start of the list, and to speed up
adding new elements to the list, you normally also keep a pointer to the
last element of the list. Therefore, you would also have variables which look
like:
\begin{boxverbatim}
TYPE(linked_list) :: head, tail
\end{boxverbatim}

Since Fortran pointers are not initialised in any particular state, you have
to remember to set the head and tail pointers to explicitly point nowhere
(normally called a null pointer by analogy with the older C style
pointers). This is done using the nullify command.
\begin{boxverbatim}
NULLIFY(head)
NULLIFY(tail)
\end{boxverbatim}

The same thing is important when creating a new linked list element, so you
would normally have a creation function for linked list elements.
\begin{boxverbatim}
SUBROUTINE create_element(element)

  TYPE(linked_list), POINTER :: element

  ALLOCATE(element)
  NULLIFY(element%next)
  NULLIFY(element%prev)

END SUBROUTINE create_element
\end{boxverbatim}
Note that the allocate function can be used on pointers in the same way that
it can be used with variables which have the allocatable attribute. However,
there is one important difference between a pointer and an allocatable
variable. If you attempt to allocate an already allocated variable which has
the allocatable attribute then the code will fail, whereas allocating an
already allocated pointer is perfectly valid, and will allocate the new
variable and point the pointer to it. This does not deallocate the memory that
the pointer previously pointed to, and Fortran does not have a ``garbage
collector'' which deallocates memory no longer accessible. So if you
allocate a pointer which already points to a variable, it is very important
that you have another pointer somewhere which points to the same memory. Once
you no longer have a pointer to an area of memory, that area of memory is
completely inaccessible and cannot even be deallocated. This is termed a
memory leak and for programs which run for many cycles and have a memory leak
on each cycle, the entire memory can very quickly be used up.

So, to add a new element to the list you would have a subroutine which looks
like:
\begin{boxverbatim}
SUBROUTINE add_element(element)

  TYPE(linked_list), POINTER :: element

  IF (.NOT. ASSOCIATED(head)) THEN
    ! Adding first element to list, so just set
    ! both head and tail to the element
    head=>element
    tail=>element
    RETURN
  ENDIF

  tail%next=>element
  element%prev=>tail
  tail=>element

END SUBROUTINE add_element
\end{boxverbatim}
This subroutine adds the new Fortran operator of ``$=>$'' which means ``points
to''. Unlike C or similar languages, Fortran pointers try to be partially
transparent to the end user, so the following code would fail:
\begin{boxverbatim}
PROGRAM test

  REAL, TARGET :: a = 10.0
  REAL, POINTER :: b

  b = a

END PROGRAM test
\end{boxverbatim}

This happens because Fortran will try to copy the value of ``a'' into ``b''.
However, ``b'' is a pointer which hasn't been initialised, so the code will
crash when it tries to copy the data in (in theory, the code may not crash if
the uninitialised ``b'' pointer happens to point somewhere in memory which is
a valid target, but this is very unlikely). Note also that ``a'' has the
attribute ``TARGET''. The target attribute means that it is possible to point
a pointer to this variable. You can only point a pointer to a variable which
is either a pointer itself or has the target attribute. This is to try and
keep Fortran pointers ``safer'' than C style pointers. The correct code would
use \inlinecode{b$=>$a}, at which point ``b'' is set to point to ``a'' and
can then be used everywhere in place of ``a''.

So, to set up a linked list of n elements, you would use the following code:
\begin{boxverbatim}
TYPE(linked_list), POINTER :: new
NULLIFY(new)

DO i = 1,n
  CALL create_element(new)
  CALL add_element(new)
ENDDO
\end{boxverbatim}

To then run through the elements of your newly created linked list, you would
use code like:
\begin{boxverbatim}
TYPE(linked_list), POINTER :: current

current=>head
DO WHILE(ASSOCIATED(current))
  ! Do stuff
  current=>current%next
ENDDO
\end{boxverbatim}

This code snippet introduces one new function ``ASSOCIATED'', which tells you
whether a pointer is a null pointer or not (this is why it is so important to
nullify new pointers, because ASSOCIATED on its own doesn't check whether a
pointer is valid, just whether or not it is a null pointer). You can also use
ASSOCIATED to check whether a pointer points to a particular object or not, in
which case the syntax is #RESULT = ASSOCIATED(b, TARGET=a)#, which
returns true if ``b'' points to ``a'', or false if it doesn't, even if ``b''
is a valid pointer pointing to something else. It also introduces the way in
which you must use linked lists in {\EPOCH}. The execution flow is as follows
\begin{itemize}
\item Point current to the current element to the start of the linked list
  (head).
\item Iterate while current points to a valid element.
\item Perform whatever actions you want on current.
\item Point current to the next element in the chain.
\end{itemize}
This leads to the slightly counter intuitive behaviour where even though the
loop only acts on the variable named ``current'', all of the elements in the
list are operated on. Although there are many tricks which can be performed
with linked lists, the only other aspect which needs to be explained is how
to delete elements. A subroutine to remove a single element from a linked list
would look like:
\begin{boxverbatim}
SUBROUTINE remove_element(element)

  TYPE(linked_list), POINTER :: element

  IF (ASSOCIATED(element%prev)) THEN
    ! Previous element exists
    element%prev%next=>element%next
  ELSE
    ! Previous element does not exist therefore element is the head. When
    ! element is removed the head is the element after the one being removed
    head=>element%next
  ENDIF

  IF (ASSOCIATED(element%next)) THEN
    ! next element exists
    element%next%prev=>element%prev
  ELSE
    ! next element does not exists therefore element is the tail. When element
    ! is removed the head is the element before the one being removed
    tail=>element%prev
  ENDIF

END SUBROUTINE remove_element
\end{boxverbatim}

Once again, this code looks slightly counter-intuitive, but if you go through
step by step, it's fairly simple. In the following discussion the element
being removed is called ``C'', the element before ``C'' (if it exists) is
called ``P'' and the element after ``C'' (if it exists) is called ``N''
\begin{itemize}
\item Check whether \inlinecode{C}'s prev element exists, this means that
  \inlinecode{P} exists.
\item If \inlinecode{P} exists then the element to be removed isn't at the
  start of the chain. When \inlinecode{C} is removed, we need
  \inlinecode{P}\%next to point to \inlinecode{C}\%next. This leads to the odd
  looking element\%prev\%next$=>$ element\%next syntax.
\item If \inlinecode{P} does not exist then \inlinecode{C} is at the the start
  of the chain. In order to not leave the chain orphaned when \inlinecode{C}
  is removed, we need head to point to \inlinecode{C}\%next.
\item Exactly the same logic applies for updating the element after
  \inlinecode{C}.
\item Check whether \inlinecode{C}'s next element exists, this means that
  \inlinecode{N} exists.
\item If \inlinecode{N} exists then the element to be removed isn't at the end
  of the chain. When \inlinecode{C} is removed, we need \inlinecode{N}\%prev
  to point to \inlinecode{C}\%prev.
\item If \inlinecode{P} does not exist then \inlinecode{C} is at the the start
  of the chain. In order to not leave the chain orphaned when \inlinecode{C}
  is removed, we need head to point to \inlinecode{C}\%next.
\end{itemize}

Therefore, code to remove some elements from a linked list would look like:
\begin{boxverbatim}
TYPE(linked_list), POINTER :: current, next

current=>head
DO WHILE(ASSOCIATED(current))
  next=>current%next
  IF (dealloc) THEN
    CALL remove_element(current)
    DEALLOCATE(current)
  ENDIF
  current=>next
ENDDO
\end{boxverbatim}
Note that ``current'' must be deallocated explicitly even after it has been
removed from the linked list to prevent a memory leak. Note also that the
pointer to the ``next'' element is saved before ``current'' is deallocated.
This is not necessary but means that there is only one IF statement rather
than the two otherwise required.

\subsubsection{Particles and particle species}
Particles are represented as linked lists of Fortran TYPES. The definition of
the particle type is:
\begin{boxverbatim}
  TYPE particle
    REAL(num), DIMENSION(3) :: part_p
    REAL(num), DIMENSION(c_ndims) :: part_pos
#ifdef PER_PARTICLE_WEIGHT
    REAL(num) :: weight
#endif
#ifdef PER_PARTICLE_CHARGE_MASS
    REAL(num) :: charge
    REAL(num) :: mass
#endif
    TYPE(particle), POINTER :: next, prev
#ifdef PARTICLE_DEBUG
    INTEGER :: processor
    INTEGER :: processor_at_t0
#endif
  END TYPE particle
\end{boxverbatim}
And the descriptions are
\begin{itemize}
\item REAL(num) :: part\_p(3) - The particle momentum. Always dimension 3 even
  in 1D and 2D codes.
\item REAL(num) :: part\_pos({\it ndims}) - The particle position. Has
  the same dimensions as that of the code.
\item REAL(num) :: weight - The particle weight if the code is running with
  per particle weighting.
\item REAL(num) :: charge - The particle charge in Coulombs if the code is
  running with per particle charge.
\item REAL(nun) :: mass - The particle mass in kilograms if the code is
  running with per particle mass.
\item TYPE(particle), POINTER :: next, prev - The pointers to the next and
  previous elements of the linked list.
\item INTEGER :: processor - The rank of the processor that the particle
  thinks it is on. Used for debugging.
\item INTEGER :: processor\_at\_t0 - The rank of the processor that the
  particle started on. Used for debugging.
\end{itemize}
Simply adding a new parameter to the definition of the particle type is NOT
sufficient to extend the particle type, since the communications when the
particle crosses a processor boundary do not know about the new parameter and
it will not be transmitted with the particle. How to add new properties to the
particle communication layer is described later.\\

The entire linked list of particles is encapsulated in another Fortran TYPE,
called \inlinecode{particle\_list}, which is defined as:
\begin{boxverbatim}
TYPE particle_list
  TYPE(particle), POINTER :: head
  TYPE(particle), POINTER :: tail
  INTEGER(KIND=8) :: count
  ! Pointer is safe if the particles in it are all unambiguously linked
  LOGICAL :: safe

  TYPE(particle_list), POINTER :: next, prev
END TYPE particle_list
\end{boxverbatim}
And its properties are:
\begin{itemize}
\item TYPE(particle), POINTER :: head - The first particle in the linked list.
\item TYPE(particle), POINTER :: tail - The last particle in the linked
  list. New particles added to the end of the list are added onto the end of
  the tail element, and the new last particle becomes the new tail element.
\item INTEGER(KIND=8) :: count - The number of particles in this particle
  list. Note that the \inlinecode{particle\_list} type is not directly MPI
  aware, so this is literally the number of particles in {\it this} particle
  list, not the number of particles of this species on all processors.
\item LOGICAL :: safe - A particle list is {\it safe} if the particles in it
  are unambiguously linked. That is that the \inlinecode{count}th particle is
  guaranteed to have its \inlinecode{next} property be null. Most particle
  lists within {\EPOCH} are safe, but sometimes it is useful to be able to have
  particle lists which are subsets of longer particles lists, and these
  particle lists are not {\it safe}.
\item TYPE(particle\_list), POINTER :: next, prev - At present, {\EPOCH} does
  not use these pointers, which are intended to allow multiple particle lists to
  be attached together. Certain parts of {\EPOCH}, such as the I/O system are
  aware of these pointers and will automatically use them if they are ever
  set. They are reserved for future use.
\end{itemize}

The \inlinecode{particle\_list} objects are used to abstract all the functions
of the linked list, including adding and removing particles and transporting
particles between processors.\\
\\
The particle species are represented by yet another Fortran TYPE, this time
called \inlinecode{particle\_species}, which is defined as:
\begin{boxverbatim}
  TYPE particle_species
    ! Core properties
    CHARACTER(string_length) :: name
    TYPE(particle_species), POINTER :: next, prev
    INTEGER :: id
    LOGICAL :: dump
    INTEGER :: subtype

    REAL(num) :: charge
    REAL(num) :: mass
    INTEGER(KIND=8) :: count
    TYPE(particle_list) :: attached_list

#ifdef TRACER_PARTICLES
    LOGICAL :: tracer
#endif

    ! particle cell division
#ifdef SPLIT_PARTICLES_AFTER_PUSH
    INTEGER(KIND=8) :: global_count
    LOGICAL :: split
    INTEGER(KIND=8) :: npart_max
    ! Secondary list
    TYPE(particle_list), DIMENSION(:,:), POINTER :: secondary_list
#endif

    ! Injection of particles
    INTEGER(KIND=8) :: npart_per_cell
    REAL(num), DIMENSION(:), POINTER :: density
    REAL(num), DIMENSION(:,:), POINTER :: temperature

    ! Species_ionisation
#ifdef PARTICLE_IONISE
    LOGICAL :: ionise
    INTEGER :: ionise_to_species
    INTEGER :: release_species
    REAL(num) :: critical_field
    REAL(num) :: ionisation_energy
#endif
    ! Attached probes for this species
#ifdef PARTICLE_PROBES
    TYPE(particle_probe), POINTER :: attached_probes
#endif
  END TYPE particle_species
\end{boxverbatim}
Again, most of these properties are self explanatory, but they are detailed
below.
\begin{itemize}
\item #CHARACTER(LEN=entry_length) :: name# - The name of the particle
  species. Used when constructing things like ``ekbar\_electron'' and similar
  names.
\item #TYPE(particle_species), POINTER :: next, prev# - Particle species are
  connected to each other as a linked list using pointers as well as being
  available through a simple array. These pointers are used behind the scenes
  in the I/O.
\item #INTEGER :: id# - The number of the species, so for the species
  \inlinecode{species\_list(1)}, the id field would be 1. For
  \inlinecode{species\_list(2)}, the id field would be 2 etc.
\item #LOGICAL :: dump# - Whether or not this species should be dumped in
  diagnostic output.
\item #REAL(num) :: charge# - The charge on a single particle of the species in
  Coulombs.
\item #REAL(num) :: mass# - The mass of a single particle of the species in
  kilograms.
\item #INTEGER(KIND=8) :: count# - The number of particles of this species on
  all processors. NOTE that this is only accurate if the code is compiled with
  the correct preprocessor options. Without the correct preprocessor options,
  this will be accurate at the start of the code runtime, but will not be if
  any particles enter or leave the domain. This is mainly a debugging
  parameter.
\item #TYPE(particle_list) :: attached_list# - This is the
  \inlinecode{particle\_list} object which holds the particles assigned to this
  species on this processor. Particles are attached to this list at all
  times EXCEPT when they are explicitly split when the code is
  compiled with the
  \inlinecode{PARTICLE\_CELL\_DIVISION} option. When the code is compiled with
  \inlinecode{PARTICLE\_CELL\_DIVISION}, the particles are attached to
  \inlinecode{attached\_list} except between the calls to
  \inlinecode{reorder\_particles\_to\_grid} and\linebreak
  \inlinecode{reattach\_particles\_to\_mainlist} in
  \inlinecode{epoch{\it n}d.F90} where the particles are instead attached to
  \inlinecode{secondary\_list}. This is explained later.
\item #LOGICAL :: tracer# - Whether or not this species is a tracer particle. If
  a species is a tracer species then it moves under the fields as normal for a
  particle with its mass and charge but contributes no current.
\item #LOGICAL :: split# - {\EPOCH} includes a very early version of a particle
  splitting operator. It works mechanically but has undesirable properties at
  present. If this flag is true then the code attempts to split the particles
  when the pseudoparticle number density drops too low.
\item #INTEGER(KIND=8) :: npart_max# - Used with the particle splitting
  operator. When the total number of particles equals this number, further
  particle splitting is suppressed.
\item #TYPE(particle_list), DIMENSION(:,:,:), POINTER :: secondary_list# - When
  the code is compiled with the \inlinecode{-DPARTICLE\_CELL\_DIVISION} option,
  the code allocates\linebreak
  \inlinecode{secondary\_list(0:nx+1,0:ny+1,0:nz+1)} and then loops over all
  particles. It calculates the cell in which each particle is and moves the
  particle from \inlinecode{attached\_list} to the correct element of
  \inlinecode{secondary\_list} for that cell. This means the particles which
  are nearby in space are now linked together in an array of linked lists.
  This allows things such as collision operators which require direct
  interaction between nearby particles.
\item #INTEGER(KIND=8) :: npart_per_cell# - The number of pseudoparticles per
  cell in the initial conditions. This is used with the moving window function
  to ensure that the same number of particles per cell are used for the new
  material introduced at the leading edge of the window.
\item #REAL(num), DIMENSION(:,:), POINTER :: density# - The density of the
  plasma at the leading edge of the window at the start of the simulation. This
  is used to structure the density of the new material introduced at the leading
  edge of the plasma.
\item #REAL(num), DIMENSION(:,:,:), POINTER :: temperature# - The temperature
  in of the plasma at the leading edge of a moving window at the start of the
  simulation. The final index of the array is the direction in which the
  temperature is set (1=x, 2=y, 3=z).
\item #LOGICAL :: ionise# - If the ionisation model is activated then this
  species should ionise.
\item #INTEGER :: ionise_to_species# - The species number for the next ionised
  state of this species.
\item #INTEGER :: release_species# - Specifies what type of particle should be
  released when this species ionises (i.e. which species is the electron).
\item #REAL(num) :: ionisation_energy# - The ionisation energy for the next
  ionisation of this species.
\item #TYPE(particle_probe), POINTER :: attached_probes# - A pointer pointing to
  the head of an attached linked list of particle probe diagnostics.
\end{itemize}

\subsubsection{EM Fields}
There are nine variables which are used in updating the EM field solver. These
are
\begin{itemize}
\item ex - Electric field in the X direction.
\item ey - Electric field in the Y direction.
\item ez - Electric field in the Z direction.
\item bx - Magnetic field in the X direction.
\item by - Magnetic field in the Y direction.
\item bz - Magnetic field in the Z direction.
\item jx - Current in the X direction.
\item jy - Current in the Y direction.
\item jz - Current in the Z direction.
\end{itemize}
The EM fields in {\EPOCH} are simple allocatable arrays, which are of size
(-2:nx+3,-2:ny+3,-2:nz+3), although this includes the ghost cells. The length of
the core domain is different for each variable due to the grid stagger.

The {\EPOCH} field solver is a Yee staggered 2nd order FDTD scheme, directly
based on the scheme in the PSC by Hartmut Ruhl and is contained in the file
\inlinecode{fields.F90}. To locate a variable on the grid there is a simple
rule.
\begin{itemize}
\item Start at the cell centre.
\item For an $E$ field component, move the field half a grid point in the
  direction that the field points if possible.
\item For a $B$ field component, move the field half a grid point in all
  directions {\it except} the one it points.
\end{itemize}
This is illustrated in Figure~\ref{yeegrid} for the 2D case.\\

\captionedimage{./images/stagger}{yeegrid}{The Yee grid in 2D}


The grid stagger means that you have to be careful with boundary conditions
since some variables are defined on the domain boundaries whereas others are
defined on either side of a domain boundary. This is handled automatically by
the built in boundary routines, but must be understood if developing other
boundary conditions. To explain it, consider only the left/right boundary in 1D
and consider $E_x$ and $B_x$.\\

$E_x$ is defined on the cell boundary, so \inlinecode{ex(0)} is the value of
$E_x$ on the left boundary and similarly \inlinecode{ex(nx)} is the
value on the right boundary. Conversely, in the 1D code $B_x$ is cell centred
(in reality, $B_x$ is never used in the field update and is unimportant since
any gradients in $B_x$ in 1D automatically break the solenoidal condition, but
this is still a useful example.). This means that \inlinecode{bx(1)} is the
centre of the first cell in the domain, and \inlinecode{bx(0)} is the value at
the centre of the first left hand ghost cell. This means the you must do
different things as boundary conditions for the two fields for some boundary
conditions.\\

For example, if you want to clamp the value of $E_x$ to be zero on the
boundary, then just set \inlinecode{ex(0) = 0.0\_num} since \inlinecode{ex(0)}
lies on the boundary. To do the same for $B_x$ on the boundary you have to
set \inlinecode{bx(0) = -bx(1)}. This is because if you use a linear
reconstruction of $B_x$ (i.e second order) then the point between
\inlinecode{bx(0)} and \inlinecode{bx(1)} has the value
$B_x(1/2) = \left(B_x(1)+B_x(0)\right)/2$. Similarly, if you want to set zero
gradient on the boundary then for $E_x$ you set \inlinecode{ex(-1) = ex(1)},
whereas for $B_x$ you would set \inlinecode{bx(0) = bx(1)}. This is explained
in more detail in \sect{bcs}.

In the particle pusher, time centred field variables are needed for second
order accuracy, so an FDTD scheme is used to advance the fields. This looks
like

\begin{itemize}
\item $\vec{E}^{n+\frac{1}{2}} = \vec{E}^n + \frac{\Delta t}{2} \left( c^2
  \nabla \wedge \vec{B}^{n} -\vec{j}^{n} \right)$
\item $\vec{B}^{n+\frac{1}{2}} = \vec{B}^n - \frac{\Delta t}{2} \left( \nabla
  \wedge \vec{E}^{n+\frac{1}{2}} \right)$
\item Call particle pusher which calculates $j^{n+1}$ currents
\item $\vec{B}^{n+1} = \vec{B}^{n+\frac{1}{2}} - \frac{\Delta t}{2} \left(
  \nabla \wedge \vec{E}^{n+\frac{1}{2}} \right)$
\item $\vec{E}^{n+1} = \vec{E}^{n+\frac{1}{2}} + \frac{\Delta t}{2} \left( c^2
  \nabla \wedge \vec{B} ^{n+1} - \vec{j}^{n+1} \right)$
\end{itemize}
Note that all spatial derivatives are calculated using the staggered grid, so
the final derivatives in the code appear one sided. However, this is not the
case, and all spatial derivatives are second order accurate. Higher order
spatial derivatives schemes for {\EPOCH} are being developed to improve the
dispersion properties of the code when resolving small timescales.

\subsection{The particle pusher}
{\EPOCH}'s particle pusher is based on the one from the PSC by Hartmut Ruhl, and
is a Birdsall and Landon type PIC scheme using Villasenor and Buneman current
weighting. It is contained in the file \inlinecode{particles.F90}. The
operation of the particle pusher is fairly simple, but there are a few elements
which need some clarification.
\begin{itemize}
\item The update to the particle momenta etc. does not explicitly include the
  particle weight function. This means that the pseudoparticle momenta etc. are
  the momentum for a single real particle of the collection of real particles
  represented by that pseudoparticle, NOT the momentum of the whole collection
  of real particles.
\item \inlinecode{root} - The variable root which appears in various places is
  essentially the multiplicative factor which is needed to convert the particle
  momentum into the particle velocity. If {\EPOCH} was not relativistic then
  this would simply be $1/part\_m$ where $part\_m$ is the particle mass.
  Since {\EPOCH} is relativistic, root is defined as $\left(part\_m^2 +
    \vec{p}.\vec{p}/c^2\right)^{-1/2}$.
\item \inlinecode{cell\_x1=cell\_x1+1} - There are lines like this after all
  the sections of the routine where the cell a particle is in is
  calculated. This is because, for a cell centred variable, the domain runs
  (1:nx,1:ny,1:nz) rather than (0:nx-1,0:ny-1,0:nz-1).
\end{itemize}

\subsubsection{Particle shape functions}
The key feature of a PIC code controlling the smoothness of the solution is the
particle shape function. That is the function that describes the assumed
distribution of the real particles making up a pseudoparticle. The simplest
solution is to assume that the pseudoparticles uniformly fill the cell in which
the pseudoparticle is located. This has the advantages of speed and simplicity
but produces very noisy solutions. The next simplest approach is to assume a
triangular shape function with the peak of the triangle located at the position
of the pseudoparticle and a width of $ 2 \Delta x$, as illustrated in
Figure~\ref{shape}. This is the approach used
in {\EPOCH} and is a good trade-off between cleanness of solution and
speed. Higher order methods based on spline interpolation can be used and do
produce smoother solutions, but they are significantly slower and the benefits
of the schemes can easily be overstated. {\EPOCH} does now include an option to
use 4th order spline interpolation in all parts of the code. This option is
enabled with the \inlinecode{-DSPLINE\_FOUR} compile time option in the
makefile.\\
\[
S(w) =
\begin{cases}
1 - \frac{x_i-w}{\Delta x}, & (x_i-w) \le \Delta x \\
0, & \mbox{otherwise}
\end{cases}
\]

Functions derived from the particle shape function appear in two places in the
core solver: when the EM fields are interpolated to the position of the
pseudoparticle and when the current is updated and properties of the
pseudoparticle are copied onto the grid. These two uses of the shape function
are conceptually similar, but have different forms.

\captionedimage{./images/shape}{shape}{Second order particle shape function}

To derive the equations for calculating the field acting on a particle,
you calculate the overlap of the particle shape function with the function
representing the fields on the grid. In {\EPOCH}, the fields are approximated at
first order so that the field is constant over each cell. Consider a particle
with position $X$, where $X$ lies in the cell centred at $x_i$ and grid
spacing $\Delta x$. The integral is split into four parts; that part of the
shape function which overlaps with the cell $x_{i-1}$, the part of the shape
function from the left boundary of $x_i$ to the point of the triangle, the part
of the shape function from the point of the triangle to the right hand edge of
$x_i$ and finally that part of the shape function which overlaps cell
$x_{i+1}$. Assuming that fields are constant inside each cell, this takes the
form
\[
\begin{aligned}
  Fpart_i~=~\frac{1}{\Delta x} & \left[ \int^{x_{i-1}
      + \frac{\Delta x}{2}}_{X-\Delta x}
      F_{i-1} \left( 1-\frac{X-x}{\Delta x} \right) dx \right.\\
    & + \int^{X}_{x_i-\frac{\Delta x}{2}}
      F_i \left( 1-\frac{X-x}{\Delta x} \right) dx \\
    & + \int^{x_i+\frac{\Delta x}{2}}_{X}
      F_i \left(  1-\frac{x-X}{\Delta x}\right) dx \\
    & \left. + \int^{X+\Delta x}_{x_{i+1} - \frac{\Delta x}{2}}
      F_{i+1} \left( 1-\frac{x-X}{\Delta x}\right) dx\right]
\end{aligned}
\]

Performing these integrals and remembering that $x_{i-1}+\frac{\Delta x}{2}$ is
equal to $x_i-\frac{\Delta x}{2}$ since the grid is uniformly spaced with
spacing $\Delta x$ this gives a final formula for the field at a particle of

\[
\begin{aligned}
  F_{part}~=~& \frac{1}{2} F_{i-1} \left( \frac{1}{2}
  + \frac{x_i-X}{\Delta x} \right)^2 \\
  & + F_i \left( \frac{3}{4} - \frac{(x_i-X)^2}{\Delta x^2} \right)\\
  & +\frac{1}{2} F_{i+1} \left( \frac{1}{2} - \frac{x_i-X}{\Delta x} \right)^2
\end{aligned}
\]

%If you are running the code with the \inlinecode{-DSPLINE\_FOUR} high order
%particle weight function option then the triangular shape function is replaced
%by a 4th order spline function which has a basis of 5 cells rather than 3
%cells. The form of this function is

In the code calculating the strength of a cell centred field on the particle
is done as follows.
\begin{boxverbatim}
  REAL(num) :: cell_x_r, cell_frac_x
  INTEGER :: cell_x1
  REAL(num) :: gx(-2:2)
  TYPE(particle), POINTER :: current

  part_x  = current%part_pos(1) - x_min_local

  ! Work out the grid cell number for the particle.
  ! Not an integer in general.
  cell_x_r = part_x / dx

  ! Round cell position to nearest cell
  cell_x1 = FLOOR(cell_x_r + 0.5_num)
  ! Calculate fraction of cell between nearest cell boundary and particle
  cell_frac_x = REAL(cell_x1, num) - cell_x_r
  cell_x1 = cell_x1 + 1

  cf2 = cell_frac_x**2
  gx(-1) = 0.25_num + cf2 + cell_frac_x
  gx( 0) = 1.5_num - 2.0_num * cf2
  gx( 1) = 0.25_num + cf2 - cell_frac_x

  f_part = &
        gx(-1) * F(cell_x1-1) &
      + gx( 0) * F(cell_x1  ) &
      + gx( 1) * F(cell_x1+1)
\end{boxverbatim}

where \inlinecode{f\_part} is the field at the particle location. Note that
this has been simplified a little for brevity. Just the triangle shape
function is given.
In 2D or 3D, you just calculate gy
in the same manner as gx and calculate the weight over all the cells affected
by the individual 1D shape functions. In 2D this looks like:
\begin{boxverbatim}
  f_part = 0.0_num
  DO iy = sf_min, sf_max
    DO ix = sf_min, sf_max
      f_part = f_part + f(cell_x+ix, cell_y+iy) * gx(ix) * gy(iy)
    ENDDO
  ENDDO
\end{boxverbatim}
The variables \inlinecode{sf\_min} and \inlinecode{sf\_max} contain the shape
function order parameters which indicate the cells each side of the cell
containing the particle which are overlapped by the particle shape function.
They are defined in \inlinecode{shared\_data.F90} and should only be changed
by the developer if a new particle shape function is being added.
Although provided here as pseudo-code for the particle push, it should be
noted that the actual particle push unrolls these loops for the sake of speed.

Inside the particle pusher the $E$ and $B$ fields are not cell centred fields,
but Yee staggered. This means that there is a small change to the above
mentioned example. In 1D this change looks like

\begin{boxverbatim}
  REAL(num) :: cell_x_r, cell_frac_x
  INTEGER :: cell_x1, cell_x2
  REAL(num) :: gx(-2:2), hx(-2:2)
  TYPE(particle), POINTER :: current

  part_x  = current%part_pos(1) - x_min_local

  ! Work out the grid cell number for the particle.
  ! Not an integer in general.
  cell_x_r = part_x / dx

  ! Round cell position to nearest cell
  cell_x1 = FLOOR(cell_x_r + 0.5_num)
  ! Calculate fraction of cell between nearest cell boundary and particle
  cell_frac_x = REAL(cell_x1, num) - cell_x_r
  cell_x1 = cell_x1 + 1

  ! Calculate weights
  INCLUDE 'include/triangle/gx.inc'

  ! Now redo shifted by half a cell due to grid stagger.
  ! Use shifted version for ex in X, ey in Y, ez in Z
  ! And in Y&Z for bx, X&Z for by, X&Y for bz
  cell_x2 = FLOOR(cell_x_r)
  cell_frac_x = REAL(cell_x2, num) - cell_x_r + 0.5_num
  cell_x2 = cell_x2 + 1

  ! Calculate weights
  INCLUDE 'include/triangle/hx_dcell.inc'

  ! bx is cell centred
  bx_part = 0.0_num
  DO ix = sf_min, sf_max
    bx_part = bx_part + bx(cell_x1+ix) * gx(ix)
  ENDDO

  ! ex is staggered 1/2 a cell to the right
  ex_part = 0.0_num
  DO ix = sf_min, sf_max
    ex_part = ex_part + ex(cell_x2+ix) * hx(ix)
  ENDDO
\end{boxverbatim}

In 2D and 3D, you just combine the shifted and unshifted shape functions and
associated cell positions depending on the position of the variable in the
cell. Therefore, in 3D and using the loop notation for clarity you would get:
\begin{boxverbatim}
  DO iz = sf_min, sf_max
    DO iy = sf_min, sf_max
      DO ix = sf_min, sf_max
        ex_part = ex_part + hx(ix) * gy(iy) * gz(iz) * &
            ex(cell_x2+ix, cell_y1+iy, cell_z1+iz)
      ENDDO
    ENDDO
  ENDDO

  DO iz = sf_min, sf_max
    DO iy = sf_min, sf_max
      DO ix = sf_min, sf_max
        bx_part = bx_part + gx(ix) * hy(iy) * hz(iz) * &
            bx(cell_x2+ix, cell_y1+iy, cell_z1+iz)
      ENDDO
    ENDDO
  ENDDO
\end{boxverbatim}

Since $E_x$ is staggered half a grid cell in the x direction, whereas $B_x$ is
staggered by half a grid cell in the y and z directions.

The next stage is to consider how to copy pseudoparticle
properties on the grid. This is very similar to the function for calculating
grid variables at the particle location and, for each grid point $x_i$,
consists of integrating the part of the particle shape function which overlaps
the $i^{th}$ cell. That is

\[
F(i) = Data  \int^{x_i+\frac{\Delta x}{2}}_{x_i-\frac{\Delta x}{2}} S(X-x) dx
\]

Where $Data$ is the particle property to be copied onto the grid. In {\EPOCH},
since the particle shape function is known to go to zero outside a distance of
$2 \Delta x$ from the maximum, the maximum number of cells that can possibly be
overlapped by a given particle shape function is 3; the cell containing the
particle maximum and the two cells to either side. Performing the integration
using the triangular shape function given above gives the result

\[
  F(i) =
\begin{cases}
  \frac{3}{4} - \frac{|X-x_i|^2}{\Delta x^2}, & |X-x_i|
    \le \frac{\Delta x}{2}\\
  \frac{1}{2} \left(\frac{3}{2}
    - \frac{|X - x_i|}{\Delta x} \right)^2, & \frac{\Delta x}{2} < |X-x_i|
    \le \frac{3 \Delta x}{2}\\
  0, & |X-x_i| > \frac{3 \Delta x}{2}\\
\end{cases}
\]

%Again, when using high order particle shape functions using the
%\inlinecode{-DSPLINE\_FOUR} option this is replaced with an equivalent form for
%a 4th order spline.

When this is translated into the code, it looks very similar to that presented
for the case where grid properties are interpolated to the particle
position. This form is used in the particle pusher to perform the current
update and in the routines in \inlinecode{src/io/calc\_df.F90} to copy particle
properties onto the grid for output. The form from calc\_df is rather clearer
and easier to see in operation. In 1D it looks like:
\begin{boxverbatim}
  cell_x_r = (current%part_pos - x_min_local) / dx + 1.5_num
  cell_x = FLOOR(cell_x_r)
  cell_frac_x = REAL(cell_x, num) - cell_x_r + 0.5_num

  CALL particle_to_grid(cell_frac_x, gx)

  wdata = part_m * fac
  DO ix = sf_min, sf_max
    data_array(cell_x+ix) = data_array(cell_x+ix) + gx(ix) * wdata
  ENDDO
\end{boxverbatim}

Once again multi-dimensional codes just have the weighting functions multiplied
together.
\begin{boxverbatim}
  DO iy = sf_min, sf_max
    DO ix = sf_min, sf_max
      data_array(cell_x+ix, cell_y+iy) = &
          data_array(cell_x+ix, cell_y+iy) + gx(ix) * gy(iy) * wdata
    ENDDO
  ENDDO
\end{boxverbatim}

\subsubsection{Current calculation}
{\EPOCH} uses the Villasenor and Buneman (Villasenor and Buneman, Computer
Physics Communications 69(1992) 306-316) current calculating scheme which
solves the additional equation
${\partial \rho}/{\partial t} = \nabla\cdot\vec{J}$ to
calculate the current at each timestep. The main advantage of this scheme is
that it conserves charge {\it on the grid} rather than just globally conserving
charge on the particles. This means that the error in the solution of Poisson's
equation is conserved, so if Poisson's equation is satisfied for $t = 0$ it
remains satisfied for all time.\\

The Villasenor and Buneman scheme works because exactly the same charge added
to one cell is subtracted from another cell, which in turn means that exactly
the same current added to one cell is subtracted from another cell. This is
intuitively correct since a point particle crossing a cell boundary would
represent the loss of that particle's contribution to the current from the
source cell and the gain of that particle's contribution to the current by the
destination cell. In fact this simple type of cell boundary crossing
current calculation was used in classical Buneman type PIC codes.\\

The scheme is messy, in practise, but simple. After the main particle push, the
particle is advanced a further half timestep into the future to first order
using the velocities calculated at the end of the particle push. The particle
position at $t + dt/2$ were stored earlier, and combined with the newly
calculated particle position at $t + {3dt}/{2}$ this allows a time centred
evaluation of ${\partial \rho}/{\partial t}$ meaning that the current
update is second order accurate in time. The spatial order of the scheme
matches the spatial order of the particle weight function.\\

The weight functions for transferring particle properties onto the grid at the
two timesteps are calculated including a shift when necessary to allow for the
particle having crossed a cell boundary. Since the charge associated with the
particle is spatially distributed using the weight function, all that is
necessary to calculate ${\partial \rho}/{\partial t}$ is to subtract the
two functions, multiply by the charge on the pseudoparticle and the
pseudoparticle weight and finally divide by $dt$. The spatial derivative of
$\vec{J}$ is then converted to a one sided finite difference form and solved
directly. In multiple dimensions this is slightly complicated by the effects of
offsets in directions other than the direction that a given current component
is pointing in, with this adding additional weight factors based on the overlap
of the shape functions in other directions. This is explained in full in the
Villasenor and Buneman paper already quoted.\\

Currents in ignorable directions are simply calculated using $J = n\rho\vec{v}$
with the correct shape functions to ensure that the current is placed in the
correct places.

\subsection{The timestep}

The timestep is calculated in the subroutine \inlinecode{set\_dt} in the file
\inlinecode{src/io/diagnostics.F90}. All that the subroutine has to do is set
the variable \inlinecode{dt} to set the timestep for the whole code. Any
additional timestep constraints should be coded into this subroutine. This
should be implemented after the existing \inlinecode{dt=} lines but before the
line \inlinecode{dt = dt\_multiplier * dt}. Such a modification should be set so
that it only changes the timestep if the timestep is MORE restrictive than that
calculated from the core code. An example would be:
\begin{boxverbatim}
  dt = dx * dy / SQRT(dx**2 + dy**2) / c
  dt = MIN(dt, my_new_dt)
\end{boxverbatim}

In the core {\EPOCH} code the timestep can be calculated identically on each
processor, so there is no requirement to synchronise the timestep across
multiple processors. If your new timestep restriction uses information local to
each processor then some additional lines must be added to the
\inlinecode{set\_dt} routine after the timestep has been calculated which
should read:
\begin{boxverbatim}
  REAL(num) :: dt_global
          .
          .
          .
  CALL MPI_ALLREDUCE(dt_global, dt, 1, mpireal, MPI_MIN, comm, errcode)
  dt = dt_global
\end{boxverbatim}

This uses another MPI command to determine the most restrictive timestep across
all processors. {\EPOCH} is not written in a way that permits operation with
different timesteps on different processors, and the behaviour of the code is
undefined (and likely wrong) if the code runs with different timesteps on
different processors.

\subsection{Boundary conditions}
\label{sec:bcs}
Boundary conditions in {\EPOCH} are split into three types
\begin{itemize}
\item Simple field boundaries.
\item Laser and outflow boundaries.
\item Particle boundaries.
\end{itemize}

These boundaries can be combined in different ways to give different
effects. From the end user perspective there are 4 boundaries which can be
applied to each edge of the simulation domain. These are
\begin{itemize}
\item Periodic
  \subitem Particles periodic
  \subitem Fields periodic
  \subitem Lasers off
\item Other
  \subitem Particles reflect
  \subitem Fields clamped zero
  \subitem Lasers off
\item Simple Laser
  \subitem Particles transmissive
  \subitem Fields clamped zero
  \subitem Lasers applied at half timestep for $B$ field
\item Simple outflow
  \subitem Particles transmissive
  \subitem Fields clamped zero
  \subitem No lasers applied at half timestep, but outflow conditions applied
  to $B$ field at half timestep
\end{itemize}
The boundary conditions are applied in too many places in the code to give a
full description of them, but the laser boundaries are only applied in
\inlinecode{src/fields.f90}. The boundaries requested by the user are converted
into the conditions on the fields and particles in the routine
\inlinecode{setup\_particle\_boundaries} in
\inlinecode{src/boundaries.F90}. For each of the six possible boundaries
(x\_min, x\_max, y\_min, y\_max, z\_min, z\_max) there is a variable which will
be named something like \inlinecode{bc\_x\_min\_particle} or
\inlinecode{bc\_y\_max\_field} which controls the boundary condition which will
be applied to either the field or the particles.

\subsubsection{Simple field boundaries}
There are two subroutines which apply the standard boundary conditions:
\inlinecode{field\_zero\_gradient} and \inlinecode{field\_clamp\_zero}. The
type of boundary condition that the two apply is obvious from the name, but
the two functions have different calling conventions.

\pagebreak
\begin{codedef}
SUBROUTINE field_zero_gradient
\HRule
REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field
LOGICAL, INTENT(IN) :: force
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/boundary.F90}\\
\\[0.5cm]
{\Large Description\\}
#field_zero_gradient# is the routine which applies zero gradient
boundary conditions to a field variable passed in the parameter
\inlinecode{field}. It can be used as a global field boundary condition by
setting one of the field boundary conditions to c\_bc\_zero\_gradient in
\inlinecode{setup\_particle\_boundaries}, but it is mostly used to give
boundary conditions for the autoloader, where the \inlinecode{force} parameter
is set to \inlinecode{.TRUE.} to override the boundary condition values.
\\[0.5cm]
{\Large Notes\\ \\}

\pagebreak
\begin{codedef}
SUBROUTINE field_clamp_zero
\HRule
REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field
INTEGER, DIMENSION(ndims), INTENT(IN) :: stagger
\end{codedef}
\vspace{1cm}
{\Large Description\\}
\inlinecode{field\_clamp\_zero} is the routine which clamps the field given by
the \inlinecode{field} variable to zero on the boundary. Since this routine
explicitly sets the field to zero {\it on} the boundary it needs to know about
the grid stagger which is provided in the parameter \inlinecode{stagger}. At
present stagger is simply an array of 1/0 values which indicates whether a
given field is staggered in that direction, so a cell centred field has
stagger \inlinecode{(/0, 0, 0/)} while ex has stagger \inlinecode{(/1, 0, 0/)}
and bx has stagger \inlinecode{(/0, 1, 1/)}.
\\[0.5cm]
{\Large Notes\\}
\pagebreak

Additional boundary conditions should follow the same basic principle as these
routines. Note that all of the routines test for things like \inlinecode{x\_min
.EQ. MPI\_PROC\_NULL} etc. these tests confirm that a given processor is at the
edge of the real domain, and so should have a real boundary condition applied
to it. This also explains why there are no explicit periodic boundary condition
routines, since by connecting the processors cyclically in a periodic direction
the domain boundary effectively becomes another internal processor boundary.

\subsubsection{Laser and outflow boundaries}
Setting up lasers is explained in \sect{lasers}
and the way in which the laser specification in the input deck works is
described later, so this section just describes how the actual laser and
outflow routines in \inlinecode{laser.F90} work.\\

The laser boundaries in {\EPOCH} are based on a rewriting of Maxwell's
equations in a new form which expresses the fields explicitly in terms of waves
propagating in both directions along each co-ordinate axis with both S and P
polarisation states. In the X direction,
\[
\partial_t(E_y \pm B_z) \pm \partial_x(E_y \pm B_z) = \pm \partial_yE_x
+ \partial_zB_x -\frac{j_y}{\epsilon_0}
\]
\[
\partial_t(E_z \mp B_y) \pm \partial_x(E_z \mp B_y) = \pm \partial_zE_x
- \partial_yB_x -\frac{j_z}{\epsilon_0}
\]
It is then possible to rewrite these equations to provide a boundary condition
on $B_z$ and $B_y$ to give propagating EM waves at the boundary. For waves
travelling into the boundary, this gives a transmissive boundary, and if the
components for waves propagating out from the boundary are set to be non-zero
then it also introduces an EM wave propagating from the left boundary.\\

This boundary condition is found in the file \inlinecode{laser.F90} which also
includes the routines for handling the \inlinecode{laser\_block} objects which
represent how lasers are represented in {\EPOCH}.

\subsubsection{Particle boundaries}
Due to the time that is required to loop over all the particles the particle
boundary conditions in {\EPOCH} combine the inter-processor boundary conditions
with the real boundary conditions. The boundary conditions for particles are in
the routine \inlinecode{particle\_bcs} in the file \inlinecode{boundary.f90} \\
Currently {\EPOCH} includes only three particle boundary conditions
\begin{itemize}
\item c\_bc\_periodic - Particles which leave one side of the box reappear on
  the other side.
\item c\_bc\_reflect - Particles reflect off the boundary as if it was a hard
  boundary.
\item c\_bc\_open - Particles pass through the boundary and are destroyed. Total
  pseudoparticle number is not conserved in this mode.
\end{itemize}

Although the routine looks rather messy, it is fairly easy to understand. The
sequence goes:
\begin{itemize}
\item Loop over all species.
\item Create particle list objects for particles to be sent to and received from
  other processors.
\item Loop over all particles.
\item If the particle has crossed the domain boundary and that boundary has
  reflecting boundary conditions then reflect the particle.
\item If the particle has crossed the processor boundary then set the variables
  \inlinecode{xbd} and \inlinecode{ybd} which are used to identify which
  processor relative to the current processor the particle should be moved to.
\item Check whether the particle has crossed an open domain boundary.
\item If the particle has crossed a processor boundary or an open domain
  boundary then remove the particle from the particle list for its species.
\item If the particle has crossed a processor boundary but not an open domain
  boundary then add it to the list to be sent to its new processor using
  \inlinecode{xbd} and \inlinecode{ydb} to identify which processor it should
  be on.
\item If the particle has crossed an open domain boundary then either add it to
  another list to be dumped to disk if the user has requested this, or
  otherwise just deallocate the particle to reclaim memory.
\item End particle loop.
\item Loop over all possible neighbouring processors for the current processor
  and exchange particle lists with that processor.
\item Add any received particles onto the particle list for the current
  species.
\item Although particles which have crossed a periodic boundary are now on the
  correct processor, they have the wrong position in space, so subtract the
  length of the domain from the particles position.
\item End species loop.
\end{itemize}

Note that, unlike for fields, there is explicit periodic boundary code. This is
because although the MPI routines place the particle on the correct processor
after the MPI routines, the particle's position variable still places it beyond
the other end of the domain. The MPI parallelism for exchanging particles is
hidden in the routines which deal with the particle list objects and are
described in the next section.
\pagebreak

\subsubsection{MPI Boundaries}
There are three routines which deal with MPI exchange for field variables in
{\EPOCH}. Two are closely related and will be considered together. The third
deals with using MPI to sum variables at processor boundaries rather than
synchronise ghost cells.\\\\

\begin{codedef}
SUBROUTINE field_bc
\HRule
REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/boundary.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{field\_bc} exchanges the information in the ghost cells between
adjacent processors. Any field variable which is used in a calculation that
requires operations involving information from points other than the
current point should call this routine each time the variable is updated. This
will ensure that the ghost cells are populated from adjacent processors.
(i.e. if you only need to access field(ix,iy,iz) there is no need to update
ghost cells, whilst if you use field(ix-1,iy,iz) you do).
\\[0.5cm]
{\Large Notes\\}
The \inlinecode{field\_bc} routine just calls the
\inlinecode{do\_field\_mpi\_with\_lengths} routine which is a more general
routine that allows ghost cell information to be exchanged for fields with
an arbitrary number of cells, rather than fields which are
(-2:nx+3,-2:ny+2,-2:nz+3). This routine is used internally in the load
balancing routine when fields with both the old and new sizes must be handled
at the same time.

\pagebreak
\begin{codedef}
SUBROUTINE processor_summation_bcs
\HRule
REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/boundary.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{processor\_summation\_bcs} is a routine which is used to deal with
variables, like $\vec{j}$ or number density that should be added at boundaries
to include contributions from particles on both sides of a processor boundary.
The routine is used for the current inside the particle pusher and inside most
of the routines for calculating derived variables. If you have a variable
which needs to add contributions from adjacent processors then you should
calculate the quantity on each processor, including contributions from the
particles to the ghost cells and then call this routine.
\\[0.5cm]
{\Large Notes\\}
\pagebreak

These routines can be used for most MPI calls required by all but the most
extreme modifications to {\EPOCH}.

\subsection{Particle List control functions}
Collections of particles in {\EPOCH} are represented by the #particle_List#
object. These objects abstract much of the operation of the linked lists,
including adding and removing particles and sending particles to other
processors. The functions are as follows:

\pagebreak
\begin{codedef}
FUNCTION create_empty_partlist(partlist)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{create\_empty\_partlist} is a function which takes a particle\_list
object and sets it up so that it points to no particles at all. It should be
used on newly allocated particle\_list objects and when a particle\_list has
served its purpose. It DOES NOT destroy the particles linked in the list at
the point that it is called. If the user wishes to delete all the particles in a
particle\_list then the routine \inlinecode{destroy\_partlist} should be used
instead.
\\[0.5cm]
{\Large Notes\\}

\pagebreak
\begin{codedef}
FUNCTION create_unsafe_partlist(partlist, a_particle, &
    n_elements)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
TYPE(particle), POINTER :: a_particle
INTEGER(KIND=8), INTENT(IN) :: n_elements
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{create\_unsafe\_partlist} is a routine which allows the creation of
a particle\_list which represents a subset of another particle list. This subset
is defined as starting at the particle pointed to by \inlinecode{a\_particle}
and extending for \inlinecode{n\_elements} elements. The new particle\_list is
then flagged as ``unsafe'' because if it is destroyed for any reason then it
will affect other particle lists. Many particle\_list functions can only work
on safe particle lists.
\\[0.5cm]
{\Large Notes\\}

\pagebreak
\begin{codedef}
FUNCTION create_unsafe_partlist_by_tail(partlist, head, &
    tail)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
TYPE(particle), POINTER :: head, tail
\end{codedef}
\vspace{1cm}
{\Large Description\\}
\inlinecode{create\_unsafe\_partlist\_by\_tail} is almost identical to
\inlinecode{create\_unsafe\_partlist}, but instead of specifying the first
particle and a number of elements, the user specifies the first and last
elements in the subset of the particle list. If the particle objects specified
for head and tail are not in the same partlist or tail actually comes before
head then the routine will fail in an undefined manner.
\\[0.5cm]
{\Large Notes\\}

\pagebreak
\begin{codedef}
FUNCTION create_allocated_partlist(partlist, n_elements)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
INTEGER(KIND=8), INTENT(IN) :: n_elements
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{create\_allocated\_partlist} is a helper routine to setup a new
particle\_list and create \inlinecode{n\_elements} new particle objects already
in place in the list.
\\[0.5cm]
{\Large Notes\\}
You should always use this routine when creating large numbers of new particle
objects since there is no guarantee that the internal structure of the
particle\_list objects will not change in the future. This routine will
be modified to reflect any changes in the underlying code.

\pagebreak
\begin{codedef}
FUNCTION create_filled_partlist(partlist, data_in, &
    n_elements)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
REAL(num), DIMENSION(:), INTENT(IN) :: data_in
INTEGER(KIND=8), INTENT(IN) :: n_elements
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{create\_filled\_partlist} is a helper routine to setup a new
particle\_list and create \inlinecode{n\_elements} new particle objects already
in place in the list. These new particle objects are then assigned properties
from the array \inlinecode{data\_in} where the particle properties are contained
in packed form. The particle data is unpacked from the array using the
\inlinecode{unpack\_particle} routine.
\\[0.5cm]
{\Large Notes\\}
You should always use this routine, if possible, when copying particles out of
packed format since there is no guarantee that the internal structure of the
particle\_list objects will not change in the future. This routine will
be modified to reflect any changes in the underlying code.

\pagebreak
\begin{codedef}
FUNCTION test_partlist(partlist)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{test\_partlist} is a routine which tests for various possible types
of error within a particle\_list object. It has a number of possible return
codes for different errors, using negative values for errors so severe that
the main tests cannot be run, or with a bitmask for errors in the main tests.
The return codes are:
\begin{itemize}
\item 0 - No error, particle\_list has passed all tests.
\item -1 - Either the head or tail of the particle\_list object is NULL. This is
  a serious error and usually means that there is a serious error inside the
  particle\_list routines.
\end{itemize}
The other error codes are returned as a bitmask and mean the following
\begin{itemize}
\item 1 - A particle\_list marked as safe has a head element which is linked to
  a preceding particle object.
\item 2 - A particle\_list marked as safe has a tail element which is linked to
  a proceding particle object.
\item 4 - The count property of a particle\_list does not correspond to the
  actual number of objects linked between the head and tail objects. This error
  code on its own usually means that the count property has been modified
  improperly.
\end{itemize}
\vspace{0.5cm}
{\Large Notes\\}
Note that this routine is only intended for debugging and is very slow. It
should never be used by the code in normal operation and all routines should be
written in such a way that it is impossible for a particle\_list object to
become corrupted.

\pagebreak
\begin{codedef}
FUNCTION destroy_partlist(partlist)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{destroy\_partlist} is a helper routine to delete all the particles
attached to a particle\_list and free up the memory that they use. It also
guarantees to leave the particle\_list object itself in a blank state where new
particles can be added to it. It DOES NOT delete the particle\_list object
itself, since it does not know whether or not the particle\_list is dynamically
allocated. If using dynamically allocated particle\_list objects then it is up
to the user to deallocate them AFTER the attached particles are destroyed using
\inlinecode{destroy\_partlist}.
\\[0.5cm]
{\Large Notes\\}
If a particle\_list is deleted without deleting the attached particle objects,
either using this routine or explicitly by the user, then the particles will
become orphaned and sit around using memory until the code ends. If this
happens regularly then the code will quickly crash, usually with a SIG\_SEGV
error.

\pagebreak
\begin{codedef}
FUNCTION copy_partlist(partlist1, partlist2)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist1, partlist2
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{copy\_partlist} is a routine which sets \inlinecode{partlist2} to
point to the same linked list of particles as \inlinecode{partlist1}. It does
not copy the particles, just sets the head and tail pointers of
\inlinecode{partlist1} to point to the same particle objects as
\inlinecode{partlist1}.
\\[0.5cm]
{\Large Notes\\}

\pagebreak
\begin{codedef}
FUNCTION append_partlist(head, tail)
\HRule
TYPE(particle_list), INTENT(INOUT) :: head, tail
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{append\_partlist} is a routine which takes the particles
attached to the particle\_list object \inlinecode{tail} and adds them to the
end of the linked list for particle\_list \inlinecode{head}. The particle\_list
\inlinecode{tail} is then set to be an empty particle\_list.
\\[0.5cm]
{\Large Notes\\}
This routine can only append one safe particle\_list to another safe
particle\_list.

\pagebreak
\begin{codedef}
FUNCTION add_particle_to_partlist(partlist, new_particle)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
TYPE(particle), POINTER :: new_particle
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{add\_particle\_to\_partlist} adds a new
particle (\inlinecode{new\_particle}) to the end of the linked list of
particles in the particle\_list object \inlinecode{partlist}. It deals with
cases of empty particle\_list objects automatically.
\\[0.5cm]
{\Large Notes\\}
If you want to add a new particle to the end of a particle list you should
always use this routine.

\pagebreak
\begin{codedef}
FUNCTION remove_particle_from_partlist(partlist, &
    a_particle)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
TYPE(particle), POINTER :: a_particle
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{remove\_particle\_from\_partlist} removes the particle object
specified by \inlinecode{a\_particle} from the particle\_list object given by
\inlinecode{partlist}. Be very careful that \inlinecode{a\_particle} is indeed
in the linked list pointed to by \inlinecode{partlist}, otherwise it is possible
for the particle\_list object which really does contain \inlinecode{a\_particle}
to be left with an invalid pointer as its head or tail element if
\inlinecode{a\_particle} is either the head or tail element.
\\[0.5cm]
{\Large Notes\\}
Although this routine does work with unsafe particle\_list objects, you should
be very careful using it in this case as it can break the head or tail element
of the primary particle\_list which the unsafe particle\_list is a subset of.
As a general rule, you should only use this routine to remove particles from a
simple particle\_list which is a singly referenced primary, safe particle\_list.

\pagebreak
\begin{codedef}
SUBROUTINE setup_partlists()
\HRule

\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{setup\_partlists} is a routine which is called once when {\EPOCH}
first starts. It sets the variable \inlinecode{nvars} which is the number of
REAL(num) values required to contain all the information about a
single particle object needed when a particle is transferred to another
processor. How the information is packed and unpacked from the particle object
into an array of REAL(num) values is controlled in the functions
\inlinecode{pack\_particle} and \inlinecode{unpack\_particle}.
\\[0.5cm]
{\Large Notes\\}
If the particle type gains additional properties as the result of preprocessor
directives then there should be a line which increments \inlinecode{nvars} by
the correct number when that preprocessor directive is active. For example:
\begin{boxverbatim}
#ifdef PER_PARTICLE_CHARGEMASS
  nvar = nvar+2
#endif
\end{boxverbatim}

\pagebreak
\begin{codedef}
SUBROUTINE   pack_particle(data, a_particle)
SUBROUTINE unpack_particle(data, a_particle)
\HRule
REAL(num), DIMENSION(:), INTENT(INOUT) :: data
TYPE(particle), POINTER :: a_particle
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{pack\_particle} and \inlinecode{unpack\_particle} are subroutines
which are used to copy all the information about a particle
necessary for the particle to be transferred to another processor into a
temporary array before sending to another processor. If a new particle property
has been added to the particle then these routines must be modified to allow
the copying of the new data into the array. The parameter \inlinecode{data} is
a REAL(num) array of length \inlinecode{nvars} and is the array into which the
data either must be packed or from which it must be
unpacked. \inlinecode{a\_particle} is the particle object which must either have
its data copied into the array or be
populated with data from the array. No restriction is placed on how the
data should be packed into the data array, but obviously
\inlinecode{pack\_particle} and \inlinecode{unpack\_particle} must be inverse
operations so that particles packed by one processor can be unpacked correctly
by another processor.
\\[0.5cm]
{\Large Notes\\}
Since it is very unlikely that {\EPOCH} will be run on anything other than a
homogeneous cluster, it is acceptable to use the Fortran \inlinecode{TRANSFER}
function to pack incompatible data types into the \inlinecode{data} array. Just
make sure that \inlinecode{nvars} is defined in \inlinecode{setup\_partlists}
to be long enough to contain all the information. More documentation on the
\inlinecode{TRANSFER} function (which is rarely used and dangerous!) can be
found at \url{http://www.macresearch.org/%
advanced_fortran_90_callbacks_with_the_transfer_function}.

\pagebreak
\begin{codedef}
SUBROUTINE display_particle(a_particle)
\HRule
TYPE(particle), POINTER :: a_particle
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
Displays the key information about a particle given by the parameter
\inlinecode{a\_particle}. Used by\linebreak \inlinecode{compare\_particles}.
\\[0.5cm]

\begin{codedef}
FUNCTION compare_particles(particle1, particle2)
\HRule
TYPE(particle), POINTER :: particle1, particle2
LOGICAL :: compare_particles
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
Compares all the properties of two particle objects and displays the
information if they don't match. Used internally by
\inlinecode{test\_packed\_particles}. If the particle object is extended then
this routine should also be modified to test for equivalence of the new
properties.
\\[0.5cm]

\begin{codedef}
SUBROUTINE test_packed_particles(partlist, data, &
    npart_in_data)
\HRule
TYPE(particle_list), INTENT(IN) :: partlist
REAL(num), DIMENSION(:), INTENT(IN) :: data
INTEGER(KIND=8), INTENT(IN) :: npart_in_data
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{test\_packed\_particles} is a routine which checks that a packed
array of particles can be successfully unpacked back into particle objects. The
parameters are:
\begin{itemize}
\item \inlinecode{partlist} - The particle\_list corresponding to the original
  unpacked particles.
\item \inlinecode{data} - The REAL(num) array containing the packed data.
\item \inlinecode{npart\_in\_data} - The number of particles which were packed
  into the \inlinecode{data} array.
\end{itemize}
The routine tests that the number of particles in the particle\_list match the
number believed to be in the data array, that the length of the data array is
correct and then unpacks each particle in turn from the data array and uses the
\inlinecode{compare\_particles} function to compare the particles with the
original versions in the particle\_list. If any particles fail the comparison
then an error is output to stdout. The error message includes the processor
rank on which the problem occurs but the routine does not specifically include
any MPI commands, so it is possible to call the routine on a subset of
processors.
\\[0.5cm]

\pagebreak
\begin{codedef}
FUNCTION partlist_send(partlist, dest)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
INTEGER, INTENT(IN) :: dest
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{partlist\_send} is a routine for sending all the particles in the
particle\_list object \inlinecode{partlist} to another processor. The
destination processor is identified by its rank which is given by the
\inlinecode{dest} parameter. The routine does not destroy the particle\_list
object which is given to it.
\\[0.5cm]
{\Large Notes\\}
\inlinecode{partlist\_send} uses MPI blocking sends, so unless a matching
\inlinecode{partlist\_recv} has been posted on \inlinecode{dest} then the
routine will deadlock. It would be fairly simple to write a non-blocking
version of \inlinecode{partlist\_send}, but at present no need for such a
routine has been found.

\pagebreak
\begin{codedef}
FUNCTION partlist_recv(partlist, src)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist
INTEGER, INTENT(IN) :: src
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{partlist\_recv} is a routine for receiving particles sent by a call
to \inlinecode{partlist\_send} and loading them into the particle\_list object
\inlinecode{partlist}. The source processor is identified by its rank which is
given by the \inlinecode{src} parameter. The routine destroys the particle\_list
which it is given and indeed will leave orphaned particles if it is not given
an empty particle\_list to receive the data.
\\[0.5cm]
{\Large Notes\\}
\begin{itemize}
\item \inlinecode{partlist\_recv} uses MPI blocking receives, so unless a
  matching \inlinecode{partlist\_send} has been posted on \inlinecode{src} then
  the routine will deadlock. It would be fairly simple to write a non-blocking
  version of \inlinecode{partlist\_recv}, but at present no need for such a
  routine has been found.

\item Although it is not possible to directly use \inlinecode{partlist\_recv}
  to add new particles onto an existing particle\_list, it is only two lines to
  do this. First call \inlinecode{partlist\_recv} with a temporary
  particle\_list to receive the data and then use \inlinecode{append\_partlist}
  to attach the particles to the end of the already populated list.
\end{itemize}

\pagebreak
\begin{codedef}
FUNCTION partlist_send_recv(partlist_send, partlist_recv, &
    dest, src)
\HRule
TYPE(particle_list), INTENT(INOUT) :: partlist_send
TYPE(particle_list), INTENT(INOUT) :: partlist_recv
INTEGER, INTENT(IN) :: dest, src
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/partlist.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{partlist\_sendrecv} is a routine equivalent to
\inlinecode{MPI\_SENDRECV} in that it allows overlapping sends and receives to
be written in a single line rather than the end user having to split processors
into red/black ordered pairs for communication. It sends the particle data in
\inlinecode{partlist\_send} to the processor with rank \inlinecode{dest} and
receives particle data sent by processor \inlinecode{src} and stores it in the
particle\_list \inlinecode{partlist\_recv}. The routine is destructive to both
sending and receiving particle\_lists, and can lead to orphaned particles if a
filled particle\_list is passed as \inlinecode{partlist\_recv}. this is the
routine which is used in the particle boundary conditions.
\\[0.5cm]
{\Large Notes\\}
\begin{itemize}
\item \inlinecode{partlist\_sendrecv} uses MPI blocking sendrecv commands, so
  should be used in matching pairs or the routine will deadlock.

\item Although it is not possible to directly use
  \inlinecode{partlist\_sendrecv} to add new particles onto an existing
  particle\_list, it is only two lines to do this. First call
  \inlinecode{partlist\_sendrecv} with a temporary particle\_list to receive the
  data and then use \inlinecode{append\_partlist} to attach the particles to
  the end of the already populated list.
\end{itemize}
\pagebreak


\subsection{MPI in {\EPOCH}}
{\EPOCH} is a massively parallel code written using standard MPI1.2, and likely
to be upgraded to MPI2 in the near future. Due to the massively parallel nature
of {\EPOCH}, there are MPI commands scattered throughout many parts of the code,
although the MPI has been hidden as far as possible from the end user. The main
use of MPI occurs during I/O, in the boundary conditions and during load
balancing. The MPI setup routines are all in
\inlinecode{src/housekeeping/mpi\_routines.f90}, and the routines which are
used to create the MPI types used by MPI-IO are in
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}.

\subsubsection{General MPI in {\EPOCH}}
{\EPOCH} uses Cartesian domain decomposition for parallelism and creates an MPI
Cartesian topology using \inlinecode{MPI\_CART\_CREATE}. The use of MPI in
{\EPOCH} is deliberately kept as simple as possible, but there are some points
which must be made and some variables which must be explained.
\begin{itemize}
\item MPI decomposition is reversed compared to array ordering. Due to the
  layout of arrays in Fortran, you get slightly faster performance if you split
  arrays so that the first index remains as long as possible. Since {\EPOCH}
  uses \inlinecode{MPI\_DIMS\_CREATE} to do array subdivision, this means that
  the MPI coordinate system is ordered backwards compared to the main arrays.
  This means that the \inlinecode{coordinates} array which holds the
  coordinates of the current processor in the Cartesian topology is ordered
  as \{coord\_z, coord\_y, coord\_x\}.
\item To make this easier, there are some helper variables. The simplest of
  these just gives the processors attached to each face of the domain on the
  current processor. These variables are named \inlinecode{x\_min, x\_max,
  y\_min, y\_max, z\_min} and \inlinecode{z\_max}.
\item Since it is possible for particles to cross boundaries diagonally there
  is another variable \inlinecode{neighbour} which identifies every possible
  neighbouring processor including those meeting at single edges and at
  corners. \inlinecode{neighbour} is an array which runs (-1:1,-1:1,-1:1) and,
  perhaps inconsistently, is ordered in normal order rather than reversed
  order. This means that \inlinecode{x\_min == neighbour(-1,0,0)} and
  \inlinecode{z\_max == neighbour(0,0,1)}.
\item The variable \inlinecode{comm} is the handle for the Cartesian
  communicator returned from\linebreak MPI\_CART\_CREATE.
\item The variable \inlinecode{errcode} is the standard error variable for all
  MPI communications. However, {\EPOCH} uses the standard
  MPI\_ERRORS\_ARE\_FATAL error handler so this variable is never tested.
\item {\EPOCH} uses a single variable, \inlinecode{status}, to hold all MPI
  status calls. Since there is no non-blocking communication this variable
  is never checked.
\item The rank of the current processor is stored in the variable
  \inlinecode{rank}.
\item The number of processors is stored in \inlinecode{nproc}.
\item The number of processors assigned to any given direction of the Cartesian
  topology is given by \inlinecode{nproc\_\{x,y,z\}}.
\end{itemize}

There are some other variables which are not technically part of the MPI
implementation, but which only exist because the code is running in
parallel. These are
\begin{itemize}
\item #REAL(num) :: {x,y,z}_start_local# - The location of the start of the
  domain on the local processor in real units.
\item #REAL(num) :: {x,y,z}_end_local# - The location of the end of the
  domain on the local processor in real units.
\item #INTEGER, DIMENSION(1:nproc{x,y,z}) :: cell_{x,y,z}_start# - The cell
  number for the start of the local part of the global array in each direction.
\item #INTEGER, DIMENSION(1:nproc{x,y,z}) :: cell_{x,y,z}_end#
  - The cell number for the end of the local part of the global array in each
  direction.
\end{itemize}

\subsubsection{\inlinecode{mpi\_routines.f90}}
\inlinecode{mpi\_routines.f90} is the file which contains all the MPI setup
code. It contains the following routines:
\begin{itemize}
\item mpi\_minimal\_init - Contains code to start MPI enough to
  allow the input deck reader to work. The default {\EPOCH} code setup means
  that it needs to initialise MPI, obtain the rank and the number of processors.
\item setup\_communicator - Routine which creates the Cartesian communicator
  used by the code after the input deck has been parsed. It also populates
  \inlinecode{x\_min, x\_max} etc. It is in its own subroutine so that it can be
  recalled after the start of the window move when the code is using a moving
  window. This is needed since it is valid to have a non-periodic boundary
  before the window starts to move and a periodic boundary afterwards.
\item mpi\_initialise - This routine calls \inlinecode{setup\_communicator} and
  then allocates all the arrays to do with fields, etc. It also sets up the
  particle list objects for each species. If the code is running with only
  manual initial conditions then this routine loads the requested number of
  particles on each processor. Otherwise either the restart or the autoloader
  code load the particles.
\item mpi\_close - This routine performs all the needed cleanup before the
  final call to \inlinecode{MPI\_FINALIZE}.
\end{itemize}

\subsubsection{\inlinecode{mpi\_subtype\_control.F90}}
This file contains all the routines which are used to create the MPI types
which are used in the SDF I/O system. Most of the routines in this section are
used to create the types used for writing the default variables and,
when modifying the code, it is possible to output anything which has the same
shape and size on disk as the default variables without ever having to use the
routines in this file. However, if you are creating more general modifications
which can include variables of different sizes with different layouts across
processors then you may wish to use these routines to create new MPI types which
match your data layout. Any valid MPI type describing the data layout will work
with the SDF library, so there is no absolute need to use these routines. Only
the general purpose subroutines are described here, since most of the other
routines are fairly clear and use these routines internally.

\pagebreak
\begin{codedef}
FUNCTION create_particle_subtype(npart_local)
\HRule
INTEGER(KIND=8), INTENT(IN) :: npart_local
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{create\_particle\_subtype} is a routine which creates an MPI type
representing particles which are spread across different processors with
\inlinecode{npart\_local} particles on each
processor. \inlinecode{npart\_local} does not have to be the same number on all
processors.
\\[0.5cm]
{\Large Notes\\}
If you use this routine to write data from multiple species of particle then
the data will be written out in a way which is unhelpful for data analysis,
since the layout will be ``All particles on processor 1, All Particles on
processor 2 etc.'' rather than ``All of species 1, All of species 2''. To create
this type of layout use \inlinecode{create\_ordered\_particle\_subtype}

\pagebreak
\begin{codedef}
FUNCTION create_ordered_particle_subtype(n_species_dump, &
    npart_local)
\HRule
INTEGER, INTENT(IN) :: n_species_dump
INTEGER(KIND=8), DIMENSION(n_species_dump), &
    INTENT(IN) :: npart_local
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{create\_ordered\_particle\_subtype} is a routine which creates an
MPI type representing particles from \inlinecode{n\_species\_dump} which are
spread across different processors with \inlinecode{npart\_local(ispecies)}
particles of each species on each processor. \inlinecode{npart\_local} does not
have to be the same number on all processors and does not have to be the same
number for each species.
\\[0.5cm]
{\Large Notes\\}
This routine causes the data to be written to disk as ``All of species 1, All of
species 2 etc.'' as opposed to \inlinecode{create\_particle\_subtype}. It does,
however, need rather more memory and is slower.

\pagebreak
\begin{codedef}
FUNCTION create_field_subtype(n{x,y,z}_local, &
    cell_start_{x,y,z}_local)
\HRule
INTEGER, INTENT(IN) :: n_x_local, n_y_local, n_z_local
INTEGER, INTENT(IN) :: cell_start_x_local
INTEGER, INTENT(IN) :: cell_start_y_local
INTEGER, INTENT(IN) :: cell_start_z_local
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/housekeeping/mpi\_subtype\_control.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{create\_field\_subtype} is a routine which creates an MPI type
representing a field that is defined across some or all of the processors. The
\inlinecode{n\_\{x,y,z\}\_local} parameters are the number of points in the x,
y, z directions (if they exist in the version of the code that you are working
on) that are on the local processor. The
\inlinecode{cell\_start\_\{x,y,z\}\_local} parameters are the offset of the
top, left, back corner of the local subarray in the global array that would
exist if the code was running on one processor. This is an {\it offset}, not a
position and so it begins at \{0,0,0\} NOT \{1,1,1\}.
\\[0.5cm]
{\Large Notes\\}
In EPOCH3D there is also a routine called
\inlinecode{create\_field\_subtype\_2d} which is exactly equivalent to
\inlinecode{create\_field\_subtype} in EPOCH2D and is used for writing the 2D
distribution functions. At present, there are not equivalent 1D functions
except in EPOCH1D, but these could easily by added if required.

\pagebreak

\subsection{The load balancer}
One of the major limiting factors in the scalability of PIC codes is load
balancing. Due to the synchronisation of the currents required for the update
of the EM fields the entire code runs at the speed of the slowest
process. Since most of the time in the main {\EPOCH} cycle is taken by the
particle pusher, this equates to the process with the highest number of
particles being the slowest. Since the location of particles is dependent upon
the solution of the problem under consideration, in general the code will not
have exactly the same number of particles on each processor. The load balancer
is used to move the inter-processor boundaries so that the number of particles
is as close to the same on each processor as possible. The load balancer is
invoked at the start of the code and when the ratio of the least loaded
processor to the most loaded processor falls below a user specified critical
point.\\

{\EPOCH}'s load balancer works by rearranging the processor boundaries in 1D
sweeps in each direction, rather than attempting to perform multidimensional
optimisation. Also, at present the MPI in {\EPOCH} requires each processor to be
simply connected at every point, so it must have one processor to the left, one
to the front etc. which introduces a further restriction on the load
balancer. Otherwise, the load balancer is fully general. The load balancing
sweep is illustrated in Figure~\ref{sweep}.
The load balancer is
implemented in the file \inlinecode{src/housekeeping/balance.F90} and is called
by the routine \inlinecode{balance\_workload(override)}. The parameter
\inlinecode{Override} is used to force the code to perform a load balancing
sweep even when it would normally determine that the imbalance is not large
enough to force a load balancing sweep. Although the load balancer is hard
coded to load balance in all available directions, the code is written in such
a way that it is possible to modify the code to load balance in only one
direction, or to automatically determine which single direction gives the best
performance.

\captionedimage{./images/sweep}{sweep}{Illustration of the load balancing sweep}

The details of the load balancer are fairly intricate, and if major
modification to the load balancer is required, it is recommended that the
original authors be contacted for detailed advice on how to proceed. However,
the general layout of the routine is as follows.

\begin{itemize}
\item Use MPI\_ALLGATHER to get the total number of particles on each processor
  and determine the global minimum and maximum number of particles. If the
  ratio of the minimum to the maximum is above the load balance threshold then
  just return from the subroutine.
\item The code uses the routines \inlinecode{get\_density\_in\_x},
  \inlinecode{get\_density\_in\_y} and \inlinecode{get\_density\_in\_z} to
  determine the pseudoparticle number density along each direction. Each of
  these routines integrates in both other directions.
\item This section of the code fills the arrays \inlinecode{starts\_\{x,y,z\}}
  and \inlinecode{ends\_\{x,y,z\}}. These arrays contain the starting and
  ending cell numbers of the hypothetical global array in each direction for
  each processor.
\item The routine \inlinecode{redistribute\_fields} is then called to move the
  information about field variables which cannot be recalculated. If new field
  variables are created that cannot be recalculated after the load balancing is
  completed then \inlinecode{redistribute\_fields} has to be modified for these
  new variables.
\item The next section of the routine deals with those variables which can be
  recalculated after the load balance sweep is complete, such as the coordinate
  axes and the arrays which hold the particle kinetic energy.
\item The penultimate section of the routine then changes the variables which
  tell the code where the edges of its domain lie in real space to reflect the
  changed shape of the domains.
\item The final part is the call to \inlinecode{distribute\_particles} which
  moves the particles to the new processor. Once this is
  finished, the code should have as near as possible the same number of
  particles on each processor.
\end{itemize}

Most of the load balancer is purely mechanical and should only be changed if
the way in which the code is to perform load balancing is fundamentally
altered. The redistribution of particles that takes place in
\inlinecode{distribute\_particles} uses the standard particle\_list objects, so
that if the necessary changes have been made to the routines in
\inlinecode{src/housekeeping/partlist.F90} to allow correct
boundary swaps of particles then the load balancer should work with no further
modification. The only part of the load balancer which should need changing is
\inlinecode{redistribute\_fields} which requires explicit modification if new
field variables are required. For fields which are the same shape as the main
array there is significant assistance provided within the code to make the
re-balancing simpler. There are also routines which can help with re-balancing
variables which are the size of only one edge or face of the domain. Variables
which are of a completely different size but still need to be rebalanced when
coordinate axes move have to have full load balancing routines implemented by
the developer. This is beyond the scope of this manual and any developer who
needs assistance with development such a modification should contact the
original author of the code. The field balancer is fairly simple and mostly
calls one of three routines: \inlinecode{redistribute\_field} and either
\inlinecode{redistribute\_field\_2d} or \inlinecode{redistribute\_field\_1d}
depending on the dimensionality of your code. To redistribute full field
variables the routine to use is \inlinecode{redistribute\_field}, and an
example of using the code looks like:
\begin{boxverbatim}
  temp = 0.0_num
  CALL redistribute_field(new_domain, bz, temp)
  DEALLOCATE(bz)
  ALLOCATE(bz(-2:nx_new+3,-2:ny_new+3))
  bz = temp
\end{boxverbatim}

In this calling sequence the
\inlinecode{redistribute\_field} subroutine is used to redistribute the field
\inlinecode{bz}, and the newly redistributed field is copied
into \inlinecode{temp}; an array which is already allocated to the
correct size. The \inlinecode{new\_domain} parameter is an array indicating the
location of the start and end points of the new domain for the current processor
in gridpoints offset from the start of the global array. It is passed into the
\inlinecode{redistribute\_fields} subroutine as a parameter from the
\inlinecode{balance\_workload} subroutine and should not be changed. The
\inlinecode{temp} variable is needed since Fortran standards before Fortran2000
do not allow the deallocation and reallocation of parameters passed to a
subroutine. There is a more elegant solution, where \inlinecode{temp} is
hidden inside the \inlinecode{redistribute\_field} subroutine. However, support
for this in current Fortran2000 implementations is unreliable.\\

The routine for re-balancing variables which lie along an edge of the domain are
very similar and are demonstrated in the \inlinecode{redistribute\_fields}
subroutine for lasers attached to different boundaries. It is
recommended that a developer examine this code when developing new routines.

\subsection{{\EPOCH} I/O}
\label{sec:io}

{\EPOCH} uses a file format called {\it SDF} which was custom developed for use
with codes developed by CFSA at the University of Warwick. The internal
structure of this format is documented in \sect{sdf},
but it is not necessary to have a full understanding of the file format
to add the output of new variables to {\EPOCH}. To add a new variable to
{\EPOCH}'s output, you simply have to use the supplied subroutines of the SDF
library which is part of {\EPOCH}. The file output from {\EPOCH} takes place in
{\it diagnostics.F90}, so to add new variables to the output you must
add additional code there. Looking through the listings, you will see two lines:
\begin{boxverbatim}
  CALL sdf_open(sdf_handle, filename, rank, comm, c_sdf_write)

  CALL sdf_close(sdf_handle)
\end{boxverbatim}

These, as may be expected, are the commands which open and close the SDF file.
It is perfectly possible to create new SDF files containing only your own data.
There are various commands in-between which actually write the data into the
file. These commands start with \inlinecode{sdf\_} to ensure that the don't
conflict with any other subroutine names in the code.
Some more complex areas of I/O, such as the particle probes
and the distribution function routines call other subroutines in their
respective source files, but these too make use of the SDF routines to actually
write data. A user should never try to write data directly to the output file,
since this will cause problems with internal parts of the SDF format and
generate a nonsensical file.

\subsubsection{dumpmask}
Looking through {\it diagnostics.F90} there are many lines with commands which
begin \inlinecode{sdf\_}, but are all prepended with a command which looks
like:
\begin{boxverbatim}
  IF (IAND(dumpmask(c_dump_id), code) .NE. 0) THEN
\end{boxverbatim}
This is the method by which {\EPOCH} allows the end user to specify whether a
variable should be dumped, and whether it should only be dumped at
full/partial/restart dumps. #dumpmask# is an integer array, the length of
which is defined by the variable \inlinecode{num\_vars\_to\_dump} in
\inlinecode{shared\_data.f90} and contains the bitmask representing all the
types of output which should be written for the associated variable. The
possible values in the bitmask are:

\begin{itemize}
\item \inlinecode{c\_io\_never} - Never dump this variable.
\item \inlinecode{c\_io\_always} - Dump this variable at every output dump.
\item \inlinecode{c\_io\_full} - Dump this variable at full dumps.
\item \inlinecode{c\_io\_restartable} - Dump this variable for restart dumps.
\item \inlinecode{c\_io\_species} - If meaningful for this variable, write
  information for each species rather than integrated over all species.
\end{itemize}

The \inlinecode{c\_dump\_id} entry is a constant defined in
\inlinecode{shared\_data.f90} which identifies the variable's index within
this dumpmask.

When adding a new variable to be written to disk, the value of
\inlinecode{num\_vars\_to\_dump} should be increased to match the number of new
written variables. Next, open the file \inlinecode{src/deck/deck\_io\_block.F90}
and find the line:
\begin{boxverbatim}
  CHARACTER(LEN=entry_length), DIMENSION(io_block_elements) :: io_block_name = ...
\end{boxverbatim}

Simply add new strings for your new variables to the end of the
definitions along with its \inlineemph{c\_dump\_id} value. These new variable
names should then be placed in your input decks
in the same place as the existing I/O information and take the same parameters.

\subsection{Adding a derived variable}

As already stated, derived variables are variables which are defined on the
Cartesian spatial grid but are not directly updated by the solver. They are
calculated when needed for output or for use in other physics packages. The
final form of a derived variable is an array on each processor with the same
size as the field arrays.

\subsubsection{Writing your variable to disk}
A derived variable is defined on the same grid as the main simulation variables
and must be written to disk in such a way as to stitch the parts of the grid
from each processor together. This is achieved using the routine:
\begin{boxverbatim}
CALL sdf_write_plain_variable(sdf_handle, id, name, units, dims, stagger, &
    grid_id, variable, subtype_field, subarray_field)
\end{boxverbatim}
The parameters have the following types and meanings:

\begin{itemize}
\item block\_id - The id name of the variable. This character string is a
  unique identifier for
  the variable in the file enabling a program to retrieve it later. Once
  defined it should not change so that newer versions of {\EPOCH} can still
  identify variables generated by older versions.
\item name - The display name of the variable. This character string is
  the name that is used
  by external programs to display an identifying name for the variable. If it
  contains '/' characters then these are used by VisIt to group the variables.
\item units - The units of the variable. This character string is used when
  displaying the data units. For most variables in {\EPOCH} these
  are SI units.
\item dims - An nD integer array containing the GLOBAL length of the variable
  across all processors. In {\EPOCH} a variable actually called ``dims'' exists
  for variables which are the same size as the default field variables.
\item stagger - An integer constant containing the stagger of a variable from
  the cell centre of a cell. This property lets external programs know the
  position of a variable on the grid.
\item grid\_id - The id name of the grid to which the variable is attached. In
  {\EPOCH}, the main grid is just called ``grid''. Note that this property is
  case sensitive.
\item variable - The actual variable to be written to disk.
\item subtype\_field - This is an MPI type representing the layout of the data
  across the processors. For a standard field variable, there is an
  automatically created type called ``subtype\_field'' which should be used
  here.
\item subarray\_field - This is an MPI type representing the section of
  the ``variable'' parameter to be written. For a standard field variable,
  there is an automatically created type called ``subarray\_field'' which
  should be used here.
\end{itemize}

It's probably easiest to read the diagnostics.f90 file and see how the code
implements the output of simple variables like ex or ey for an example of how
this works. Once the appropriate sdf\_write call has
been added to the code, there is no further work
to be done. The IDL, MatLab and VisIt routines will all read the existence of
the variable from the metadata in the SDF file, and it will now be available to
view in all SDF reading packages.

There is a working variable called \inlinecode{array} which is large enough to
store a derived variable. It is
therefore recommended that to calculate derived variables a new subroutine
should be created which populates \inlinecode{array} with the required variable
and then writes it to disk. An example would look like:
\begin{boxverbatim}
IF (IAND(dumpmask(c_dump_myvar), code)) THEN
  CALL calc_my_variable(array)

  CALL sdf_write_plain_variable(sdf_handle, 'my_var', 'Mine/variable', 'unit',
      dims, c_stagger_cell_centre, 'grid', array, subtype_field, subarray_field)
ENDIF
\end{boxverbatim}
where \inlinecode{calc\_my\_variable} is a function which calculates the
variable which you wish to write. The form of this function depends on the type
of variable to be calculated and is given in the next section.

\subsection{Adding a particle variable}
The next simplest type of output to add is a new property for all particles. To
add new particle variables to the output dump, two things are needed: a call
to the SDF command to write the data and an iterator function to iterate
through all the particles. The iterators are stored in the file
{\it iterators.F90}. An example iterator is:
\begin{boxverbatim}
  ! iterator for particle momenta
  FUNCTION iterate_px(array, n_points, start)

    REAL(num) :: iterate_px
    REAL(num), DIMENSION(:), INTENT(INOUT) :: array
    INTEGER, INTENT(INOUT) :: n_points
    LOGICAL, INTENT(IN) :: start
    TYPE(particle), POINTER, SAVE :: cur
    TYPE(particle_list), POINTER, SAVE :: current_list
    INTEGER :: part_count

    IF (start)  THEN
      CALL start_particle_list(current_family, current_list, cur)
    ENDIF

    part_count = 0
    DO WHILE (ASSOCIATED(current_list) .AND. (part_count .LT. n_points))
      DO WHILE (ASSOCIATED(cur) .AND. (part_count .LT. n_points))
        part_count = part_count + 1
        array(part_count) = cur%part_p(1)
        cur=>cur%next
      ENDDO
      ! If the current partlist is exhausted, switch to the next one
      IF (.NOT. ASSOCIATED(cur)) CALL advance_particle_list(current_list, cur)
    ENDDO
    n_points = part_count

    iterate_px = 0

  END FUNCTION iterate_px
\end{boxverbatim}

This is a fairly complicated routine which includes code for dealing with the
possibility of particle species not being dumped, and other complicated
book keeping. Luckily, there is only one line in the routine which needs to
change to output a new variable. The is the line:
\begin{boxverbatim}
        array(part_count) = cur%part_p(1)
\end{boxverbatim}

To write a new iterator, you just have to copy the skeleton of an existing
iterator and change this line to copy your particle property into the ``array''
array. The details of the particle structure's contents is explained in
\sect{partrep}. Once your new iterator has been written and added into
the {\it iterators.F90} file, it's time to add the SDF routine to actually
write the data. The routine is:
\begin{boxverbatim}
    CALL write_particle_variable(c_dump_id, code, name, iterator)
\end{boxverbatim}

The parameters this time are
\begin{itemize}
\item c\_dump\_id - The index into the dumpmask for this variable.
\item code - The dump code for the current output dump.
\item name - The display name to use for this variable.
\item iterator - The name of the iterator function that you created in
  the previous step. Note that this is not a string but simply the name of the
  function.
\end{itemize}

Once again, looking at how this is implemented for one of the existing
variables (e.g. px) is probably the most enlightening way to see how it
works. As for the fluid variables, the new variable will appear in IDL, MatLab
and VisIt.

At this point it is possible to write any property which is similar to the
default field variables or the default particle properties. It becomes slightly
more challenging if you want to write other types of variable into an output
file.

\pagebreak

\subsection{Precompiler directives}
{\EPOCH} uses precompiler directives to switch certain features of the code on
or off. The precompiler directives all begin with a ``\#'' character and look
like:
\begin{boxverbatim}
#ifdef MY_PRECOMPILER_DIRECTIVE
  some_fortran_of_some_kind
#else
  some_other_fortran
#endif
\end{boxverbatim}
They behave in a very simple manner. The precompiler runs BEFORE the
Fortran compiler and, until it reaches a precompiler directive, it just creates
a temporary file which is an exact copy of the source file. When it reaches a
precompiler directive of this kind it treats the \#ifdef commands as
if/then/else statements. If
\inlinecode{MY\_PRECOMPILER\_DIRECTIVE} was defined in the makefile then
\inlinecode{SOME\_Fortran\_OF\_SOME\_KIND} is pushed out to the temporary
file. Otherwise \inlinecode{SOME\_OTHER\_Fortran} is written instead.
The precompiler directives themselves are never output to the temporary
file. Once then preprocessor has finished, it passes this temporary file
to the Fortran compiler which can then compile it just like any other
standard Fortran file.

\subsubsection{When to use precompiler directives}
\begin{itemize}
\item When adding properties to the \inlinecode{particle} structure.
\item When adding time consuming calculations to the particle pusher.
\end{itemize}
Precompiler directives should be avoided when there is no significant
performance gain or memory reduction to be made. Wherever possible, optional
features should be controlled by parameters in the input deck.

\subsubsection{The directive printing routine on code startup}
When {\EPOCH} starts it prints the precompiler directives that it was built with
and what they mean. This isn't required, but has proved very useful and is
implemented in a very simple way. Just open the file
\inlinecode{src/housekeeping/welcome.F90} and find the subroutine
\inlinecode{compiler\_directives}. There are a large block of precompiler
directives which read:
\begin{boxverbatim}
#ifdef TRACER_PARTICLES
    defines = IOR(defines, c_def_tracer_particles)
    WRITE(*, *) "Tracer particle support -DTRACER_PARTICLES"
#endif
\end{boxverbatim}

Simply add a new element to the end of the list.
\begin{boxverbatim}
#ifdef MY_PRECOMPILER_DIRECTIVE
    defines = IOR(defines, c_def_my_precompiler_directive)
    WRITE(*,*) "My new physics -DMY_PRECOMPILER_DIRECTIVE"
#endif
\end{boxverbatim}

You will also need to add #c_def_my_precompiler_directive# to the list of
constants in\linebreak #src/shared_data.F90#.

\subsubsection{Precompiler directives and the input deck}
In theory, it is possible for someone to request a feature of the code in the
input deck which this version hasn't been compiled with. In this
case, there is a special error code \inlinecode{c\_err\_pp\_options\_wrong}
which causes the input deck parser to give a meaningful error. You should also
set the string\linebreak \inlinecode{extended\_error\_string} to be the define
command for the missing preprocessor directive i.e\linebreak
\inlinecode{extended\_error\_string = "-DMY\_PRECOMPILER\_DIRECTIVE"}

\section{{\EPOCH} front end programming}

\subsection{Strings in {\EPOCH}}
Fortran is not a language famous for its string handling capabilities, but due
to the presence of the input deck {\EPOCH} has fairly extensive string handling
routines. Strings used are all of the standard Fortran \inlinecode{CHARACTER}
type and are defined as:
\begin{boxverbatim}
CHARACTER(LEN=entry_length) :: string
\end{boxverbatim}
\inlinecode{entry\_length} is a global constant defined in
\inlinecode{src/shared\_data.F90} which can be increased to allow {\EPOCH} to
handle longer strings. There may be reasons to increase this length if you wish
to use long complex expressions in the input deck. Note that many Fortran
compilers do not allow strings to exceed 512 characters in length.

\subsubsection{{\EPOCH} string handling routines}

Listed here are the string handling routines (other than those in the core
maths parser routine which are documented elsewhere) which are currently used
in {\EPOCH}.

\pagebreak
\begin{codedef}
FUNCTION str_cmp(str_in, str_test)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in, str_test
LOGICAL :: str_cmp
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{str\_cmp} is the routine which does all the string comparisons in
{\EPOCH}. It deals with leading and trailing whitespace automatically and
tests for length differences. It does not test for strings being
valid substrings of each other, only for full equality.
\\[0.5cm]
{\Large Notes\\}
A developer should always use \inlinecode{str\_cmp} rather than doing their own
string testing to ensure consistent behaviour across the entire {\EPOCH} code
base.

\pagebreak
\begin{codedef}
FUNCTION as_real_simple(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
REAL(num) :: as_real_simple
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_real\_simple} is a routine to convert a string into a real
number without invoking the maths parser. It can cope with standard form as
well as simple decimal reals. It is significantly faster than the maths parser,
but should only be used when the user explicitly {\it shouldn't} be able to use
a mathematical expression. If the string cannot be parsed then the routine sets
the bitmask \inlinecode{c\_err\_bad\_value} on the parameter \inlinecode{err}
\\[0.5cm]
{\Large Notes\\}
If you have a string which has to be converted into a real quickly then this is
the routine to use. You probably shouldn't use it when parsing a string from
the input deck, since there is no reason to restrict the user from specifying a
mathematical expression. The routine is used inside the maths parser to parse
simple numbers.

\pagebreak
\begin{codedef}
FUNCTION as_integer_simple(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
INTEGER :: as_integer_simple
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_integer\_simple} is a routine to convert a string into an
integer without invoking the maths parser. It can cope with standard form as
well as simple decimal integers. It is significantly faster than the maths
parser, but should only be used when the user explicitly {\it shouldn't} be
able to use a mathematical expression. If the string cannot be parsed then the
routine sets the bitmask \inlinecode{c\_err\_bad\_value} on the parameter
\inlinecode{err}
\\[0.5cm]
{\Large Notes\\}
This routine is used internally in several parts of the code when parsing
things like numbers which are parts of strings (i.e. the 1 in
\inlinecode{direction1} for distribution functions). It probably shouldn't
be used to directly parse input deck parameters, since there is no reason to
restrict the user from specifying mathematical expressions.

\pagebreak
\begin{codedef}
FUNCTION as_long_integer_simple(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
INTEGER(KIND=8) :: as_long_integer_simple
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_long\_integer\_simple} is equivalent to
\inlinecode{as\_integer\_simple}, but returns the larger
\inlinecode{INTEGER(KIND=8)} rather than a normal \inlinecode{INTEGER(KIND=4)}.
\\[0.5cm]
{\Large Notes\\}

\pagebreak
\begin{codedef}
FUNCTION as_direction(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
INTEGER :: as_direction
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_direction} is used when assigning a laser to a boundary and
recognises the strings
\begin{itemize}
\item x\_min or left - c\_bd\_x\_min.
\item x\_max or right - c\_bd\_x\_max.
\item y\_min or down - c\_bd\_y\_min.
\item y\_max or up - c\_bd\_y\_max.
\item z\_min or back - c\_bd\_z\_min.
\item z\_max or front - c\_bd\_z\_max.
\end{itemize}
It returns the associated direction code (given after the dash in the
definition).
\\[0.5cm]
{\Large Notes\\}
If you're writing code which requires attaching something to a boundary,
whether a boundary condition, a diagnostic or some other routine, then this is
the routine that should be used. Note that in order to prevent confusion when
moving input decks between different dimension versions of {\EPOCH}, each code
only recognises the strings for boundaries that it actually has.

\pagebreak
\begin{codedef}
FUNCTION as_logical(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
Logical :: as_logical
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_logical} simply tests for the strings ``T'' and ``F'' to
determine a boolean value. The default behaviour of \inlinecode{as\_logical} is
to treat any string that isn't ``T'' as a false value.
\\[0.5cm]
{\Large Notes\\}
You should use this rather than using a 0/1 boolean flag in the input deck for
consistency.

\pagebreak
\begin{codedef}
SUBROUTINE split_off_int(str_in, str_out, int_out, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
CHARACTER(LEN=entry_length), INTENT(OUT) :: str_out
INTEGER, INTENT(OUT) :: int_out
INTEGER, INTENT(INOUT) :: err
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{split\_off\_int} is a routine which splits a string of the format
{\bf string{\it n}} into a string {\bf string} and an integer {\it n} which are
returned separately in the \inlinecode{str\_out} and \inlinecode{int\_out}
parameters respectively.  If it can't split the string successfully then it
sets the \inlinecode{c\_err\_bad\_value} bitfield of the err parameter.
\\[0.5cm]
{\Large Notes\\}
This is used in the core of the deck parser to deal with blocks like the
numbered species blocks in the initial conditions, and also in some of the
specific block parsers. Again, this routine should be used to split strings
like this rather than coding a new routine.

\pagebreak
\begin{codedef}
SUBROUTINE split_range(str_in, real1, real2, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
REAL(num), INTENT(OUT) :: real1, real2
INTEGER, INTENT(INOUT) :: err
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{split\_range} is a routine which splits a string of the format
{(\bf{\it n}, {\it m})} into two reals {\it n} and {\it m} which are returned
separately in the \inlinecode{real1} and \inlinecode{real2} parameters
respectively.  If it can't split the string successfully then it sets the
\inlinecode{c\_err\_bad\_value} bitfield of the err parameter.
\\[0.5cm]
{\Large Notes\\}
This is used when specifying ranges in the input decks at present. Any
ranges which should be specified in a single parameter should be specified in
this form and this routine used to split the string.\\ {\bf IMPORTANT NOTE. This
routine has proved somewhat unsatisfactory and may be replaced by another
routine in the future. It is expected that the function will have the same name
and behaviour, but might have subtle differences.}

\pagebreak
\begin{codedef}
FUNCTION as_integer(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
INTEGER :: as_integer
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_integer} is the routine which returns integers from strings
using the maths parser. If a mathematical expression resolves to a non-integer
result then this routine rounds to the NEAREST integer. There are explicit
rounding routines in the maths parser to force other behaviour.
\\[0.5cm]
{\Large Notes\\}
This routine should be used when evaluating most strings into integers. Note
that this routine evaluates spatially dependent quantities at (0,0) on each
processor, so will give unpredictable results when spatially dependent
quantities are given to it (like number\_density, bx etc.). To evaluate a spatially varying
quantity use \inlinecode{evaluate\_string\_in\_space}.

\pagebreak
\begin{codedef}
FUNCTION as_long_integer(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
INTEGER(KIND=8) :: as_long_integer
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_long\_integer} is the routine which returns long integers from
strings using the maths parser. If a mathematical expression resolves to a
non-integer result then this routine rounds to the NEAREST integer. There are
explicit rounding routines in the maths parser to force other behaviour.
\\[0.5cm]
{\Large Notes\\}
This routine should be used when evaluating strings which are likely to be too
large to be stored in an INTEGER(KIND=4).

\pagebreak
\begin{codedef}
FUNCTION as_real(str_in, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
INTEGER, INTENT(INOUT) :: err
REAL(num) :: as_real
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{as\_real} is the routine which returns reals from strings using the
maths parser.
\\[0.5cm]
{\Large Notes\\}
This routine should be used when evaluating most strings into reals. Note that
this routine evaluates spatially dependent quantities at (0,0) on each
processor, so will give unpredictable results when spatially dependent
quantities are given to it (like number\_density, bx etc.). To evaluate a spatially varying
quantity use \inlinecode{evaluate\_string\_in\_space}.

\pagebreak
\begin{codedef}
SUBROUTINE evaluate_string_in_space(str_in, data_out, &
    xrange, {yrange}, {zrange}, err)
\HRule
CHARACTER(LEN=entry_length), INTENT(IN) :: str_in
REAL(num), DIMENSION(1:,{1:},{1:}), INTENT(OUT) :: data_out
INTEGER, DIMENSION(2), INTENT(IN) :: xrange, {yrange}
INTEGER, DIMENSION(2), INTENT(IN) :: {zrange}
INTEGER, INTENT(INOUT) :: err
\end{codedef}
\vspace{1cm}
{\Large Location\\}
\inlinecode{src/deck/strings\_advanced.F90}\\
\\[0.5cm]
{\Large Description\\}
\inlinecode{evaluate\_string\_in\_space} is a routine which is used to evaluate
a tokenized maths expression over a region of the domain. The dimensionality of
\inlinecode{data\_out}, and the presence or absence of \inlinecode{yrange} and
\inlinecode{zrange} depend on the dimensionality of the code being used. The
\inlinecode{{\it $\alpha$}range} parameters represent the indices in that
direction over which the expression should be evaluated. For example, in 2D to
evaluate an expression over the entire domain, the code would look like:
\begin{boxverbatim}
REAL(num), DIMENSION(:,:), ALLOCATABLE :: data
ALLOCATE(data(0:nx+1,0:ny+1)
CALL evaluate_string_in_space(string, data, (/0,nx+1/), (/0:ny+1/), err)
\end{boxverbatim}
{\Large Notes\\}
This routine is suitable to evaluate expressions over a subsection or all of
the domain, and is used in this way in the initial condition deck parser
routines. However, the routine does have one significant weakness, which is
that it tokenizes the string each time it is called. Tokenizing the string is a
time consuming process, so if the string is to be evaluated several times for
different reasons (for example, the time profile for the laser) then a
different procedure should be followed using the lower level parser routines,
which are described in \sect{maths}.
\pagebreak

\subsection{Permanently adding blocks to the input deck}

While using the \inlinecode{custom\_deck} subroutine is a good way of passing
parameters into the code or for temporary additions, it is not suitable for
permanent additions to the code. Adding new blocks to the code permanently is
very similar to doing it temporarily, but requires changes to some of the
subroutines in \inlinecode{deck.F90}.\\

There are four subroutines which may need to be changed to add new blocks to
the deck. These are
\begin{itemize}
\item \inlinecode{start\_block(block\_name)} - Called when the deck directive
  \inlinecode{begin:{\it block\_name}} appears in a deck file.
\item \inlinecode{end\_block(block\_name)} - Called when the deck directive
  \inlinecode{end:{\it block\_name}} appears in a deck file.
\item \inlinecode{handle\_block(block\_name, block\_element, block\_value)} -
  Called once for each element in a block.
\item \inlinecode{check\_compulsory\_blocks(errcode\_deck)} - Called once when
  the deck file has been read to check that all necessary blocks have been
  populated.
\end{itemize}

There is one final variable which is important for modifying the input deck,
\inlinecode{deck\_state}. The input deck parser routine used to read the main
input deck uses the variable \inlinecode{deck\_state} to
determine which stage of parsing the deck is required. The possible values of
\inlinecode{deck\_state} are

\begin{itemize}
\item c\_ds\_deck - The main input deck.
\item c\_ds\_ic - The initial conditions.
\item c\_ds\_eio - The extended I/O.
\end{itemize}
These constants are defined in \inlinecode{shared\_data.F90} and if new files
need to be read, then new variables should be created in the same place with
similar names using the \inlinecode{c\_ds\_} prefix.

The layout of \inlinecode{start\_block} and \inlinecode{end\_block} is very
simple, and just tests \inlinecode{deck\_state} to make sure that the deck
reader is reading the right file. It then uses \inlinecode{str\_cmp} to test the
block name and if necessary calls the correct routine to deal with the
start or finish of a block.

The main routine which needs to be explained is \inlinecode{handle\_block},
which is the function that determines which subroutine to call for parsing the
elements of a given block. The function is very simple and has the same basic
sequence as the \inlinecode{start\_block} and \inlinecode{end\_block}
functions. First determine what file is being parsed by checking
\inlinecode{deck\_state}, then use \inlinecode{str\_cmp} to compare the
\inlinecode{block\_name} parameter with the list of known block names. What
happens next is dependent on exactly what a developer wants their block to do.
At the simplest level the routine simply calls another function which
takes the element\_name and element\_value as
parameters and returns an error code from Appendix A determining the success or
failure of reading the element. Some blocks have slightly more sophisticated
entries in \inlinecode{handle\_deck}, such as the \inlinecode{species} block in
the initial conditions file reader. This strips the species number off the end
of the block name and passes it to the handler routine. The routines that deal
with constants are implemented before any tests to
\inlinecode{deck\_state} since it is valid to set constants in any
type of file.

The final routine is \inlinecode{check\_compulsory\_blocks} which is used to
check that all the needed elements of the input deck have been set. A single
parameter \inlinecode{errcode\_deck} is passed in. Once again, the routine
checks \inlinecode{deck\_state} to make sure that it is testing the correct
type of input deck file. It then goes through and calls functions to check that
all the necessary parts of a block have been set. The subroutines are contained
in the same file as the routine which is called in \inlinecode{handle\_block} to
handle elements of the block. The error handler functions should return an
error code from Appendix A, usually \inlinecode{c\_err\_missing\_elements}. The
return code from the error handler function should then be \inlinecode{IOR}ed
with \inlinecode{errcode\_deck} to allow error codes to be returned from
several different checks with errors occurring.

\subsubsection{The element handler routines for deck elements}
The exact form of the handler routines is up to the end user. The only {\it
requirements} are that the routine should return an error code detailing
whether or not there are any problems with reading the block and that the error
code should be \inlinecode{c\_err\_none} if either the element name or element
value are the special constant \inlinecode{blank}. The typical implementation
of an element handler routine is shown in the file
\inlinecode{src/deck/deck\_control\_block.f90}, and this general layout should
be copied for compatibility if possible.\\

Sometimes, it is useful to have each new block correspond to a new instance of
an object in the code. An example of this in {\EPOCH} is in
\inlinecode{src/deck/deck\_ic\_laser\_block.f90} where each new laser block in
the input deck corresponds to a new laser being attached to a boundary. This is
accomplished by implementing the lasers as a linked list on each boundary,
with a new laser object being created when a laser block is started, the laser
information being set during the main reader routine, and then the laser being
attached to the linked list by a call to \inlinecode{attach\_laser} in
\inlinecode{src/laser.f90} when the block is ended. When a new laser block is
started the process simply repeats allowing the end user to have as many lasers
as desired.

\subsubsection{Naming new element handler files}
While the name of the function which deals with elements of a new block is up
to the end user, the file should try to follow the form of the existing
names. That is, the name should have the following form, remembering that words
should be spaced out using \_ characters.
\begin{itemize}
\item Begin with \inlinecode{deck\_}.
\item If the block is associated with initial conditions or I/O then there
  should be a code here which details
  when this block is valid. For the existing input deck files this would be
  \subitem \inlinecode{ic\_} for the initial conditions file.
  \subitem \inlinecode{eio\_} for the extended I/O file.
\item The next element should be the name of the block followed by \_.
  i.e. \inlinecode{control\_}.
\item The final element should just be the work \inlinecode{block}.
\end{itemize}

\subsubsection{Adding elements to existing blocks}
The existing blocks in the code are read in the following files
\begin{itemize}
\item \inlinecode{deck\_boundaries\_block.f90} - Input deck boundary block.
\item \inlinecode{deck\_constant\_block.f90} - Sets constants in all deck files.
\item \inlinecode{deck\_control\_block.f90} - Input deck control block.
\item \inlinecode{deck\_eio\_dist\_fn\_block.f90} - dist\_fn blocks.
\item \inlinecode{deck\_eio\_particle\_probe\_block.F90} - probe blocks.
\item \inlinecode{deck\_ic\_external\_block.f90} - Initial conditions deck for
  reading species\_external and\linebreak field\_external blocks.
\item \inlinecode{deck\_ic\_fields\_block.f90} - Initial conditions deck field
  blocks.
\item \inlinecode{deck\_ic\_laser\_block.f90} - Initial conditions deck laser
  blocks.
\item \inlinecode{deck\_ic\_species\_block.f90} - Initial conditions deck
  species\{n\} blocks.
\item \inlinecode{deck\_io\_block.F90} - Input deck output blocks.
\item \inlinecode{deck\_species\_block.F90} - Input deck species blocks.
\item \inlinecode{deck\_window\_block.f90} - Input deck window block.
\end{itemize}

The existing structure of the blocks is simple enough in most cases that it
should be fairly easy to add new elements if needed. The most likely change
needed is to change the list of variables to dump in the \inlinecode{output}
block. How to do this is detailed in \sect{io}.

\subsection{Adding new elements to the maths parser}
Sometimes the complexity in changing the input.deck file is due to the fact that
a function which must be used is fairly complex in form and is not supplied
with the core code. It must therefore be represented in the input deck maths
parser. This can be a significant cause of complexity for some problems, and
in this case, there are three options: Put up with it and implement in the
deck, use the internal initial conditions rather than the deck or extend the
maths parser to include your function. Extending the maths parser can either
be permanent (described later in the manual) or temporary (described
here). Temporarily adding elements to the parser is much the easier. It is
possible to add new constants and functions to the maths parser. It is hoped
that in a future release of {\EPOCH} this will be extended to allow custom
operators as well.\\

As an example, lets look at adding a new function (lorentz) for a
Lorentzian distribution, and adding a new constant, phi.

\subsubsection{Registering your new constant/function}
All of the routines used in extending the maths parser are in the file
user\_interaction/custom\_parser.f90.  Before a new constant or function
can be defined it must be registered. In the registration phase the text
representation of the function or constant is given to the parser subroutines
and the user is returned an integer handle for the registered object. The
numerical handle must be stored so that that all of the functions in this
module can access it, so they should be placed after the \inlinecode{IMPLICIT
NONE} statement at the top of the file and defined as:
\begin{boxverbatim}
INTEGER :: c_func_lorentz
INTEGER :: c_const_phi
\end{boxverbatim}

Note that the names given to the constants is obviously at the developers
discretion, but these names comply with the {\EPOCH} style guide.
Actually registering the objects is done in the \inlinecode{register\_objects}
subroutine which should include lines to register functions and constants.
An example is given below.
\begin{boxverbatim}
SUBROUTINE register_objects

  c_func_lorentz = register_function("lorentz")
  c_const_phi = register_constant("phi")

END SUBROUTINE register_objects
\end{boxverbatim}

Note that the input deck parser is case sensitive, so the strings which are
given to \inlinecode{register\_function} and \inlinecode{register\_constant}
should be in the case that they will appear in the input deck. To follow the
{\EPOCH} style guide this should be all lowercase. At this point, the maths
parser would start to recognise the new function/constant, but would still
give error messages since they haven't yet been implemented.

\subsubsection{Setting up new constants}

Once a new constant has been registered it must be described using the
\inlinecode{custom\_constant} function. In 2D this function looks like:
\begin{boxverbatim}
FUNCTION custom_constant(opcode, ix, iy, errcode)

  INTEGER, INTENT(IN) :: opcode, ix, iy
  INTEGER, INTENT(INOUT) :: errcode
  REAL(num) :: custom_constant

  ! Leave these lines in place. They cause the code to throw an error if
  ! The opcode is unknown
  custom_constant = 0.0_num
  errcode = IOR(errcode, c_err_unknown_element)

END FUNCTION custom_constant
\end{boxverbatim}

The parameters are

\begin{itemize}
\item opcode - The operator code of the constant requested. This will be the
  integer handle returned from \inlinecode{register\_constant}.
\item ix, iy, iz - Some constants are actually evaluated at specific points in
  space and ix, iy, iz are the gridpoint number of the location currently being
  evaluated. If you are specifying a simple constant then just ignore
  these. If your constant does depend upon space then directly subscript your
  array with ix, iy, iz as needed to read the correct location.
\item errcode - The error code which should be passed back to the
  parser. If for some reason you cannot evaluate your constant then you should
  \inlinecode{IOR} errcode with the appropriate error code (all the error
  codes are listed in appendix A). Note that errcode should never be SET to
  any specific error code when extending the parser, since this might
  overwrite errors put in place earlier in the parsing sequence. This is
  different to extending the input deck where the error code is set.
\end{itemize}

The function should just return the evaluated value of the constant requested
by \inlinecode{opcode}. This might look like:
\begin{boxverbatim}
FUNCTION custom_constant(opcode, ix, iy, errcode)

  INTEGER, INTENT(IN) :: opcode, ix, iy
  INTEGER, INTENT(INOUT) :: errcode
  REAL(num) :: custom_constant

  IF (opcode .EQ. c_const_phi) THEN
    custom_constant = pi
    RETURN
  ENDIF

  ! Leave these lines in place. They cause the code to throw an error if
  ! The opcode is unknown
  custom_constant = 0.0_num
  errcode = IOR(errcode, c_err_unknown_element)

END FUNCTION custom_constant
\end{boxverbatim}

Note that when \inlinecode{opcode} is successfully recognised, the code sets
the return value and returns straight away. This is how all constants should
work, since the last line forces the function to return an error code. This
last line is in place to trap people registering constants but never defining
them. Without this line, it is possible to define a constant which is
never specified and have the code complete OK with a random value for that
constant.

The constant ``phi'' should now work fine when used anywhere in the input deck
and will return a value of $\pi$.

\subsubsection{Setting up new functions}

Setting up the new function \inlinecode{lorentz} is very similar to setting up
the new constant. The relevant function is \inlinecode{custom\_function} and
when empty looks like:
\begin{boxverbatim}
FUNCTION custom_function(opcode, ix, iy, errcode)

  INTEGER, INTENT(IN) :: opcode, ix, iy
  INTEGER, INTENT(INOUT) :: errcode
  REAL(num) :: custom_function
  REAL(num) :: values(5)

  ! Leave these lines in place. They cause the code to throw an error if
  ! The opcode is unknown
  custom_function = 0.0_num
  errcode = IOR(errcode, c_err_unknown_element)

END FUNCTION custom_function
\end{boxverbatim}

The parameters are

\begin{itemize}
\item opcode - The operator code of the constant requested. This will be the
  integer handle returned from \inlinecode {register\_function}.
\item ix, iy, iz - Some functions are evaluated differently at specific points
  in space and ix, iy, iz are the gridpoint number of the location currently
  being evaluated. If you are specifying a simple function then just
  ignore these. If your function does depend upon space then directly
  subscript your array with ix, iy, iz as needed to read the correct location.
\item errcode - The error code which should be passed back to the
  parser. If for some reason you cannot evaluate your function then you should
  \inlinecode{IOR} errcode with the appropriate error code. Note that errcode
  should never be SET to any specific error code, since this might overwrite
  errors put in place earlier in the parsing sequence.
\end{itemize}

The function should return the value of your evaluated constant. The
parameters which are passed to the function can be retrieved by the function
\inlinecode {get\_values(n, values)}, where \inlinecode {n} is the number of
parameters to be returned and \inlinecode{values} is a \inlinecode{REAL(num)}
array of length \inlinecode{n} which will hold the returned values .  In this
implementation of the Lorentzian function there are three parameters: The
dependent variable, the location parameter and the scale parameter. The code
to implement the function therefore looks like:
\begin{boxverbatim}
FUNCTION custom_function(opcode, ix, iy, errcode)

  INTEGER, INTENT(IN) :: opcode, ix, iy
  INTEGER, INTENT(INOUT) :: errcode
  REAL(num) :: custom_function
  REAL(num) :: values(5)

  IF (opcode .EQ. c_func_lorentz) THEN
    CALL get_values(3, values(1:3))
    ! values(1) - Dependent variable
    ! values(2) - location parameter
    ! values(3) - scale parameter
    custom_function = values(3)**2/((values(1)-values(2))**2+values(3)**2)
    RETURN
  ENDIF

  ! Leave these lines in place. They cause the code to throw an error if
  ! The opcode is unknown
  custom_function = 0.0_num
  errcode = IOR(errcode, c_err_unknown_element)

END FUNCTION custom_function
\end{boxverbatim}

This function is then available at any point in the input deck and if I return
to the previous example ic.deck file, it would be used as follows:
\begin{boxverbatim}
begin:constant
   particle_density = 100.0 # Particle number density
   profile_x = lorentz(x,0.0,1.0)
   profile_y = lorentz(y,0.0,1.0)
end:constant

begin:species
   name = s1

   # multiply density by real particle density
   number_density = particle_density * profile_x * profile_y

   # Set the temperature to be zero
   temp_x = 0.0
   temp_y = temp_x(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species

begin:species
   name = s2

   # Just copy the density for species s1
   number_density = number_density(s1)

   # Just copy the temperature from species s1
   temp_x = temp_x(s1)
   temp_y = temp_y(s1)

   # Set the minimum density for this species
   number_density_min = 0.3*particle_density
end:species
\end{boxverbatim}

It is therefore clear that the new lorentz function is essentially the same as
the built in gauss function. Note that due to the way that the parser works,
the end user is not required to deal with parameters which are themselves
maths expressions. They have been fully evaluated by the time they are
returned by \inlinecode{get\_values}. Note that the parser is not guaranteed to
be bulletproof. If a user calls \inlinecode{get\_values} requesting more
parameters than have been passed to the function then it will scramble the
stack which is used by the parser and cause the code to fail. Note that
calling \inlinecode{get\_values(2, values)} is not the same as calling
\inlinecode{get\_values(1, values)} twice, in fact calling
\inlinecode{get\_values(1, values)} multiple times will return the parameters in
{\it reverse} order. This is normal and is a feature of how the maths parser
operates. It is possible to use this property to write functions which have a
variable number of parameters, but this is not recommended.

\subsection{Adding new elements to the input deck}

For some types of changes to the code it is more convenient to have the end
user pass new parameters into the code. This can be for several reasons, and
the section on permanent additions to the input deck is given later in this
manual. At this stage, we will describe how to temporarily add new
elements to the input deck parser routines, allowing parameterising of
internal and manual initial conditions.

Custom input deck elements are setup in the file
\inlinecode{src/user\_interaction/custom\_deck.f90}. The function
\inlinecode{handle\_custom\_block} is called when a new block is started which
the core parser is not familiar with, and once for each element of a block. The
function \inlinecode{check\_custom\_blocks} is called once the entire deck has
been parsed and is used to check that all the elements which are required for
the code to run have been specified.

\subsubsection{handle\_custom\_block}
There are three parameters passed to \inlinecode{handle\_custom\_block}, which
are:
\begin{itemize}
\item blockname - The name of the block specified in the
  \inlinecode{begin:blockname} part of the input deck.
\item element - The name of the element in an input deck
  \inlinecode{element = value} pair.
\item value - The string representation of the value in an input deck
  \inlinecode{element = value} pair.
\end{itemize}

\inlinecode{handle\_custom\_block} is first called when a new block is begun
using \inlinecode{begin:blockname} and ``blockname'' is not recognised by the
core input deck parser. The first thing that it does is test whether or not it
is a valid custom block. The code does this by passing in the blockname with
\inlinecode{element} and \inlinecode{value} set to the special constant called
``blank''. When extending the input deck, an end user should check if either
\inlinecode{element} or \inlinecode{value} are set to the special constant
``blank'', and if they are then test to see whether the blockname is known or
not. If the blockname is known then the code should return the error code
\inlinecode{c\_err\_none} (No error). If the blockname is not known then the
code should return \inlinecode{c\_err\_unknown\_block} and the deck parser will
just skip the block. In operation, this looks like:
\begin{boxverbatim}
FUNCTION handle_custom_block(blockname, element, value)

  CHARACTER(LEN=entry_length), INTENT(IN) :: blockname, element, value
  INTEGER :: handle_custom_block
  TYPE(primitive_stack) :: output
  INTEGER :: ix, iy
  IF (str_cmp(blockname, "custom")) THEN
    IF (element .EQ. blank .OR. value .EQ. blank) THEN
       ! If element or value are blank then just testing block so return c_err_none
       handle_custom_block = c_err_none
       RETURN
     ENDIF
   ENDIF

  ! The following line must always be present
  handle_custom_block = c_err_unknown_block

END FUNCTION handle_custom_block
\end{boxverbatim}

In order to simply Fortran's rather annoying string handling behaviour, several
helper functions have been defined and the most used one is
\inlinecode{str\_cmp(string1, string2)}. This is a simple routine which returns
true if string1 == string2 and false otherwise. It is case sensitive but can
deal with differing string lengths etc. The next stage is to deal with the
actual \inlinecode{element = value} pairs in the deck. Each time that a new pair
is read from the deck, \inlinecode{handle\_custom\_block} is called with
\inlinecode{element} and \inlinecode{value} having the values read from the
deck. To test for known elements they should just be checked against a known
list of names using \inlinecode{str\_cmp} and return the error code
\inlinecode{c\_err\_unknown\_element} if the element isn't a known element. This
looks like:
\begin{boxverbatim}
FUNCTION handle_custom_block(blockname, element, value)

  CHARACTER(LEN=entry_length), INTENT(IN) :: blockname, element, value
  INTEGER :: handle_custom_block
  TYPE(primitive_stack) :: output
  INTEGER :: ix, iy

  IF (str_cmp(blockname, "custom")) THEN
    IF (element .EQ. blank .OR. value .EQ. blank) THEN
      ! If element or value are blank then just testing block so return c_err_none
      handle_custom_block = c_err_none
      RETURN
    ENDIF
    handle_custom_block = c_err_unknown_element
    ! Now test for the real elements
    IF (str_cmp(element, "int_element")) THEN
      handle_custom_block = c_err_none
    ENDIF
    IF (str_cmp(element, "real_element")) THEN
      handle_custom_block = c_err_none
    ENDIF
    IF (str_cmp(element, "logical_element")) THEN
      handle_custom_block = c_err_none
    ENDIF
    RETURN
  ENDIF

  ! The following line must always be present
  handle_custom_block = c_err_unknown_block

END FUNCTION handle_custom_block
\end{boxverbatim}

This version of the code will allow you to add a new block called ``custom''
with elements\linebreak
``int\_element'', ``real\_element'' and ``logical\_element'' and the
code will parse them successfully, while any other block or any other element
in the block ``custom'' will throw errors. However, at this stage the code
doesn't actually read any of the values from the deck. To make it useful, any
variable which is read from the input deck must be stored in a global
variable. Defining global variables are explained in more detail in the
relevant section of the manual, but in short, any variable defined in the
module \inlinecode{shared\_data} in the file \inlinecode{src/shared\_data.F90}
will be a global variable. After the variables have been setup, there are once
again helper functions to make converting the text from the deck into a normal
Fortran90 variable. These helper functions are:

\begin{itemize}
\item as\_integer - Attempts to convert a string to an integer. Invokes the
  maths parser.
\item as\_real - Attempts to convert a string to a REAL(num). Invokes the maths
  parser.
\item as\_logical - Attempts to convert a string to a logical. Does not invoke
  the maths parser (must be either ``T'' or ``F'').
\end{itemize}

They are used pretty much as expected, except that the return value is passed
to the functions so that they can report errors while trying to parse the
string. An example would then be:
\begin{boxverbatim}
FUNCTION handle_custom_block(blockname, element, value)

  CHARACTER(LEN=entry_length), INTENT(IN) :: blockname, element, value
  INTEGER :: handle_custom_block
  TYPE(primitive_stack) :: output
  INTEGER :: ix, iy
  IF (str_cmp(blockname, "custom")) THEN
    IF (element .EQ. blank .OR. value .EQ. blank) THEN
      ! If element or value are blank then just testing block so return c_err_none
      handle_custom_block = c_err_none
      RETURN
    ENDIF
    handle_custom_block = c_err_unknown_element
    ! Now test for the real elements
    IF (str_cmp(element, "int_element")) THEN
      handle_custom_block = c_err_none
      int_element = as_integer(value, handle_custom_block)
    ENDIF
    IF (str_cmp(element, "real_element")) THEN
      handle_custom_block = c_err_none
      real_element = as_real(value, handle_custom_block)
    ENDIF
    IF (str_cmp(element, "logical_element")) THEN
      handle_custom_block = c_err_none
      logical_element = as_logical(value, handle_custom_block)
      ENDIF
    RETURN
  ENDIF

  ! The following line must always be present
  handle_custom_block = c_err_unknown_block

END FUNCTION handle_custom_block
\end{boxverbatim}

It is possible to perform more advanced types of evaluation of maths
expressions such as reading arrays etc. but this is beyond the scope of this
manual at present.

\subsubsection{check\_custom\_blocks}
This function is called when all the blocks in the input deck have been
evaluated and is used to check that all required parameters have been set. If
all required elements have been set then you should just return
\inlinecode{c\_err\_none}, otherwise return
\inlinecode{c\_err\_missing\_elements}. How you test that required elements have
been set is up to the developer, and for testing and personal use (which is
all that the custom deck parts of the code should be used for) it is
acceptable to just not check and always return \inlinecode{c\_err\_none}. If
permanently expanding the deck, error trapping should always be written.

\subsection{Permanently adding functions, constants to {\EPOCH}}
\label{sec:maths}
In much the same way that it is possible to permanently add new blocks to the
input deck, it is also possible to permanently add functions and constants to
{\EPOCH}'s maths parser. Although adding new operators is possible, it is
sufficiently likely to cause problems with the operation of the maths parser
that it is formally not recommended by the author of the program, and hence is
not documented here.

\subsubsection{Adding the new tokenizer handle}
When adding a new function or constant to the maths parser using the temporary
routines, there are two calls (\inlinecode{register\_function} and
\inlinecode{register\_constant}) which give a numerical handle. This is the
token used to represent that function or constant after the text has been parsed
(remember that {\EPOCH}'s maths parser tokenizes before evaluation!). When
permanently adding objects to the maths parser, the tokenizer handles have to
be set up manually. This takes place in \inlinecode{src/shared\_data.F90} in
the module \inlinecode{shared\_parser\_data}. There are several lines which
look like:
\begin{boxverbatim}
  INTEGER, PARAMETER :: c_const_ix = 40
  INTEGER, PARAMETER :: c_const_iy = 41
  .
  .
  .
  INTEGER, PARAMETER :: c_func_interpolate = 22
  INTEGER, PARAMETER :: c_func_tanh = 23
\end{boxverbatim}
Constants beginning with \inlinecode{c\_const\_} are tokenizer handles for
constants, and those beginning with \inlinecode{c\_func\_} are tokenizer handles
for functions. Each number must be unique and has to be less than
the lower bound of values reserved for temporary or deck
specified values. This means that any tokenizer handle for a function has to be
less than the value of the variable \inlinecode{c\_func\_custom\_lowbound} and
any handle for a constant must be less than
\inlinecode{c\_const\_deck\_lowbound}. It is acceptable to simply increase the
value of \inlinecode{c\_func\_custom\_lowbound} and
\inlinecode{c\_const\_deck\_lowbound} to
allow the use of more values for internal constants and functions, although
care should be taken since this could lead to performance issues.
If \inlinecode{c\_const\_deck\_lowbound} is increased then the constant
\inlinecode{c\_constant\_custom\_lowbound} should be increased by the same
amount (the values between \inlinecode{c\_const\_deck\_lowbound} and\linebreak
\inlinecode{c\_constant\_custom\_lowbound-1} are used for constants specified
inside the input deck while values greater than or equal to
\inlinecode{c\_constant\_custom\_lowbound} are used for constants specified
by\linebreak \inlinecode{register\_constant}.

Once the tokenizer handle is specified in \inlinecode{shared\_parser\_data}, it
is now possible to extend the main areas of the maths parser. Note that from
here on, you MUST always use the constant named handle, NEVER the numerical
value that you specified for the value of the handle. If this is not done
then combining functions and constants from several sources becomes much harder.

\subsubsection{Adding the new function or constant to the tokenizer}
The next stage is to add the string representation of your constant or function
to the tokenizer routines in
\inlinecode{src/parser/tokenizer\_blocks.F90}. This is very simple to do, just
find either the function \inlinecode{as\_constant} or \inlinecode{as\_function}
and look at the existing code. These functions are just long lists of
\inlinecode{str\_cmp} commands followed by code to deal with custom
functions/constants. To add the new code, create an additional line such as:
\begin{boxverbatim}
  IF (str_cmp(name, "my_const")) as_constant = c_const_my_const
  .
  .
  .
  IF (str_cmp(name, "my_func"))  as_function = c_func_my_func
\end{boxverbatim}
Note that neither routine returns immediately after recognising the name of the
function/constant. This allows users to override built in constants or
functions with custom versions using\linebreak \inlinecode{register\_constant}
and \inlinecode{register\_function}. This is not significant, since tokenizing
should never be used in a speed critical part of the code.

\subsubsection{Implementing the function or constant in the evaluator}
The evaluator is the part of the code that actually takes the streams of tokens
produced by the tokenizer and evaluates them into a number. The relevant parts
of the evaluator for adding new constants or functions are in
\inlinecode{src/parser/evaluator\_blocks.F90} and the functions which may need
changing are \inlinecode{do\_constant} and \inlinecode{do\_functions}. These are
both passed up to five parameters:
\begin{itemize}
\item #INTEGER :: opcode# - The operation code, this is the tokenizer handle
  which was defined in \inlinecode{shared\_parser\_data}.
\item #INTEGER :: ix, iy, iz# - The position of the current evaluation in the
  domain. If your function or constant behaves differently at different points
  in space then you should use these parameters to reference the correct point
  of an array.
\item #INTEGER :: errcode# - This should be set to an error code from
  Appendix A, usually\linebreak \inlinecode{c\_err\_bad\_value} if for some
  reason it is not possible to evaluate your constant or function.
\end{itemize}

The rest of the routine to set a constant is as simple as testing for the
tokenizer handle already set up in \inlinecode{shared\_parser\_data} and then
calling the subroutine \inlinecode{push\_on\_eval}. This pushes the final
constant onto the evaluation stack which is used by the RPN parser. The basic
sequence for functions is similar except for the addition of a code to read
the values that the function takes. This is again the subroutine
\inlinecode{get\_values} which is also used in custom\_function. The calling
sequence in \inlinecode{do\_function} looks like:
\begin{boxverbatim}
  IF (opcode .EQ. c_func_gauss) THEN
    CALL get_values(3, values)
    CALL push_on_eval(EXP(-((values(1)-values(2))/values(3))**2))
    RETURN
  ENDIF
\end{boxverbatim}
Simply call the \inlinecode{get\_values} subroutine, passing the number of
required parameters and an array of type \inlinecode{REAL(num)} which is at
least as long as the number of required parameters. The array is populated
by the values passed into the function. Constants and maths expressions are
already evaluated by the time that this section of code is reached, so there is
no need to deal with further parsing. Next, simply call
\inlinecode{push\_on\_eval} to push the result of your function onto the
evaluation stack.

\section{Developing an extension to {\EPOCH}}
\label{sec:extend}

Exactly how to extend {\EPOCH} depends heavily upon what you intend to add. The
simplest things to add are new diagnostics, and this is detailed in
\sect{io}. Other places where changes are likely to be made
are the following:
\begin{itemize}
\item The field solver - Changing the field solver to add new laser-like
  boundaries, add spatial smoothing to remove noise, add high order field
  solvers etc.
\item The particle pusher - Change the basic physical model of {\EPOCH} by
  modifying the particle pusher.
\item The boundary routines - Add new boundary conditions or modify existing
  boundary conditions.
\item The laser boundary routines - Add new features to the laser boundaries in
  this routine.
\item The main driver (\inlinecode{epoch\{n\}d.F90}) - This is the routine
  where the main calling sequence of {\EPOCH} is setup, and totally new
  extensions to {\EPOCH} should be placed in here.
\end{itemize}

Changing the field solver, the particle pusher or boundary routines
is fairly easy to accomplish by reading the section of this manual that
details the relevant code. The general sequence for writing an extension
would be:
\begin{itemize}
\item Add any new global variables needed to \inlinecode{shared\_data.F90}.
\item Add the meat of your change to the code.
\item Test the changes to your code. Make absolutely sure that you can turn your
  change to the code off.
\item Add controls for your extension to the input deck reader.
\end{itemize}

\subsection{The main driver routine}
When adding completely new routines to the code, they should be added to the
file \inlinecode{src/epoch\{n\}d.F90}. This routine simply calls other routines
to perform the actual execution of the code. The first section of the code
controls basic setup, MPI initialisation and
initial conditions. If you wish to add new startup conditions then
you should find the location in this routine where the
initial conditions are setup. The code is fairly complicated, but
there are a few key points at which the code significantly changes state.
\begin{itemize}
\item After the call to \inlinecode{read\_deck} the code has read the basic
  information from the input deck files and any tests or changes which have to
  be made to input deck values should be made immediately after this line. Note
  that although the variables from the deck have been set,
  none of these values have been used so allocatable
  variables have yet to be allocated. The grid does not exist at this point.
\item After the call to \inlinecode{open\_files} the code has finished
  allocating all field variables, although particles may not yet have been set
  up. The grid now exists.
\item There are now a series of \inlinecode{IF} statements which test for
  things like\linebreak \inlinecode{IF (IOR(ictype, c\_ic\_autoload) .NE. 0)}.
  These are the lines which test for all possible states of the
  initial conditions. The last test is for the manual load routine
  (\inlinecode{c\_ic\_manual}). After this test all the particles have been
  loaded and are now on their correct processor. The load balancer has now been
  called at least once so the domains may no longer be identical.
\item The main loop is a simple do loop beginning with just the single command
  \inlinecode{DO}. Inside this loop there are several calls to routines which
  actually advance the system. Most routines which can change currents should
  take place after the particle pusher but before the final update for the $E$
  and $B$ fields. These routines are
  \subitem \inlinecode{set\_dt} - This routine sets the timestep.
  \subitem \inlinecode{update\_eb\_fields\_half} - Time centre the $E$ and $B$
    fields.
  \subitem \inlinecode{push\_particles} - The particle pusher.
  \subitem \inlinecode{reorder\_particles\_to\_grid} - Groups particles into
    linked lists at each grid point. Used for the particle splitting routine,
    and would be the right place to add a collision operator. Any routine
    which needs to have nearby particles grouped together should take place
    after the call to this routine.
  \subitem \inlinecode{split\_particles} - The very early beta particle
    splitting operator. Doesn't really work yet, so do not use!
  \subitem \inlinecode{reattach\_particles\_to\_mainlist} - Undoes the
    particle grouping and rebuilds the main list of particles used by the
    particle pusher. Any routine which needs to have nearby particles grouped
    together should take place before the call to this routine.
  \subitem \inlinecode{update\_eb\_fields\_final} - Updates the $E$ and $B$
    fields to the full timestep.
\item After the call to \inlinecode{update\_eb\_fields\_final} the code is
  ready for another timestep. Any routines which do not change the time
  integrated properties of the code (like the moving window) should come after
  this call.
\end{itemize}

\subsection{The particle reordering routine}
If the code is compiled with the right flags then during the main loop the
particles are grouped into a linked list for each cell in the domain, with all
the particles which are in that cell linked into the list. The main list
\inlinecode{species(ispecies)\%attached\_list} is empty and cannot be used
during this period. The particles should now be accessed using the variable
\inlinecode{species(ispecies)\%secondary\_list(ix,iy,iz)} which is the array of
linked lists. This array is allocated on the call to
\inlinecode{reorder\_particles\_to\_grid} and deallocated on the call to
\inlinecode{reattach\_particles\_to\_mainlist}, and should not be used outside
the section of code between these two calls. The particles themselves remain
unchanged. No attempt is made to check that particles do not cross processor
boundaries in this section, so if a particle's position is changed, it is up to
the user to ensure that the particle is transferred to another processor if
required. However, if a particle is transferred to another processor, it is
acceptable to relink it to \inlinecode{species(ispecies)\%attached\_list} since
the other lists are simply appended to that list when the particles are
reattached to the main list.\\

You should not write an extension to the code which requires the use of the
particle reordering routines if it can be avoided since these routines
have a significant impact on performance.

\pagebreak
\def\epoch{}\input{sdf_format}
\pagebreak

\appendix
  \appendixpage
  \addappheadtotoc
\section{Error Codes}
The input deck and maths parser in {\EPOCH} use various named error codes to
report on errors which occur during the evaluation of the input deck. These
codes are
\begin{itemize}
\item c\_err\_none - No error. Set an error code to c\_err\_none to state that
  no error has occurred.
\item c\_err\_unknown\_block - In the input deck a block has been found which is
  not known. This should be returned in \inlinecode{handle\_custom\_block} if
  it is passed any block that it has not been written to handle.
\item c\_err\_unknown\_element - In the input deck an element of a valid block
  has been found which is not known. This should be returned in
  \inlinecode{handle\_custom\_block} if an element is requested which is
  unknown.
\item c\_err\_preset\_element - An element of the input deck has already been
  set and is being set again. Usually this is an indication of a malformed input
  deck file, so \inlinecode{handle\_custom\_block} should try to
  identify such situations and return this error message if
  subsequent attempts to set the variable are being ignored.
\item c\_err\_preset\_element\_use\_later - An element of the input deck has
  already been set and is being set again. Usually this is an indication of a
  malformed input deck file, so \inlinecode{handle\_custom\_block} should try to
  identify such situations and return this error message if
  the subsequent attempts to set the variable override previous ones.
\item {\bf c\_err\_bad\_value} - A value which is being evaluated for the right
  hand side of an element assignment is in some way invalid. Internally to the
  code this usually means that a string which must be interpreted as a maths
  expression or numerical constant is in some way malformed. It is also
  acceptable to return this error code when a value has been passed which is
  invalid for some other reason (the value is outside an acceptable range, etc.)
\item {\bf c\_err\_missing\_elements} - This is an error code returned when the
  code is testing to make sure that all necessary elements of an input deck
  file have been specified. It should be returned when some required parameter
  is missing in the subroutine \inlinecode{check\_custom\_blocks}.
\item c\_err\_terminate - This error code means that the code is in a state
  where execution is impossible and the code must terminate once the input deck
  has been read. Some other error codes automatically set c\_err\_terminate,
  but it can always be IOR'ed with any error code to force the code to exit.
  Note that just returning c\_err\_terminate will cause the code to
  silently quit.
\item {\bf c\_err\_required\_element\_not\_set} - This means that the code
  cannot parse an input deck element since another element which must be known
  beforehand has not been set. This is intended for things like setting the
  species information where the number of species must be known in
  advance. This error code uses the extended error string to give user friendly
  feedback. If you return this error code then you should set
  extended\_error\_string to be equal to the name of the required element which
  has not been set. If multiple previous elements are required then the code
  should be set up so that it checks for the presence of the required elements
  in order and reports on missing elements so that the end user can fix them
  one by one.
\item c\_err\_pp\_options\_wrong - If you've written a section of the code that
  is controlled by preprocessor options then you should return this
  error message if someone attempts to set input deck elements which refer to
  that part when the correct preprocessor options are not used. This means that
  the user is aware of the fact that the requested feature will not be
  active. This error code also uses the extended error string to give user
  friendly feedback. If you return this error code, you should set the string
  extended\_error\_string to the define command that would turn on the
  requested feature of the code (``-DPER\_PARTICLE\_WEIGHT'', for example).
\item {\bf c\_err\_other} - This error code is a catch all error which causes
  the code to quit with a sarcastic error message. It's mainly intended for
  debugging and is used before the final error code is implemented.
\end{itemize}

Those error codes with names in {\bf BOLD} are those which will cause the code
to terminate.

\end{document}
